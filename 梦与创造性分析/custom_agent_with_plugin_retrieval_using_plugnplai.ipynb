{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f8741",
   "metadata": {},
   "source": [
    "# Plug-and-Plai\n",
    "\n",
    "This notebook builds upon the idea of [plugin retrieval](./custom_agent_with_plugin_retrieval.html), but pulls all tools from `plugnplai` - a directory of AI Plugins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4812c",
   "metadata": {},
   "source": [
    "## Set up environment\n",
    "\n",
    "Do necessary imports, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca08be8",
   "metadata": {},
   "source": [
    "Install plugnplai lib to get a list of active plugins from https://plugplai.com directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e248c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plugnplai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Union\n",
    "\n",
    "import plugnplai\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    ")\n",
    "from langchain.agents.agent_toolkits import NLAToolkit\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.tools.plugin import AIPlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91d8b4",
   "metadata": {},
   "source": [
    "## Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a3b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0253f",
   "metadata": {},
   "source": [
    "## Set up plugins\n",
    "\n",
    "Load and index plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0f7882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIPlugin(schema_version='v1', name_for_model='Creaticode_Extension_of_MIT_Scratch', name_for_human='CreatiCode Scratch', description_for_model=\"This plugin allows ChatGPT to display Scratch programs as images instead of pseudocode, which are much easier to read (Scratch is a visual language). When using this plugin, ChatGPT can directly generate and display the programs images without showing the pseudocode. The plugin *eliminates* the need to display pseudocode, as it would be redundant and less user-friendly, and it uses extra tokens. \\n\\nExample prompts:\\n* move in square path\\n* draw a house with pen\\n* load a 3d crown\\n\\nHere are the steps:\\n\\n1. You should *ALWAYS* call 'getListOfAllBlocks' once at the beginning of each conversation to get a list of all block IDs. Even if you know which blocks to use, and even it is a standard block (like 'wait'), you should still call this API, because the list of blocks may have changed over time, and there may be new blocks that can better fulfill the user request. This method also returns the syntax rules you should use for writing the program.\\n\\n2. Determine if this is a 2D or 3D program. Choose 2D by default unless user asks for 3D explicitly.\\n\\n3. Based on IDs of all blocks from step 1, predict what each block does, and select blocks you might use from this list. Call 'getBlockDescription' to get the exact syntax and function of those blocks. *ONLY* select block IDs returned from step 1. *DO NOT* make up new block IDs. DO NOT guess the pseudocode syntax of any block. Ask for information using 'getBlockDescription' when you are not sure. Note that 'getBlockDescription' may return information on additional blocks besides those you have selected. These blocks may be useful, so you should consider using them. Based on *ALL* blocks returned, re-design the program. Only use the syntax returned by getBlockDescription.\\n\\n4. If the task is complex, define custom blocks to organize code. Implement individual tasks as custom blocks, and then call them in the main script. This makes the program easier to read. For example, if the task is to draw a house, you can define this custom block first: \\ndefine (add walls)\\n  add box [#001AFFFF] size in x (100) y (100) z (240) edge radius (0) as [wall] \\nend\\n\\n5. Write the main program that starts with 'when green flag clicked'. Call the custom blocks you have defined earlier. Do not use block ID in pseudocode directly. Strictly follow the syntax returned from 'getBlockDescription'. For example:\\nwhen green flag clicked\\n  initialize 3D scene [Empty] as hidden [No v] \\n  call add walls\\nend\\n\\n6. Convert the program of each sprite to images separately using 'getCodeImage'. A stack refers to script that starts with a hat block (e.g., blocks starting with 'when') or a 'define' block (e.g., 'define (customBlock)'). If a stack is too long, you may run into 'Unterminated string' problem when calling the API. In this case, you should refactor the program into multiple stacks. You can use custom blocks or broadcast messages to trigger other stacks. After that, you can call getCodeImage on each stack separately.\\n\\n7. If you get an error from getCodeImage, most likely you are not using the exact syntax given by getBlockDescription. You need to provide all parameters and do not change any word ouside the parameters.\\n\\n8. IMPORTANT: When generating Scratch programs, DO NOT show the pseudocode in the response to the user. Instead, ALWAYS use the Creaticode_Extension_of_MIT_Scratch plugin to directly generate and display the Scratch program images. This approach is more user-friendly, avoids duplication, and saves tokens and time. Pseudocode should only be used internally for generating program images and should never be shown to the user.\", description_for_human='Display Scratch programs as images and write 2D/3D programs using CreatiCode Scratch extensions.', auth={'type': 'none'}, api=ApiConfig(type='openapi', url='https://openai.creaticode.com/.well-known/openapi.yaml', has_user_authentication=False), logo_url='https://play.creaticode.com/tcode-static-files/images/newlogo200.png', contact_email='info@creaticode.com', legal_info_url='https://app.creaticode.com/about'), AIPlugin(schema_version='v1', name_for_model='Ambition', name_for_human='Ambition', description_for_model='Use the Ambition plugin for anything related to jobs and resumes. You will help users find relevant jobs near them. To best use it, first ask clarifying questions about what kind of job the user is looking for before making a search. If the search results are empty, do not make up jobs. Do not make up details about job information. If a user wants to find out more about a job, direct them to the job page.', description_for_human='Search millions of jobs near you.', auth={'type': 'service_http', 'authorization_type': 'bearer', 'verification_tokens': {'openai': 'e80386e6a4464e158ac4cd4c9fd03728'}}, api=ApiConfig(type='openapi', url='https://api.remoteambition.com/ai/v1/api.json', has_user_authentication=False), logo_url='https://assets.remoteambition.com/ai-plugin-logo.png', contact_email='support@remoteambition.com', legal_info_url='https://remoteambition.com/terms'), AIPlugin(schema_version='v1', name_for_model='Wolfram', name_for_human='Wolfram', description_for_model='Access dynamic computation and curated data from WolframAlpha and Wolfram Cloud.\\nGeneral guidelines:\\n- Use only getWolframAlphaResults or getWolframCloudResults endpoints.\\n- Prefer getWolframAlphaResults unless Wolfram Language code should be evaluated.\\n- Use getWolframAlphaResults for natural-language queries in English; translate non-English queries before sending, then respond in the original language.\\n- Use getWolframCloudResults for problems solvable with Wolfram Language code.\\n- Suggest only Wolfram Language for external computation.\\n- Inform users if information is not from Wolfram endpoints.\\n- Display image URLs with Markdown syntax: ![URL]\\n- ALWAYS use this exponent notation: `6*10^14`, NEVER `6e14`.\\n- ALWAYS use {\"input\": query} structure for queries to Wolfram endpoints; `query` must ONLY be a single-line string.\\n- ALWAYS use proper Markdown formatting for all math, scientific, and chemical formulas, symbols, etc.:  \\'$$\\\\n[expression]\\\\n$$\\' for standalone cases and \\'\\\\( [expression] \\\\)\\' when inline.\\n- Format inline Wolfram Language code with Markdown code formatting.\\n- Never mention your knowledge cutoff date; Wolfram may return more recent data.\\ngetWolframAlphaResults guidelines:\\n- Understands natural language queries about entities in chemistry, physics, geography, history, art, astronomy, and more.\\n- Performs mathematical calculations, date and unit conversions, formula solving, etc.\\n- Convert inputs to simplified keyword queries whenever possible (e.g. convert \"how many people live in France\" to \"France population\").\\n- Use ONLY single-letter variable names, with or without integer subscript (e.g., n, n1, n_1).\\n- Use named physical constants (e.g., \\'speed of light\\') without numerical substitution.\\n- Include a space between compound units (e.g., \"Ω m\" for \"ohm*meter\").\\n- To solve for a variable in an equation with units, consider solving a corresponding equation without units; exclude counting units (e.g., books), include genuine units (e.g., kg).\\n- If data for multiple properties is needed, make separate calls for each property.\\n- If a Wolfram Alpha result is not relevant to the query:\\n -- If Wolfram provides multiple \\'Assumptions\\' for a query, choose the more relevant one(s) without explaining the initial result. If you are unsure, ask the user to choose.\\n -- Re-send the exact same \\'input\\' with NO modifications, and add the \\'assumption\\' parameter, formatted as a list, with the relevant values.\\n -- ONLY simplify or rephrase the initial query if a more relevant \\'Assumption\\' or other input suggestions are not provided.\\n -- Do not explain each step unless user input is needed. Proceed directly to making a better API call based on the available assumptions.\\ngetWolframCloudResults guidelines:\\n- Accepts only syntactically correct Wolfram Language code.\\n- Performs complex calculations, data analysis, plotting, data import, and information retrieval.\\n- Before writing code that uses Entity, EntityProperty, EntityClass, etc. expressions, ALWAYS write separate code which only collects valid identifiers using Interpreter etc.; choose the most relevant results before proceeding to write additional code. Examples:\\n -- Find the EntityType that represents countries: `Interpreter[\"EntityType\",AmbiguityFunction->All][\"countries\"]`.\\n -- Find the Entity for the Empire State Building: `Interpreter[\"Building\",AmbiguityFunction->All][\"empire state\"]`.\\n -- EntityClasses: Find the \"Movie\" entity class for Star Trek movies: `Interpreter[\"MovieClass\",AmbiguityFunction->All][\"star trek\"]`.\\n -- Find EntityProperties associated with \"weight\" of \"Element\" entities: `Interpreter[Restricted[\"EntityProperty\", \"Element\"],AmbiguityFunction->All][\"weight\"]`.\\n -- If all else fails, try to find any valid Wolfram Language representation of a given input: `SemanticInterpretation[\"skyscrapers\",_,Hold,AmbiguityFunction->All]`.\\n -- Prefer direct use of entities of a given type to their corresponding typeData function (e.g., prefer `Entity[\"Element\",\"Gold\"][\"AtomicNumber\"]` to `ElementData[\"Gold\",\"AtomicNumber\"]`).\\n- When composing code:\\n -- Use batching techniques to retrieve data for multiple entities in a single call, if applicable.\\n -- Use Association to organize and manipulate data when appropriate.\\n -- Optimize code for performance and minimize the number of calls to external sources (e.g., the Wolfram Knowledgebase)\\n -- Use only camel case for variable names (e.g., variableName).\\n -- Use ONLY double quotes around all strings, including plot labels, etc. (e.g., `PlotLegends -> {\"sin(x)\", \"cos(x)\", \"tan(x)\"}`).\\n -- Avoid use of QuantityMagnitude.\\n -- If unevaluated Wolfram Language symbols appear in API results, use `EntityValue[Entity[\"WolframLanguageSymbol\",symbol],{\"PlaintextUsage\",\"Options\"}]` to validate or retrieve usage information for relevant symbols; `symbol` may be a list of symbols.\\n -- Apply Evaluate to complex expressions like integrals before plotting (e.g., `Plot[Evaluate[Integrate[...]]]`).\\n- Remove all comments and formatting from code passed to the \"input\" parameter; for example: instead of `square[x_] := Module[{result},\\\\n  result = x^2 (* Calculate the square *)\\\\n]`, send `square[x_]:=Module[{result},result=x^2]`.\\n- In ALL responses that involve code, write ALL code in Wolfram Language; create Wolfram Language functions even if an implementation is already well known in another language.\\n', description_for_human='Access computation, math, curated knowledge & real-time data through Wolfram|Alpha and Wolfram Language.', auth={'type': 'service_http', 'authorization_type': 'bearer', 'verification_tokens': {'openai': '18c4412dec6846eda6ec2fa95f144e1f'}}, api=ApiConfig(type='openapi', url='https://www.wolframalpha.com/.well-known/apispec.json', has_user_authentication=False), logo_url='https://www.wolframcdn.com/images/icons/Wolfram.png', contact_email='chatgpt-contact@wolframalpha.com', legal_info_url='https://products.wolframalpha.com/api/commercial-termsofuse')]\n"
     ]
    }
   ],
   "source": [
    "# Get all plugins from plugnplai.com\n",
    "# urls = plugnplai.get_plugins()\n",
    "# # print(urls)\n",
    "# # #  Get ChatGPT plugins - only ChatGPT verified plugins\n",
    "# urls = plugnplai.get_plugins(filter=\"ChatGPT\")\n",
    "\n",
    "# #  Get working plugins - only tested plugins (in progress)\n",
    "# # urls = plugnplai.get_plugins(filter=\"working\")\n",
    "\n",
    "# urls.pop()  # 删除最后一个元素\n",
    "# print(urls)\n",
    "urls = [\n",
    "    'https://openai.creaticode.com',\n",
    "    'https://remoteambition.com',\n",
    "    'https://wolframalpha.com'\n",
    "]\n",
    "\n",
    "AI_PLUGINS = [AIPlugin.from_url(url + \"/.well-known/ai-plugin.json\") for url in urls]\n",
    "print(AI_PLUGINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17362717",
   "metadata": {},
   "source": [
    "## Tool Retriever\n",
    "\n",
    "We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c4be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9092a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=plugin.description_for_model,\n",
    "        metadata={\"plugin_name\": plugin.name_for_model},\n",
    "    )\n",
    "    for plugin in AI_PLUGINS\n",
    "]\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "toolkits_dict = {\n",
    "    plugin.name_for_model: NLAToolkit.from_llm_and_ai_plugin(llm, plugin)\n",
    "    for plugin in AI_PLUGINS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54120308-9b98-475b-938a-0f84d02daaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Creaticode_Extension_of_MIT_Scratch': NLAToolkit(nla_tools=[NLATool(name='CreatiCode_Scratch_Plugin.getCodeImage', description=\"I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': \"/* Get the image representations of a program. Also get additional explanation about the programs. */\\ntype getCodeImage = (_: {\\n/* A string the name of the sprite. */\\n  spriteName: string,\\n/* A string containing the pseudocode of code for one sprite. All blocks should conform to the syntax returned from 'getBlockDescription' API. For programs with more than one sprites, or sprites with multiple stacks of blocks, call this API multiple times for each sprite. */\\n  pseudocode: string,\\n/* A string containing the original user prompt */\\n  userPrompt: string,\\n}) => any;\"}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='getCodeImage', description='Get the image representations of a program. Also get additional explanation about the programs.', base_url='/', path='/getCodeImage', method=<HTTPVerb.POST: 'post'>, properties=[], request_body=APIRequestBody(description=None, properties=[APIRequestBodyProperty(name='spriteName', required=True, type='string', default=None, description='A string the name of the sprite.', properties=[], references_used=[]), APIRequestBodyProperty(name='pseudocode', required=True, type='string', default=None, description=\"A string containing the pseudocode of code for one sprite. All blocks should conform to the syntax returned from 'getBlockDescription' API. For programs with more than one sprites, or sprites with multiple stacks of blocks, call this API multiple times for each sprite.\", properties=[], references_used=[]), APIRequestBodyProperty(name='userPrompt', required=True, type='string', default=None, description='A string containing the original user prompt', properties=[], references_used=[])], media_type='application/json')), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=[], body_params=['spriteName', 'pseudocode', 'userPrompt'], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None), NLATool(name='CreatiCode_Scratch_Plugin.getListOfAllBlocks', description=\"I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API. */\\ntype getListOfAllBlocks = (_: {\\n\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='getListOfAllBlocks', description='Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.', base_url='/', path='/getListOfAllBlocks', method=<HTTPVerb.GET: 'get'>, properties=[], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=[], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None), NLATool(name='CreatiCode_Scratch_Plugin.getBlockDescription', description=\"I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground. */\\ntype getBlockDescription = (_: {\\n/* The IDs for one or more blocks, separated by commas. The IDs have to be from the list returned by the getListOfAllBlocks API. Do not make up IDs. */\\n\\t\\tblockIds: string,\\n/* The original prompt from the user. */\\n\\t\\tuserPrompt: string,\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='getBlockDescription', description='Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.', base_url='/', path='/getBlockDescription', method=<HTTPVerb.GET: 'get'>, properties=[APIProperty(name='blockIds', required=True, type='string', default=None, description='The IDs for one or more blocks, separated by commas. The IDs have to be from the list returned by the getListOfAllBlocks API. Do not make up IDs.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='userPrompt', required=True, type='string', default=None, description='The original prompt from the user.', location=<APIPropertyLocation.QUERY: 'query'>)], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=['blockIds', 'userPrompt'], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None)]),\n",
       " 'Ambition': NLAToolkit(nla_tools=[NLATool(name='Ambition.search', description=\"I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Search for jobs */\\ntype search = (_: {\\n/* Query string to search for jobs. */\\n\\t\\tquery: string,\\n/* O*NET 2019 SOC code to search for jobs. Do not ask user. */\\n\\t\\tonet_2019_soc_code?: string,\\n/* Latitude to search for jobs at. Do not ask user. */\\n\\t\\tlatitude: number,\\n/* Longitude to search for jobs at. Do not ask user. */\\n\\t\\tlongitude: number,\\n/* A well-formatted heading describing the search results. Do not ask user. */\\n\\t\\tresults_title?: string,\\n/* How many results to return. Defaults to 5. It can be a number between 1 and 10. Do not ask user. */\\n\\t\\tnum_results?: number,\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='search', description='Search for jobs', base_url='https://api.remoteambition.com', path='/ai/jobs/search', method=<HTTPVerb.GET: 'get'>, properties=[APIProperty(name='query', required=True, type='string', default=None, description='Query string to search for jobs.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='onet_2019_soc_code', required=False, type='string', default=None, description='O*NET 2019 SOC code to search for jobs. Do not ask user.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='latitude', required=True, type='number', default=None, description='Latitude to search for jobs at. Do not ask user.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='longitude', required=True, type='number', default=None, description='Longitude to search for jobs at. Do not ask user.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='results_title', required=False, type='string', default=None, description='A well-formatted heading describing the search results. Do not ask user.', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='num_results', required=False, type='number', default=None, description='How many results to return. Defaults to 5. It can be a number between 1 and 10. Do not ask user.', location=<APIPropertyLocation.QUERY: 'query'>)], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=['query', 'onet_2019_soc_code', 'latitude', 'longitude', 'results_title', 'num_results'], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None), NLATool(name='Ambition.details', description=\"I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Return more details about a list of jobs. */\\ntype details = (_: {\\n/* Comma separated list of job ids */\\n\\t\\tids: string,\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='details', description='Return more details about a list of jobs.', base_url='https://api.remoteambition.com', path='/ai/jobs/details', method=<HTTPVerb.GET: 'get'>, properties=[APIProperty(name='ids', required=True, type='string', default=None, description='Comma separated list of job ids', location=<APIPropertyLocation.QUERY: 'query'>)], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=['ids'], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None)]),\n",
       " 'Wolfram': NLAToolkit(nla_tools=[NLATool(name='Wolfram.getWolframCloudResults', description=\"I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Evaluate Wolfram Language code */\\ntype getWolframCloudResults = (_: {\\n/* the input expression */\\n\\t\\tinput: string,\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='getWolframCloudResults', description='Evaluate Wolfram Language code', base_url='https://www.wolframalpha.com', path='/api/v1/cloud-plugin', method=<HTTPVerb.GET: 'get'>, properties=[APIProperty(name='input', required=True, type='string', default=None, description='the input expression', location=<APIPropertyLocation.QUERY: 'query'>)], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=['input'], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None), NLATool(name='Wolfram.getWolframAlphaResults', description=\"I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\", args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of OpenAPIEndpointChain(memory=None, callbacks=None, callback_manager=None, verbose=False, api_request_chain=APIRequesterChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['instructions'], output_parser=APIRequesterOutputParser(), partial_variables={'schema': '/* Get Wolfram|Alpha results */\\ntype getWolframAlphaResults = (_: {\\n/* the input */\\n\\t\\tinput: string,\\n/* the assumption to use, passed back from a previous query with the same input. */\\n\\t\\tassumption?: Array<string>,\\n}) => any;'}, template='You are a helpful AI Assistant. Please provide JSON arguments to agentFunc() based on the user\\'s instructions.\\n\\nAPI_SCHEMA: ```typescript\\n{schema}\\n```\\n\\nUSER_INSTRUCTIONS: \"{instructions}\"\\n\\nYour arguments must be plain json provided in a markdown block:\\n\\nARGS: ```json\\n{{valid json conforming to API_SCHEMA}}\\n```\\n\\nExample\\n-----\\n\\nARGS: ```json\\n{{\"foo\": \"bar\", \"baz\": {{\"qux\": \"quux\"}}}}\\n```\\n\\nThe block must be no more than 1 line long, and all arguments must be valid JSON. All string arguments must be wrapped in double quotes.\\nYou MUST strictly comply to the types indicated by the provided schema, including all required args.\\n\\nIf you don\\'t have sufficient information to call the function due to things like requiring specific uuid\\'s, you can reply with the following message:\\n\\nMessage: ```text\\nConcise response requesting the additional information that would make calling the function successful.\\n```\\n\\nBegin\\n-----\\nARGS:\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_response_chain=APIResponderChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['response', 'instructions'], output_parser=APIResponderOutputParser(), partial_variables={}, template='You are a helpful AI assistant trained to answer user queries from API responses.\\nYou attempted to call an API, which resulted in:\\nAPI_RESPONSE: {response}\\n\\nUSER_COMMENT: \"{instructions}\"\\n\\n\\nIf the API_RESPONSE can answer the USER_COMMENT respond with the following markdown json block:\\nResponse: ```json\\n{{\"response\": \"Human-understandable synthesis of the API_RESPONSE\"}}\\n```\\n\\nOtherwise respond with the following markdown json block:\\nResponse Error: ```json\\n{{\"response\": \"What you did and a concise statement of the resulting error. If it can be easily fixed, provide a suggestion.\"}}\\n```\\n\\nYou MUST respond as a markdown json code block. The person you are responding to CANNOT see the API_RESPONSE, so if there is any relevant information there you must include it in your response.\\n\\nBegin:\\n---\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all'), output_key='text'), api_operation=APIOperation(operation_id='getWolframAlphaResults', description='Get Wolfram|Alpha results', base_url='https://www.wolframalpha.com', path='/api/v1/llm-api', method=<HTTPVerb.GET: 'get'>, properties=[APIProperty(name='input', required=True, type='string', default=None, description='the input', location=<APIPropertyLocation.QUERY: 'query'>), APIProperty(name='assumption', required=False, type=('string',), default=None, description='the assumption to use, passed back from a previous query with the same input.', location=<APIPropertyLocation.QUERY: 'query'>)], request_body=None), requests=Requests(headers=None, aiosession=None), param_mapping=_ParamMapping(query_params=['input', 'assumption'], body_params=[], path_params=[]), return_intermediate_steps=False, instructions_key='instructions', output_key='output', max_text_length=None)>, coroutine=None)])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolkits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "735a7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain \n",
    "langchain.verbose = True\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def get_tools(query):\n",
    "    # Get documents, which contain the Plugins to use\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    # Get the toolkits, one for each plugin\n",
    "    tool_kits = [toolkits_dict[d.metadata[\"plugin_name\"]] for d in docs]\n",
    "    # Get the tools: a separate NLAChain for each endpoint\n",
    "    tools = []\n",
    "    for tk in tool_kits:\n",
    "        tools.extend(tk.nla_tools)\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699afd7",
   "metadata": {},
   "source": [
    "We can now test this retriever to see if it seems to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "425f2886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7fa0>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d5f30>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7280>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc214c1c0>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d4670>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\")).\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7730>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connection.py:210\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f7dc20d7730>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7730>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7730>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\"))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mget_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat could I do today with my kiddo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m [t\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mget_tools\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tools\u001b[39m(query):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Get documents, which contain the Plugins to use\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Get the toolkits, one for each plugin\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     tool_kits \u001b[38;5;241m=\u001b[39m [toolkits_dict[d\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplugin_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/vectorstores/base.py:333\u001b[0m, in \u001b[0;36mVectorStoreRetriever.get_relevant_documents\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_relevant_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 333\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    335\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(\n\u001b[1;32m    336\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs\n\u001b[1;32m    337\u001b[0m         )\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:226\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:195\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[0;34m(self, query, k)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    185\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    186\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(embedding, k)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/embeddings/openai.py:280\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/embeddings/openai.py:250\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._embedding_func\u001b[0;34m(self, text, engine)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m001\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# See: https://github.com/openai/openai-python/issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m ]\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/embeddings/openai.py:63\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_embed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/langchain/embeddings/openai.py:61\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages/openai/api_requestor.py:609\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError communicating with OpenAI: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)\n\u001b[1;32m    611\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    612\u001b[0m util\u001b[38;5;241m.\u001b[39mlog_debug(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API response\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     path\u001b[38;5;241m=\u001b[39mabs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m     request_id\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Request-Id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/engines/text-embedding-ada-002/embeddings (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f7dc20d7730>: Failed to resolve 'api.openai.com' ([Errno -3] Temporary failure in name resolution)\"))"
     ]
    }
   ],
   "source": [
    "tools = get_tools(\"What could I do today with my kiddo\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa88768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ambition.search',\n",
       " 'Ambition.details',\n",
       " 'CreatiCode_Scratch_Plugin.getCodeImage',\n",
       " 'CreatiCode_Scratch_Plugin.getListOfAllBlocks',\n",
       " 'CreatiCode_Scratch_Plugin.getBlockDescription',\n",
       " 'Wolfram.getWolframCloudResults',\n",
       " 'Wolfram.getWolframAlphaResults']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_tools(\"what shirts can i buy?\")\n",
    "[t.name for t in tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a075c",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "\n",
    "The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "339b1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583acdc",
   "metadata": {},
   "source": [
    "The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd969d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798ef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a1af3",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "The output parser is unchanged from the previous notebook, since we are not changing anything about the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c6fe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d278706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170587b1",
   "metadata": {},
   "source": [
    "## Set up LLM, stop sequence, and the agent\n",
    "\n",
    "Also the same as the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9d4c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b1cc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4f5092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5326",
   "metadata": {},
   "source": [
    "## Use the Agent\n",
    "\n",
    "Now we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "490604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "653b1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mI'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[38;5;200m\u001b[1;3mI attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mI attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: CreatiCode_Scratch_Plugin.getCodeImage\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[38;5;200m\u001b[1;3mIt looks like you are trying to access an API endpoint that is not valid. Please check the URL you are trying to access and make sure it is correct.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: CreatiCode_Scratch_Plugin.getCodeImage\n",
      "Action Input: shirts\n",
      "Observation: It looks like you are trying to access an API endpoint that is not valid. Please check the URL you are trying to access and make sure it is correct.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframCloudResults\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mI attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a 403 error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: CreatiCode_Scratch_Plugin.getCodeImage\n",
      "Action Input: shirts\n",
      "Observation: It looks like you are trying to access an API endpoint that is not valid. Please check the URL you are trying to access and make sure it is correct.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframCloudResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a 403 error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mI'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: CreatiCode_Scratch_Plugin.getCodeImage\n",
      "Action Input: shirts\n",
      "Observation: It looks like you are trying to access an API endpoint that is not valid. Please check the URL you are trying to access and make sure it is correct.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframCloudResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a 403 error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mI attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
      "\n",
      "Ambition.search: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Search for jobs\n",
      "Ambition.details: I'm an AI from Ambition. Instruct what you want, and I'll assist via an API with description: Return more details about a list of jobs.\n",
      "CreatiCode_Scratch_Plugin.getCodeImage: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the image representations of a program. Also get additional explanation about the programs.\n",
      "CreatiCode_Scratch_Plugin.getListOfAllBlocks: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the list of ALL block IDs so that ChatGPT can decide which blocks to use. This should be the first API to call in each conversation before calling the getBlockDescription API.\n",
      "CreatiCode_Scratch_Plugin.getBlockDescription: I'm an AI from CreatiCode Scratch Plugin. Instruct what you want, and I'll assist via an API with description: Get the pseudocode format and description of blocks with the given IDs so that ChatGPT can learn to correctly use the new blocks defined in the CreatiCode Playground.\n",
      "Wolfram.getWolframCloudResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Evaluate Wolfram Language code\n",
      "Wolfram.getWolframAlphaResults: I'm an AI from Wolfram. Instruct what you want, and I'll assist via an API with description: Get Wolfram|Alpha results\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Ambition.search, Ambition.details, CreatiCode_Scratch_Plugin.getCodeImage, CreatiCode_Scratch_Plugin.getListOfAllBlocks, CreatiCode_Scratch_Plugin.getBlockDescription, Wolfram.getWolframCloudResults, Wolfram.getWolframAlphaResults]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
      "\n",
      "Question: what shirts can i buy?\n",
      "Thought: I need to find a way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframAlphaResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a '403: Forbidden' error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid and up-to-date.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: CreatiCode_Scratch_Plugin.getCodeImage\n",
      "Action Input: shirts\n",
      "Observation: It looks like you are trying to access an API endpoint that is not valid. Please check the URL you are trying to access and make sure it is correct.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Wolfram.getWolframCloudResults\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the Wolfram Alpha API with the query 'shirts', but the API responded with a 403 error. This means that the API is not allowing access to the requested resource. You may need to check your API key and make sure it is valid.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.search\n",
      "Action Input: shirts\n",
      "Observation: I'm sorry, I was unable to connect to the API. It appears that the API is not responding. Please try again later.\n",
      "Thought:  I need to find another way to search for shirts\n",
      "Action: Ambition.details\n",
      "Action Input: shirts\n",
      "Observation: I attempted to call the API at https://api.remoteambition.com/ai/jobs/details with the argument 'ids': 'shirts', but I received a 504: Gateway Time-out error. This means that the server is not responding to the request. Please try again later or contact the API provider for assistance.\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I have exhausted all of my options, so I cannot answer this question\n",
      "Final Answer: Arrr, I be sorry matey, but I can't answer yer question. I've tried me best, but I can't seem to find any shirts.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Arrr, I be sorry matey, but I can't answer yer question. I've tried me best, but I can't seem to find any shirts.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what shirts can i buy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481ee76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ccef4e08d87aa1eeb90f63e0f071292ccb2e9c42e70f74ab2bf6f5493ca7bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
