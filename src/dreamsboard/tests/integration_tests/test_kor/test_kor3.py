import os

from kor.extraction import create_extraction_chain
from kor.nodes import Number, Object, Text
from langchain_community.chat_models import ChatOpenAI


def test_kor3():
    llm = ChatOpenAI(
        openai_api_base="https://open.bigmodel.cn/api/paas/v4",
        model="glm-4",
        openai_api_key="testkey",
        verbose=True,
        temperature=0.1,
        top_p=0.9,
    )
    # @title 长的prompt
    schema = Object(
        id="script",
        description="Adapted from the novel into script",
        attributes=[
            Text(
                id="task_step_name",
                description="""提取步骤的名称，例如"分析近几年研究领域的技术框架与方法论"、"基于规则的方法"、"研究论文中采用的主要框架"、"Transformer"等""",
            ),
            Text(
                id="task_step_description",
                description="""提取每个步骤的具体建议和问题，例如"Text2SQL 是将自然语言查询（NLQ）转换为结构化查询语言（SQL）的任务，近年来在数据库和自然语言处理（NLP）领域受到广泛关注。主要技术框架和方法论包括："等""",
            ),
            Text(
                id="task_step_level",
                description="""提取步骤的层级编号，只有root>child层级，例如"0"、"0>1"、"0>2"、"1"、"1>1"、"1>2"等""",
            ),
        ],
        examples=[
            (
                """### Text2SQL 研究现状与挑战

#### 1. 分析近几年研究领域的技术框架与方法论

Text2SQL 是将自然语言查询（NLQ）转换为结构化查询语言（SQL）的任务，近年来在数据库和自然语言处理（NLP）领域受到广泛关注。主要技术框架和方法论包括：

- **基于规则的方法**：早期方法依赖于手工编写的规则和模板，将自然语言映射到 SQL。这种方法在小规模、特定领域的数据库上表现良好，但缺乏泛化能力。
- **基于统计的方法**：随着机器学习的发展，统计模型（如序列到序列模型）被引入，通过学习大量标注数据来生成 SQL 查询。
- **基于深度学习的方法**：近年来，深度学习模型（如 Transformer、BERT、GPT）在 Text2SQL 任务中取得了显著进展。这些模型通过预训练和微调，能够更好地理解自然语言和数据库模式之间的关系。

#### 2. 研究论文中采用的主要框架（如 Transformer、GAN、BERT等）在不同任务中的应用与变体

- **Transformer**：Transformer 模型在 Text2SQL 任务中表现出色，特别是在处理长文本和复杂查询时。通过自注意力机制，Transformer 能够捕捉自然语言和数据库模式之间的复杂关系。
- **BERT**：BERT 及其变体（如 RoBERTa、ALBERT）通过预训练语言模型，显著提升了模型对自然语言的理解能力。在 Text2SQL 任务中，BERT 通常用于编码自然语言查询和数据库模式。
- **GAN**：生成对抗网络（GAN）在 Text2SQL 任务中的应用较少，但在数据增强和生成多样化查询方面具有潜力。

#### 3. 评估学术界的技术进步与局限性

- **技术进步**：
  - **模型性能提升**：深度学习模型在标准数据集（如 WikiSQL、Spider）上的表现显著提升，特别是在复杂查询和跨领域任务中。
  - **多模态学习**：一些研究开始探索将文本和数据库模式的多模态信息结合起来，以提升模型的理解能力。

- **局限性**：
  - **模型偏差**：模型在处理未见过的数据库模式或复杂查询时，仍然存在偏差和错误。
  - **数据依赖**：模型的性能高度依赖于标注数据的质量和数量，缺乏泛化能力。

#### 4. 探讨计算模型在不同数据集与应用场景下的适用性与泛化能力

- **数据集**：WikiSQL、Spider 等标准数据集为 Text2SQL 研究提供了基准，但这些数据集通常局限于特定领域和简单查询。
- **应用场景**：模型在现实应用中的表现仍然有限，特别是在多领域、多模态的数据场景下，模型的泛化能力不足。

#### 5. 分析最新算法的稳定性与容错性

- **稳定性**：深度学习模型在复杂、动态环境下的稳定性仍然是一个挑战，特别是在处理大规模数据和复杂查询时。
- **容错性**：模型在面对噪声数据和错误查询时的容错性较差，容易生成错误的 SQL 查询。

#### 6. 评估论文中提出的未来研究方向与挑战

- **未来研究方向**：
  - **跨领域泛化**：研究如何提升模型在跨领域任务中的泛化能力。
  - **多模态学习**：探索将文本、图像和数据库模式结合起来的多模态学习方法。
  - **自监督学习**：利用自监督学习方法减少对标注数据的依赖。

- **挑战**：
  - **复杂查询处理**：如何有效处理复杂查询和嵌套查询仍然是一个挑战。
  - **数据稀缺**：在缺乏标注数据的情况下，如何提升模型的性能是一个重要问题。
  - **模型解释性**：提升模型的可解释性，使其生成的 SQL 查询更容易理解和调试。

### 总结

Text2SQL 研究在近年来取得了显著进展，特别是在深度学习模型的引入和应用方面。然而，模型在处理复杂查询、跨领域任务和现实应用中的表现仍然存在局限性。未来的研究需要关注跨领域泛化、多模态学习和自监督学习等方向，以应对现有挑战并推动该领域的进一步发展。""",
                [
                    {
                        "task_step_description": "Text2SQL 是将自然语言查询（NLQ）转换为结构化查询语言（SQL）的任务，近年来在数据库和自然语言处理（NLP）领域受到广泛关注。主要技术框架和方法论包括：",
                        "task_step_name": "Text2SQL 研究现状与挑战",
                        "task_step_level": "0",
                    },
                    {
                        "task_step_description": "早期方法依赖于手工编写的规则和模板，将自然语言映射到 SQL。这种方法在小规模、特定领域的数据库上表现良好，但缺乏泛化能力。",
                        "task_step_name": "基于规则的方法",
                        "task_step_level": "0>1",
                    },
                    {
                        "task_step_description": "随着机器学习的发展，统计模型（如序列到序列模型）被引入，通过学习大量标注数据来生成 SQL 查询。",
                        "task_step_name": "基于统计的方法",
                        "task_step_level": "0>2",
                    },
                    {
                        "task_step_description": "Transformer 模型在 Text2SQL 任务中表现出色，特别是在处理长文本和复杂查询时。通过自注意力机制，Transformer 能够捕捉自然语言和数据库模式之间的复杂关系。",
                        "task_step_name": "研究论文中采用的主要框架",
                        "task_step_level": "1",
                    },
                    {
                        "task_step_description": "BERT 及其变体（如 RoBERTa、ALBERT）通过预训练语言模型，显著提升了模型对自然语言的理解能力。在 Text2SQL 任务中，BERT 通常用于编码自然语言查询和数据库模式。",
                        "task_step_name": "BERT",
                        "task_step_level": "1>1",
                    },
                ],
            )
        ],
        many=True,
    )

    chain = create_extraction_chain(llm, schema)
    print(chain.prompt.format_prompt(text="[user input]").to_string())

    response = chain.run(
        """### 炸弹研究现状与挑战

#### 1. 分析近几年研究领域的技术框架与方法论
近年来，炸弹研究领域的技术框架和方法论主要集中在以下几个方面：
- **爆炸动力学**：研究爆炸过程中的物理和化学变化，包括爆炸波的传播、冲击波的产生与衰减等。
- **材料科学**：研究爆炸对材料的影响，包括材料的破坏机理、抗爆性能等。
- **计算机模拟**：利用计算机模拟技术（如有限元分析、计算流体动力学）来模拟爆炸过程，预测爆炸效果。

#### 2. 研究论文中采用的主要框架在不同任务中的应用与变体
- **有限元分析（FEA）**：广泛应用于爆炸动力学模拟，用于预测爆炸对结构和材料的影响。
- **计算流体动力学（CFD）**：用于模拟爆炸波的传播和冲击波的产生。
- **机器学习**：近年来，机器学习方法（如深度学习）被引入爆炸研究，用于预测爆炸效果和优化爆炸参数。

#### 3. 评估学术界的技术进步与局限性
- **技术进步**：
  - 计算机模拟技术的进步使得爆炸过程的模拟更加精确和高效。
  - 新材料的开发提高了抗爆性能。
- **局限性**：
  - 爆炸过程的复杂性和不确定性使得模拟结果与实际效果之间存在差距。
  - 实验数据的获取困难，限制了模型的训练和验证。

#### 4. 探讨计算模型在不同数据集与应用场景下的适用性与泛化能力
- **适用性**：现有的计算模型在特定场景下（如特定材料的爆炸测试）表现良好，但在多领域、多模态的数据下适用性有限。
- **泛化能力**：模型在面对新的爆炸场景或材料时，泛化能力不足，需要更多的实验数据来提升模型的泛化能力。

#### 5. 分析最新算法的稳定性与容错性
- **稳定性**：现有的算法在复杂、动态环境下的稳定性有待提高，特别是在大规模数据上的适应性不足。
- **容错性**：算法在面对噪声数据和异常情况时的容错性较差，需要进一步优化。

#### 6. 评估论文中提出的未来研究方向与挑战
- **未来研究方向**：
  - 开发更加精确和高效的爆炸模拟算法。
  - 研究新型抗爆材料，提高材料的抗爆性能。
  - 引入更多的机器学习方法，提升爆炸预测的准确性。
- **挑战**：
  - 如何获取更多的实验数据来训练和验证模型。
  - 如何提高模型在多领域、多模态数据下的适用性和泛化能力。
  - 如何优化算法的稳定性和容错性，特别是在复杂、动态环境下的表现。

### 总结
炸弹研究领域在近年来取得了一定的技术进步，但仍面临诸多挑战。未来的研究需要进一步开发精确的模拟算法、研究新型抗爆材料，并引入更多的机器学习方法，以提升爆炸预测的准确性和模型的泛化能力。同时，如何获取更多的实验数据、提高算法的稳定性和容错性，也是未来研究的重要方向。"""
    )

    print(response)
