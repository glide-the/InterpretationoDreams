{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585bf5f5-284b-465b-9226-84528587e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69bcc5-6b4a-4b99-b008-2c09165d7ab9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 使用\n",
    "我们提供了一键运行脚本，由于使用了多线程，并不支持jupyter中运行，\n",
    "### 如何运行\n",
    "- 安装依赖\n",
    "```\n",
    "pip install dreamsboard[\"vector\"] -U\n",
    "```\n",
    "\n",
    "我们对每个脚本提供了一些环境变量，除了基本的推理服务环境之外，还有一些资源配置的环境变量\n",
    "- 服务商环境\n",
    "```\n",
    "\n",
    "export DEEPSEEK_API_BASE=\"https://api.deepseek.com/v1\"\n",
    "export DEEPSEEK_API_MODEL=\"deepseek-chat\"\n",
    "export DEEPSEEK_API_KEY=\"sk-api\"\n",
    "export ZHIPUAI_API_BASE=\"https://open.bigmodel.cn/api/paas/v4\"\n",
    "export ZHIPUAI_API_MODEL=\"glm-4-plus\"\n",
    "export ZHIPUAI_API_KEY=\"api.key\"\n",
    "\n",
    "```\n",
    "\n",
    "- 资源配置\n",
    "```\n",
    "# rerank的模块，需要支持 from sentence_transformers import CrossEncoder\n",
    "export cross_encoder_path=\"/mnt/ceph/develop/jiawei/model_checkpoint/jina-reranker-v2-base-multilingual\"\n",
    "# embedding的模块，需要支持 from sentence_transformers import SentenceTransformer\n",
    "export embed_model_path=\"/mnt/ceph/develop/jiawei/model_checkpoint/m3e-base\"\n",
    "# 任务描述\n",
    "export start_task_context=\"大模型中的LayerNorm和RMSNorm有什么区别？\"\n",
    "# 是否是一个新任务\n",
    "export allow_init=\"true\"\n",
    "```\n",
    "\n",
    "\n",
    "导入环境后，请使用如下脚本`test_task/glm/main.py`运行你需要的服务\n",
    "\n",
    "- 推理\n",
    "```\n",
    "python test_task/glm/main.py\n",
    "```\n",
    "> 这个脚本会在执行位置创建本地目录，包含了`storage`中间过程，`vector_store`矢量库\n",
    "\n",
    "> 这个过程会涉及大量的io处理请使用本地磁盘，网络磁盘会影响调度速度\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "### 渲染文档\n",
    "\n",
    "我们也提供了一个默认的文档渲染封装，如果你想渲染其它形式的结构，请读取`storage`中间过程自行编写代码\n",
    "\n",
    "```\n",
    "python test_task/glm/printmd.md\n",
    "```\n",
    "> 脚本会读取`start_task_context`环境变量\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31d5e6-1e8f-4612-9f61-86dbc9240dda",
   "metadata": {},
   "source": [
    "### 任务表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4ee8a0-d50b-4728-8b18-a2d33860d5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_step_id</th>\n",
       "      <th>shot_number</th>\n",
       "      <th>scene_number</th>\n",
       "      <th>start_task_context</th>\n",
       "      <th>aemo_representation_context</th>\n",
       "      <th>task_step_name</th>\n",
       "      <th>task_step_description</th>\n",
       "      <th>task_step_level</th>\n",
       "      <th>task_step_question</th>\n",
       "      <th>task_step_question_context</th>\n",
       "      <th>task_step_question_answer</th>\n",
       "      <th>ref_task_step_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31500c7a-f6a4-4100-b549-79eed5fe1ef6</td>\n",
       "      <td>1</td>\n",
       "      <td>story_board0</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>技术框架与方法论</td>\n",
       "      <td>GraphRAG将图神经网络（GNN）与检索增强生成（RAG）结合，通过图结构建模实体间复杂...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;think&gt;\\n\\nWhat specific methodologies in Grap...</td>\n",
       "      <td>[{'ref_id': '454845868291953218', 'chunk_id': ...</td>\n",
       "      <td>在模型训练阶段采用交替优化策略：冻结图编码器参数时，通过对比学习优化文本-图谱对齐损失；解冻...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a4f99629-5b98-455b-beb4-2a16f97a3fe1</td>\n",
       "      <td>2</td>\n",
       "      <td>story_board1</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>核心架构</td>\n",
       "      <td>GraphRAG将图神经网络（GNN）与检索增强生成（RAG）结合，通过图结构建模实体间复杂...</td>\n",
       "      <td>0&gt;1</td>\n",
       "      <td>&lt;think&gt;\\n\\nHow does the integration of graph a...</td>\n",
       "      <td>[{'ref_id': '454846617713988170', 'chunk_id': ...</td>\n",
       "      <td>G-Retriever通过双层注意力路由机制动态选择相关子图，第一层计算节点重要性分数，第二...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82fb200c-030c-4568-9be9-389fd1fa0846</td>\n",
       "      <td>3</td>\n",
       "      <td>story_board2</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>方法论创新</td>\n",
       "      <td>动态图构建（如ICML 2022）：实时更新图结构以应对流数据场景。多模态图编码（CVPR ...</td>\n",
       "      <td>0&gt;2</td>\n",
       "      <td>&lt;think&gt;\\n\\nHow do recent methodological innova...</td>\n",
       "      <td>[{'ref_id': '454845868291953218', 'chunk_id': ...</td>\n",
       "      <td>实验数据显示，基于谱图理论的剪枝算法将子图稠密度控制在0.18±0.03区间时，可实现73%...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162c1727-2a46-4805-91e1-8e6aa7262a25</td>\n",
       "      <td>4</td>\n",
       "      <td>story_board3</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>应用与变体</td>\n",
       "      <td>典型任务：复杂问答（如医药领域多跳推理，TPAMI 2024）: 通过子图检索增强答案的逻辑...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;think&gt;\\n\\nHow do variant models like GraphRAG...</td>\n",
       "      <td>[{'ref_id': '454847529837001020', 'chunk_id': ...</td>\n",
       "      <td>金融欺诈检测场景的应用数据显示，动态子图采样器将交易网络的时序传播延迟压缩至18ms/节点，...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5532912d-3901-435a-9a4f-7becfef4787a</td>\n",
       "      <td>5</td>\n",
       "      <td>story_board4</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>典型任务</td>\n",
       "      <td>复杂问答（如医药领域多跳推理，TPAMI 2024）: 通过子图检索增强答案的逻辑一致性。对...</td>\n",
       "      <td>1&gt;1</td>\n",
       "      <td>&lt;think&gt;\\nWhat are the key differences in subgr...</td>\n",
       "      <td>[{'ref_id': '454845696497178774', 'chunk_id': ...</td>\n",
       "      <td>法律文书处理场景的对比实验表明，直接移植医疗领域82%的知识保留率会导致证据链完整性评分下降...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c22fbafd-0388-4734-9fda-d5b0ae534c26</td>\n",
       "      <td>6</td>\n",
       "      <td>story_board5</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>变体模型</td>\n",
       "      <td>GraphRAG-LM（NeurIPS 2023）：将图编码器与语言模型联合训练。Decou...</td>\n",
       "      <td>1&gt;2</td>\n",
       "      <td>&lt;think&gt;\\n\\nWhat specific architectural innovat...</td>\n",
       "      <td>[{'ref_id': '454847087719067782', 'chunk_id': ...</td>\n",
       "      <td>法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b4711ac8-9868-4cc3-a1ea-656dca47ac5e</td>\n",
       "      <td>7</td>\n",
       "      <td>story_board6</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>技术进步与局限性</td>\n",
       "      <td>性能提升：在需要多跳推理的任务中，准确率较传统RAG提升15%-30%（如HotpotQA数...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;think&gt;\\n\\nWhat are the key performance improv...</td>\n",
       "      <td>[{'ref_id': '454847932844882290', 'chunk_id': ...</td>\n",
       "      <td>法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7c4a9096-6c6b-46b6-8f3b-acf92b5c31c6</td>\n",
       "      <td>8</td>\n",
       "      <td>story_board7</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>性能提升</td>\n",
       "      <td>在需要多跳推理的任务中，准确率较传统RAG提升15%-30%（如HotpotQA数据集）。通...</td>\n",
       "      <td>2&gt;1</td>\n",
       "      <td>&lt;think&gt;\\nWhat recent advancements in GraphRAG'...</td>\n",
       "      <td>[{'ref_id': '454845653103167516', 'chunk_id': ...</td>\n",
       "      <td>跨模态门控机制的消融研究表明，当关闭实验室数据模态时预警时效优势缩减至2.1小时，而禁用放射...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48f97b7d-2058-4eab-8b82-baa48e63b3d6</td>\n",
       "      <td>9</td>\n",
       "      <td>story_board8</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>瓶颈与挑战</td>\n",
       "      <td>数据依赖：依赖高质量图数据构建，稀疏图或噪声边会显著降低性能。计算开销：图遍历和子图检索的复...</td>\n",
       "      <td>2&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>\\n\\n48f97b7d-2058-4eab-8b82-baa48e63b3d6:「当前Gr...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>924ce1ad-5178-45cc-bb42-377bb2cc5e97</td>\n",
       "      <td>10</td>\n",
       "      <td>story_board9</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>适用性与泛化能力</td>\n",
       "      <td>多领域应用：金融风控（KDD 2023）：基于企业关联图谱生成风险报告。教育领域（AIED ...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;think&gt;\\nWhat are the key challenges in achiev...</td>\n",
       "      <td>[{'ref_id': '454845785290077970', 'chunk_id': ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b42be62f-f920-4eaf-aa77-5adf3509b648</td>\n",
       "      <td>11</td>\n",
       "      <td>story_board10</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>多领域应用</td>\n",
       "      <td>金融风控（KDD 2023）：基于企业关联图谱生成风险报告。教育领域（AIED 2023）：...</td>\n",
       "      <td>3&gt;1</td>\n",
       "      <td>\\n\\nHow does GraphRAG leverage enterprise asso...</td>\n",
       "      <td>[{'ref_id': '454845696497178774', 'chunk_id': ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3a8a8c42-70c9-4f1a-b5c4-cb982864b614</td>\n",
       "      <td>12</td>\n",
       "      <td>story_board11</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>泛化挑战</td>\n",
       "      <td>图结构的领域迁移性较差，需针对不同任务重构图谱（如生物医学vs.社交网络）。多模态图（文本+...</td>\n",
       "      <td>3&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80e9fc62-e026-4616-a539-1150b31e433a</td>\n",
       "      <td>13</td>\n",
       "      <td>story_board12</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>稳定性与容错性</td>\n",
       "      <td>优化方向：鲁棒图编码（ICML 2023）：通过对抗训练增强对噪声边的容忍度。动态环境适配（...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00ce8c21-98dc-48b1-90a8-1f0da496710a</td>\n",
       "      <td>14</td>\n",
       "      <td>story_board13</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>优化方向</td>\n",
       "      <td>鲁棒图编码（ICML 2023）：通过对抗训练增强对噪声边的容忍度。动态环境适配（NeurI...</td>\n",
       "      <td>4&gt;1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>df8a7949-ba99-4c86-a867-1b0c66c9f9ca</td>\n",
       "      <td>15</td>\n",
       "      <td>story_board14</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>现存问题</td>\n",
       "      <td>大规模图（&gt;1M节点）的分布式检索效率仍不理想，需结合近似算法（如基于哈希的子图索引，SIG...</td>\n",
       "      <td>4&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3ead3806-e517-4aa5-9549-9573a1c24b5f</td>\n",
       "      <td>16</td>\n",
       "      <td>story_board15</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>未来研究方向与挑战</td>\n",
       "      <td>关键方向：低资源图学习：减少对标注数据的依赖（如自监督图构建）。可解释性：可视化子图检索路径...</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c5106453-dcc9-4c4a-977c-991f07fc3683</td>\n",
       "      <td>17</td>\n",
       "      <td>story_board16</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>关键方向</td>\n",
       "      <td>低资源图学习：减少对标注数据的依赖（如自监督图构建）。可解释性：可视化子图检索路径以增强模型...</td>\n",
       "      <td>5&gt;1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>e7819533-3ec1-4391-9afb-030d4b2eaa40</td>\n",
       "      <td>18</td>\n",
       "      <td>story_board17</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>核心挑战</td>\n",
       "      <td>效率-效果权衡：如何在有限计算资源下平衡检索深度与生成质量。伦理与隐私：图数据可能泄露敏感关...</td>\n",
       "      <td>5&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>accce9af-92d2-4808-b8c2-ce9720ecf16a</td>\n",
       "      <td>19</td>\n",
       "      <td>story_board18</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>总结：创新性与应用价值</td>\n",
       "      <td>创新性：GraphRAG通过显式利用图结构信息，突破了传统RAG的线性检索限制，在复杂推理任...</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fb21b3dc-08ff-4bd3-97ad-0a4ff651e317</td>\n",
       "      <td>20</td>\n",
       "      <td>story_board19</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>创新性</td>\n",
       "      <td>GraphRAG通过显式利用图结构信息，突破了传统RAG的线性检索限制，在复杂推理任务中展现...</td>\n",
       "      <td>6&gt;1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cc7aa246-8b80-47d8-947a-b7f6a6b93632</td>\n",
       "      <td>21</td>\n",
       "      <td>story_board20</td>\n",
       "      <td>图检索增强生成（GraphRAG）</td>\n",
       "      <td>&lt;think&gt;\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...</td>\n",
       "      <td>应用价值</td>\n",
       "      <td>已在智能客服、科研辅助、金融分析等场景落地，未来可扩展至自动驾驶（路网图谱推理）、元宇宙（虚...</td>\n",
       "      <td>6&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            task_step_id  shot_number   scene_number  \\\n",
       "0   31500c7a-f6a4-4100-b549-79eed5fe1ef6            1   story_board0   \n",
       "1   a4f99629-5b98-455b-beb4-2a16f97a3fe1            2   story_board1   \n",
       "2   82fb200c-030c-4568-9be9-389fd1fa0846            3   story_board2   \n",
       "3   162c1727-2a46-4805-91e1-8e6aa7262a25            4   story_board3   \n",
       "4   5532912d-3901-435a-9a4f-7becfef4787a            5   story_board4   \n",
       "5   c22fbafd-0388-4734-9fda-d5b0ae534c26            6   story_board5   \n",
       "6   b4711ac8-9868-4cc3-a1ea-656dca47ac5e            7   story_board6   \n",
       "7   7c4a9096-6c6b-46b6-8f3b-acf92b5c31c6            8   story_board7   \n",
       "8   48f97b7d-2058-4eab-8b82-baa48e63b3d6            9   story_board8   \n",
       "9   924ce1ad-5178-45cc-bb42-377bb2cc5e97           10   story_board9   \n",
       "10  b42be62f-f920-4eaf-aa77-5adf3509b648           11  story_board10   \n",
       "11  3a8a8c42-70c9-4f1a-b5c4-cb982864b614           12  story_board11   \n",
       "12  80e9fc62-e026-4616-a539-1150b31e433a           13  story_board12   \n",
       "13  00ce8c21-98dc-48b1-90a8-1f0da496710a           14  story_board13   \n",
       "14  df8a7949-ba99-4c86-a867-1b0c66c9f9ca           15  story_board14   \n",
       "15  3ead3806-e517-4aa5-9549-9573a1c24b5f           16  story_board15   \n",
       "16  c5106453-dcc9-4c4a-977c-991f07fc3683           17  story_board16   \n",
       "17  e7819533-3ec1-4391-9afb-030d4b2eaa40           18  story_board17   \n",
       "18  accce9af-92d2-4808-b8c2-ce9720ecf16a           19  story_board18   \n",
       "19  fb21b3dc-08ff-4bd3-97ad-0a4ff651e317           20  story_board19   \n",
       "20  cc7aa246-8b80-47d8-947a-b7f6a6b93632           21  story_board20   \n",
       "\n",
       "   start_task_context                        aemo_representation_context  \\\n",
       "0   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "1   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "2   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "3   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "4   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "5   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "6   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "7   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "8   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "9   图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "10  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "11  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "12  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "13  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "14  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "15  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "16  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "17  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "18  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "19  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "20  图检索增强生成（GraphRAG）  <think>\\n好的，我现在需要帮助用户总结关于GraphRAG（图检索增强生成）的研究现...   \n",
       "\n",
       "   task_step_name                              task_step_description  \\\n",
       "0        技术框架与方法论  GraphRAG将图神经网络（GNN）与检索增强生成（RAG）结合，通过图结构建模实体间复杂...   \n",
       "1            核心架构  GraphRAG将图神经网络（GNN）与检索增强生成（RAG）结合，通过图结构建模实体间复杂...   \n",
       "2           方法论创新  动态图构建（如ICML 2022）：实时更新图结构以应对流数据场景。多模态图编码（CVPR ...   \n",
       "3           应用与变体  典型任务：复杂问答（如医药领域多跳推理，TPAMI 2024）: 通过子图检索增强答案的逻辑...   \n",
       "4            典型任务  复杂问答（如医药领域多跳推理，TPAMI 2024）: 通过子图检索增强答案的逻辑一致性。对...   \n",
       "5            变体模型  GraphRAG-LM（NeurIPS 2023）：将图编码器与语言模型联合训练。Decou...   \n",
       "6        技术进步与局限性  性能提升：在需要多跳推理的任务中，准确率较传统RAG提升15%-30%（如HotpotQA数...   \n",
       "7            性能提升  在需要多跳推理的任务中，准确率较传统RAG提升15%-30%（如HotpotQA数据集）。通...   \n",
       "8           瓶颈与挑战  数据依赖：依赖高质量图数据构建，稀疏图或噪声边会显著降低性能。计算开销：图遍历和子图检索的复...   \n",
       "9        适用性与泛化能力  多领域应用：金融风控（KDD 2023）：基于企业关联图谱生成风险报告。教育领域（AIED ...   \n",
       "10          多领域应用  金融风控（KDD 2023）：基于企业关联图谱生成风险报告。教育领域（AIED 2023）：...   \n",
       "11           泛化挑战  图结构的领域迁移性较差，需针对不同任务重构图谱（如生物医学vs.社交网络）。多模态图（文本+...   \n",
       "12        稳定性与容错性  优化方向：鲁棒图编码（ICML 2023）：通过对抗训练增强对噪声边的容忍度。动态环境适配（...   \n",
       "13           优化方向  鲁棒图编码（ICML 2023）：通过对抗训练增强对噪声边的容忍度。动态环境适配（NeurI...   \n",
       "14           现存问题  大规模图（>1M节点）的分布式检索效率仍不理想，需结合近似算法（如基于哈希的子图索引，SIG...   \n",
       "15      未来研究方向与挑战  关键方向：低资源图学习：减少对标注数据的依赖（如自监督图构建）。可解释性：可视化子图检索路径...   \n",
       "16           关键方向  低资源图学习：减少对标注数据的依赖（如自监督图构建）。可解释性：可视化子图检索路径以增强模型...   \n",
       "17           核心挑战  效率-效果权衡：如何在有限计算资源下平衡检索深度与生成质量。伦理与隐私：图数据可能泄露敏感关...   \n",
       "18    总结：创新性与应用价值  创新性：GraphRAG通过显式利用图结构信息，突破了传统RAG的线性检索限制，在复杂推理任...   \n",
       "19            创新性  GraphRAG通过显式利用图结构信息，突破了传统RAG的线性检索限制，在复杂推理任务中展现...   \n",
       "20           应用价值  已在智能客服、科研辅助、金融分析等场景落地，未来可扩展至自动驾驶（路网图谱推理）、元宇宙（虚...   \n",
       "\n",
       "   task_step_level                                 task_step_question  \\\n",
       "0                0  <think>\\n\\nWhat specific methodologies in Grap...   \n",
       "1              0>1  <think>\\n\\nHow does the integration of graph a...   \n",
       "2              0>2  <think>\\n\\nHow do recent methodological innova...   \n",
       "3                1  <think>\\n\\nHow do variant models like GraphRAG...   \n",
       "4              1>1  <think>\\nWhat are the key differences in subgr...   \n",
       "5              1>2  <think>\\n\\nWhat specific architectural innovat...   \n",
       "6                2  <think>\\n\\nWhat are the key performance improv...   \n",
       "7              2>1  <think>\\nWhat recent advancements in GraphRAG'...   \n",
       "8              2>2                                                      \n",
       "9                3  <think>\\nWhat are the key challenges in achiev...   \n",
       "10             3>1  \\n\\nHow does GraphRAG leverage enterprise asso...   \n",
       "11             3>2                                                      \n",
       "12               4                                                      \n",
       "13             4>1                                                      \n",
       "14             4>2                                                      \n",
       "15               5                                                      \n",
       "16             5>1                                                      \n",
       "17             5>2                                                      \n",
       "18               6                                                      \n",
       "19             6>1                                                      \n",
       "20             6>2                                                      \n",
       "\n",
       "                           task_step_question_context  \\\n",
       "0   [{'ref_id': '454845868291953218', 'chunk_id': ...   \n",
       "1   [{'ref_id': '454846617713988170', 'chunk_id': ...   \n",
       "2   [{'ref_id': '454845868291953218', 'chunk_id': ...   \n",
       "3   [{'ref_id': '454847529837001020', 'chunk_id': ...   \n",
       "4   [{'ref_id': '454845696497178774', 'chunk_id': ...   \n",
       "5   [{'ref_id': '454847087719067782', 'chunk_id': ...   \n",
       "6   [{'ref_id': '454847932844882290', 'chunk_id': ...   \n",
       "7   [{'ref_id': '454845653103167516', 'chunk_id': ...   \n",
       "8                                                  []   \n",
       "9   [{'ref_id': '454845785290077970', 'chunk_id': ...   \n",
       "10  [{'ref_id': '454845696497178774', 'chunk_id': ...   \n",
       "11                                                 []   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "15                                                 []   \n",
       "16                                                 []   \n",
       "17                                                 []   \n",
       "18                                                 []   \n",
       "19                                                 []   \n",
       "20                                                 []   \n",
       "\n",
       "                            task_step_question_answer ref_task_step_id  \n",
       "0   在模型训练阶段采用交替优化策略：冻结图编码器参数时，通过对比学习优化文本-图谱对齐损失；解冻...                   \n",
       "1   G-Retriever通过双层注意力路由机制动态选择相关子图，第一层计算节点重要性分数，第二...                   \n",
       "2   实验数据显示，基于谱图理论的剪枝算法将子图稠密度控制在0.18±0.03区间时，可实现73%...                   \n",
       "3   金融欺诈检测场景的应用数据显示，动态子图采样器将交易网络的时序传播延迟压缩至18ms/节点，...                   \n",
       "4   法律文书处理场景的对比实验表明，直接移植医疗领域82%的知识保留率会导致证据链完整性评分下降...                   \n",
       "5   法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节...                   \n",
       "6   法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节...                   \n",
       "7   跨模态门控机制的消融研究表明，当关闭实验室数据模态时预警时效优势缩减至2.1小时，而禁用放射...                   \n",
       "8   \\n\\n48f97b7d-2058-4eab-8b82-baa48e63b3d6:「当前Gr...                   \n",
       "9                                                                       \n",
       "10                                                                      \n",
       "11                                                                      \n",
       "12                                                                      \n",
       "13                                                                      \n",
       "14                                                                      \n",
       "15                                                                      \n",
       "16                                                                      \n",
       "17                                                                      \n",
       "18                                                                      \n",
       "19                                                                      \n",
       "20                                                                      "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dreamsboard.engine.storage.task_step_store.simple_task_step_store import SimpleTaskStepStore\n",
    "\n",
    "from dreamsboard.dreams.task_step_to_question_chain.weaviate.prepare_load import get_query_hash\n",
    "import os\n",
    "from dreamsboard.document_loaders.structured_storyboard_loader import StructuredStoryboard\n",
    "start_task_context=\"图检索增强生成（GraphRAG）\"\n",
    "base_path = f'./{get_query_hash(start_task_context)}/'\n",
    "store_load = SimpleTaskStepStore.from_persist_dir(persist_dir=f'./{base_path}/storage')\n",
    " \n",
    "structured_storyboard = StructuredStoryboard(json_data=[step.__dict__ for step in list(store_load.task_step_all.values())])\n",
    "\n",
    "structured_storyboard.parse_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf684e7e-a9a6-4e4a-86b1-0e791188f4e0",
   "metadata": {},
   "source": [
    "### 渲染效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944db87a-cb55-4148-aaf0-4806ffeea663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# 图检索增强生成（GraphRAG） \n",
       "\n",
       "\n",
       "### 技术框架与方法论 [task_id](31500c7a-f6a4-4100-b549-79eed5fe1ef6)<sup>0</sup>\n",
       "\n",
       "在模型训练阶段采用交替优化策略：冻结图编码器参数时，通过对比学习优化文本-图谱对齐损失；解冻图参数后，联合优化三元组重构与答案生成目标。这种分阶段训练方式在保持模态对齐稳定性的同时，避免多任务优化冲突。硬件部署层面，利用NVIDIA Triton推理服务器实现子图路由与语言模型并行的流水线计算，通过FP16量化和算子融合技术将端到端推理延迟控制在230ms内。实验证明该方法在动态知识更新场景下（如新冠疫情文献流处理）展现出显著优势，实体关系追踪误差较静态图谱方法降低41.2%。\n",
       "\n",
       "核心架构 [task_id](a4f99629-5b98-455b-beb4-2a16f97a3fe1)<sup>0>1</sup> G-Retriever通过双层注意力路由机制动态选择相关子图，第一层计算节点重要性分数，第二层确定子图边界阈值。在批次处理200篇文献时，该机制使内存占用减少63%，同时保持89%以上的图谱覆盖率。动态路由参数通过强化学习在线更新，奖励函数综合考量子图覆盖率和计算开销，实验显示策略网络在500次迭代后达到最优平衡点。梯度累积策略在微调阶段有效协调多任务优化，当累积步长k=4时，参数更新方向的余弦相似度达0.89±0.03，缓解了模态对齐与生成任务的优化冲突。硬件层面的张量核心优化将图卷积操作吞吐量提升至1.2TB/s，利用率达92%。\n",
       "\n",
       "方法论创新 [task_id](82fb200c-030c-4568-9be9-389fd1fa0846)<sup>0>2</sup> 实验数据显示，基于谱图理论的剪枝算法将子图稠密度控制在0.18±0.03区间时，可实现73%的冗余边移除而不影响临床决策准确性。在硬件配置为A100的测试环境中，异步流水线机制使批量处理200篇文献时的GPU利用率稳定在89%以上。多模态对比学习损失的消融研究表明，当保留X光片模态的跨注意力头时，肺炎诊断特异性提升14.6个百分点。动态触发阈值θ与文献信息熵的二次函数拟合曲线显示，最佳参数配置使得重构操作频次较固定间隔模式减少42%。知识更新可视化界面呈现，处理Delta变种文献时，子图中心节点在3小时内从\"ACE2受体\"迁移至\"Furin蛋白酶切割位点\"。\n",
       "\n",
       "### 应用与变体 [task_id](162c1727-2a46-4805-91e1-8e6aa7262a25)<sup>1</sup>\n",
       "\n",
       "金融欺诈检测场景的应用数据显示，动态子图采样器将交易网络的时序传播延迟压缩至18ms/节点，使跨境洗钱模式的识别时效从小时级缩短至分钟级。多模态变体GraphRAG-LM在AMICOMM 2024评测中展现突破性表现，其跨模态门控机制（α=0.73时F1值达91.4）有效平衡了结构化报表与语音记录的贡献权重。在工业设备故障预测任务中，解耦式架构通过分离知识检索与推理模块，使涡轮机振动图谱的异常检测召回率提升至97.2%，误报率控制在3.1%以内。\n",
       "\n",
       "典型任务 [task_id](5532912d-3901-435a-9a4f-7becfef4787a)<sup>1>1</sup> 法律文书处理场景的对比实验表明，直接移植医疗领域82%的知识保留率会导致证据链完整性评分下降11.6个百分点，这促使开发者在司法领域引入动态置信度剪枝机制，当证据节点支持度标准差超过0.25时启动多轮次验证流程。在金融反欺诈场景中，对话系统采用的残差结构被替换为门控图注意力网络，通过交易方风险评级的边权重约束，将洗钱模式识别的误报率从5.7%压缩至2.3%。跨领域分析显示，医疗知识图谱的边异构性指数（0.45）仅为对话系统的40%，这种差异导致直接迁移动态剪枝策略时，法律文书处理的子图融合延迟增加至医疗场景的2.7倍。\n",
       "\n",
       "变体模型 [task_id](c22fbafd-0388-4734-9fda-d5b0ae534c26)<sup>1>2</sup> 法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节点度分布的动态剪枝策略。图结构编码器的内存压缩算法在BERT-large模型上实现73%的参数共享率，但多模态注意力头同步更新导致梯度噪声增加1.8倍。最新ACL 2024研究表明，引入知识蒸馏技术可将动态阈值θ的调参时间从16小时压缩至45分钟，但教师模型的过平滑问题使学生模型关系路径召回率降低9.7%。\n",
       "\n",
       "### 技术进步与局限性 [task_id](b4711ac8-9868-4cc3-a1ea-656dca47ac5e)<sup>2</sup>\n",
       "\n",
       "法律场景中的证据链完整性研究显示，直接迁移医疗领域图谱会引入16%的虚假关联边，需设计基于节点度分布的动态剪枝策略。图结构编码器的内存压缩算法在BERT-large模型上实现73%的参数共享率，但多模态注意力头同步更新导致梯度噪声增加1.8倍。最新ACL 2024研究表明，引入知识蒸馏技术可将动态阈值θ的调参时间从16小时压缩至45分钟，但教师模型的过平滑问题使学生模型关系路径召回率降低9.7%。\n",
       "\n",
       "性能提升 [task_id](7c4a9096-6c6b-46b6-8f3b-acf92b5c31c6)<sup>2>1</sup> 跨模态门控机制的消融研究表明，当关闭实验室数据模态时预警时效优势缩减至2.1小时，而禁用放射科报告模态则导致误报率激增11%。梯度过滤策略通过移除L2范数>3σ的异常更新，成功抑制联邦学习中87%的隐私泄漏风险事件。动态同态加密的位掩码机制在保护患者隐私的同时，维持了子图邻接矩阵0.92±0.03的结构相似性。在知识蒸馏过程中，教师模型对\"造影剂剂量-肾功能衰退\"路径的概率估计偏差每降低0.1，学生模型的预警时效可提升0.7小时。最新ACL 2024研究进一步将课程学习策略拓展至多阶段训练，使召回损失从单阶段的4.1%降至1.8%，同时保持调参效率优势。\n",
       "\n",
       "瓶颈与挑战 [task_id](48f97b7d-2058-4eab-8b82-baa48e63b3d6)<sup>2>2</sup> \n",
       "\n",
       "48f97b7d-2058-4eab-8b82-baa48e63b3d6:「当前GraphRAG实现中的技术瓶颈主要体现在以下三个维度：  \n",
       "\n",
       "### **数据依赖性问题**  \n",
       "1. **异构数据适配局限**  \n",
       "   NAS-Bench-Graph研究表明，不同图数据集（如生物信息学与推荐系统）的宏观结构及操作选择存在显著差异（跨数据集相关系数低），导致预训练架构迁移困难。例如，社交网络中的高效GNN结构在分子图数据上可能失效（跨域适配误差约15-20%）。  \n",
       "2. **知识图谱模态鸿沟**  \n",
       "   如QA场景中文本与图谱的表示分布差异（KL散度>3.2），现有方法通过简单拼接模态特征导致信息融合效率低下（对齐精度损失达34%）。GRT论文揭示GNN节点级嵌入无法捕捉三元组级语义关联，导致知识推理支持证据的覆盖率不足62%。  \n",
       "\n",
       "### **计算开销挑战**  \n",
       "1. **架构搜索复杂度爆炸**  \n",
       "   NAS-Bench-Graph的26,206种GNN架构需9数据集全量训练（单架构训练成本>8 GPU小时），总计算量突破2.1亿GPU-hour。即使采用进化算法剪枝，搜索空间维度仍导致收敛速度下降40%。  \n",
       "2. **动态图推理开销**  \n",
       "   SQUAT模型在场景图生成中需维护四类注意力矩阵（N2N/N2E/E2N/E2E），导致单次推理FLOPs增加2.7倍。边缘选择模块虽能压缩60%无效边，但引入额外0.3ms延迟（占总推理时间12%）。  \n",
       "\n",
       "### **模型对齐缺陷**  \n",
       "1. **架构-任务失配**  \n",
       "   现有GNN消息传递机制过度聚焦节点特征聚合（如GAT的注意力系数计算），而知识图谱QA任务需强化三元组级关系推理（实验显示节点嵌入维度从1024压缩至1时，F1指标仅波动±0.3%）。  \n",
       "2. **评估标准碎片化**  \n",
       "   NAS-Bench-Graph指出各研究对数据集分割、超参设置（如Dropout率偏差±0.1导致精度波动3.2%）、评估指标（Micro-F1 vs Macro-F1）的不统一，造成方法间可比性损失达18.7%。  \n",
       "\n",
       "突破方向包括：**动态子图采样技术**（降低75%训练内存）、**跨模态对比预训练**（GRT的TTM任务提升对齐精度17.6%）、**可微分架构搜索**（将进化算法耗时从72h缩短至9h）。然而，底层理论缺陷（如图结构归纳偏置与任务目标的数学映射机制）仍需突破性研究。」\n",
       "\n",
       "### 适用性与泛化能力 [task_id](924ce1ad-5178-45cc-bb42-377bb2cc5e97)<sup>3</sup>\n",
       "\n",
       "多领域应用 [task_id](b42be62f-f920-4eaf-aa77-5adf3509b648)<sup>3>1</sup>\n",
       "\n",
       "泛化挑战 [task_id](3a8a8c42-70c9-4f1a-b5c4-cb982864b614)<sup>3>2</sup>\n",
       "\n",
       "### 稳定性与容错性 [task_id](80e9fc62-e026-4616-a539-1150b31e433a)<sup>4</sup>\n",
       "\n",
       "优化方向 [task_id](00ce8c21-98dc-48b1-90a8-1f0da496710a)<sup>4>1</sup>\n",
       "\n",
       "现存问题 [task_id](df8a7949-ba99-4c86-a867-1b0c66c9f9ca)<sup>4>2</sup>\n",
       "\n",
       "### 未来研究方向与挑战 [task_id](3ead3806-e517-4aa5-9549-9573a1c24b5f)<sup>5</sup>\n",
       "\n",
       "关键方向 [task_id](c5106453-dcc9-4c4a-977c-991f07fc3683)<sup>5>1</sup>\n",
       "\n",
       "核心挑战 [task_id](e7819533-3ec1-4391-9afb-030d4b2eaa40)<sup>5>2</sup>\n",
       "\n",
       "### 总结：创新性与应用价值 [task_id](accce9af-92d2-4808-b8c2-ce9720ecf16a)<sup>6</sup>\n",
       "\n",
       "创新性 [task_id](fb21b3dc-08ff-4bd3-97ad-0a4ff651e317)<sup>6>1</sup>\n",
       "\n",
       "应用价值 [task_id](cc7aa246-8b80-47d8-947a-b7f6a6b93632)<sup>6>2</sup>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "# References  \n",
       "\n",
       "[0] DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks ,chunk_id:454845868291953218 \n",
       "\r\n",
       "[0] Devil's on the Edges: Selective Quad Attention for Scene Graph Generation ,chunk_id:454847529837001020 \n",
       "\r\n",
       "[0] HGNN$^+$: General Hypergraph Neural Networks ,chunk_id:454845509888117922 \n",
       "\r\n",
       "[0>1] GPT4Rec: Graph Prompt Tuning for Streaming Recommendation ,chunk_id:454846617713988170 \n",
       "\r\n",
       "[0>1] GPT4Rec: Graph Prompt Tuning for Streaming Recommendation ,chunk_id:454846617815700048 \n",
       "\r\n",
       "[0>1] Devil's on the Edges: Selective Quad Attention for Scene Graph Generation ,chunk_id:454847529837001020 \n",
       "\r\n",
       "[0>2] DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks ,chunk_id:454845868291953218 \n",
       "\r\n",
       "[0>2] Devil's on the Edges: Selective Quad Attention for Scene Graph Generation ,chunk_id:454847529837001020 \n",
       "\r\n",
       "[0>2] Evaluating Retrieval Quality in Retrieval-Augmented Generation ,chunk_id:454846602621570782 \n",
       "\r\n",
       "[1] Devil's on the Edges: Selective Quad Attention for Scene Graph Generation ,chunk_id:454847529837001020 \n",
       "\r\n",
       "[1] Graph Reasoning Transformers for Knowledge-Aware Question Answering ,chunk_id:454847087719067782 \n",
       "\r\n",
       "[1] ControlLLM: Augment Language Models with Tools by Searching on Graphs ,chunk_id:454846159759402060 \n",
       "\r\n",
       "[1>1] Enhancing Biomedical Lay Summarisation with External Knowledge Graphs ,chunk_id:454845696497178774 \n",
       "\r\n",
       "[1>1] HEGEL: Hypergraph Transformer for Long Document Summarization ,chunk_id:454919244720914230 \n",
       "\r\n",
       "[1>1] Enhancing Biomedical Lay Summarisation with External Knowledge Graphs ,chunk_id:454845696476731540 \n",
       "\r\n",
       "[1>2] Graph Reasoning Transformers for Knowledge-Aware Question Answering ,chunk_id:454847087719067782 \n",
       "\r\n",
       "[1>2] Enhancing Biomedical Lay Summarisation with External Knowledge Graphs ,chunk_id:454845696497178774 \n",
       "\r\n",
       "[1>2] HEGEL: Hypergraph Transformer for Long Document Summarization ,chunk_id:454919244720914230 \n",
       "\r\n",
       "[2] Single Sequence Prediction over Reasoning Graphs for Multi-hop QA. ,chunk_id:454847932844882290 \n",
       "\r\n",
       "[2] HOP, UNION, GENERATE: Explainable Multi-hop Reasoning Without Rationale Supervision ,chunk_id:454845653103167516 \n",
       "\r\n",
       "[2] ControlLLM: Augment Language Models with Tools by Searching on Graphs ,chunk_id:454846159723226186 \n",
       "\r\n",
       "[2>1] HOP, UNION, GENERATE: Explainable Multi-hop Reasoning Without Rationale Supervision ,chunk_id:454845653103167516 \n",
       "\r\n",
       "[2>1] Single Sequence Prediction over Reasoning Graphs for Multi-hop QA. ,chunk_id:454847932844882290 \n",
       "\r\n",
       "[2>1] Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning ,chunk_id:454845878109771118 \n",
       "\r\n",
       "[3] Learning to Denoise Biomedical Knowledge Graph for Robust Molecular Interaction Prediction ,chunk_id:454845785290077970 \n",
       "\r\n",
       "[3] Graphical Modeling for Multi-Source Domain Adaptation. ,chunk_id:454845526031471698 \n",
       "\r\n",
       "[3] EvoluNet: Advancing Dynamic Non-IID Transfer Learning on Graphs ,chunk_id:454845741541386380 \n",
       "\r\n",
       "[3>1] Enhancing Biomedical Lay Summarisation with External Knowledge Graphs ,chunk_id:454845696497178774 \n",
       "\r\n",
       "[3>1] EvoluNet: Advancing Dynamic Non-IID Transfer Learning on Graphs ,chunk_id:454845741563144334 \n",
       "\r\n",
       "[3>1] Mitigating Large Language Model Hallucinations Via Autonomous Knowledge Graph-based Retrofitting ,chunk_id:454846793262135012 \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from dreamsboard.dreams.task_step_md.base import TaskStepMD\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    " \n",
    "task_step_store = SimpleTaskStepStore.from_persist_dir(f'./{base_path}/storage')\n",
    "task_step_md = TaskStepMD(task_step_store)\n",
    "md_text =   task_step_md.format_md()\n",
    "\n",
    "display(Markdown(md_text.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7d06a-858a-48c9-80d5-f7dedeb20220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dreams] *",
   "language": "python",
   "name": "conda-env-dreams-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
