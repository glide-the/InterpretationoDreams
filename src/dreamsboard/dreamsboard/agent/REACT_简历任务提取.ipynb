{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXrSxVW3PwYU"
   },
   "source": [
    "# OpenAI Finetuning REACT- Distill GPT-4 to GPT-3.5\n",
    "\n",
    "In this notebook, we walk through an example of fine-tuning gpt-3.5-turbo.\n",
    "\n",
    "Specifically, we attempt to distill GPT-4's knowledge, by generating training data with GPT-4 to then fine-tune GPT-3.5.\n",
    "\n",
    "All training data is generated using two different sections of our index data, creating both a training and evalution set.\n",
    "\n",
    "We then finetune with our `OpenAIFinetuneEngine` wrapper abstraction.\n",
    "\n",
    "Evaluation is done using the `ragas` library, which we will detail later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9134,
     "status": "ok",
     "timestamp": 1701355247339,
     "user": {
      "displayName": "dmeck zhang",
      "userId": "07529216131586326578"
     },
     "user_tz": -480
    },
    "id": "ZLEGeuUPPwYW",
    "outputId": "e95928af-8e25-491b-ffe0-22db1e42395e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-finetuning\n",
      "  Downloading llama_index_finetuning-0.1.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-finetuning) (0.10.18.post1)\n",
      "Collecting llama-index-embeddings-adapter<0.2.0,>=0.1.2 (from llama-index-finetuning)\n",
      "  Downloading llama_index_embeddings_adapter-0.1.3-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting llama-index-llms-gradient<0.2.0,>=0.1.1 (from llama-index-finetuning)\n",
      "  Downloading llama_index_llms_gradient-0.1.2-py3-none-any.whl.metadata (685 bytes)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-finetuning) (0.1.7)\n",
      "Collecting llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1 (from llama-index-finetuning)\n",
      "  Downloading llama_index_postprocessor_cohere_rerank-0.1.2-py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting sentence-transformers<3.0.0,>=2.3.0 (from llama-index-finetuning)\n",
      "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.12.2)\n",
      "Requirement already satisfied: httpx in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.8.1)\n",
      "Requirement already satisfied: numpy in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.12.0)\n",
      "Requirement already satisfied: pandas in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.9.0)\n",
      "Collecting torch<3.0.0,>=2.1.2 (from llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting gradientai<2.0.0,>=1.6.0 (from llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning)\n",
      "  Downloading gradientai-1.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting cohere<5.0,>=4.45 (from llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning)\n",
      "  Downloading cohere-4.53-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning)\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "Collecting scikit-learn (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning)\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.21.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.0.3)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.2.1)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning)\n",
      "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (6.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.2.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.16.0)\n",
      "Collecting aenum>=3.1.11 (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning)\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pydantic<2.0.0,>=1.10.5 (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning)\n",
      "  Using cached pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.8.2)\n",
      "Requirement already satisfied: filelock in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (23.2)\n",
      "Requirement already satisfied: anyio in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.3.0)\n",
      "Requirement already satisfied: certifi in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.4)\n",
      "Requirement already satisfied: idna in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.6)\n",
      "Requirement already satisfied: sniffio in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.14.0)\n",
      "Requirement already satisfied: click in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.1.7)\n",
      "Requirement already satisfied: joblib in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.0.3)\n",
      "Requirement already satisfied: sympy in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.12)\n",
      "Requirement already satisfied: jinja2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.15.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.20.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from python-dateutil>=2.8.2->gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.3.0)\n",
      "Downloading llama_index_finetuning-0.1.4-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_adapter-0.1.3-py3-none-any.whl (4.5 kB)\n",
      "Downloading llama_index_llms_gradient-0.1.2-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_postprocessor_cohere_rerank-0.1.2-py3-none-any.whl (2.7 kB)\n",
      "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cohere-4.53-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradientai-1.8.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m506.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: aenum, triton, threadpoolctl, scipy, safetensors, pydantic, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fastavro, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gradientai, nvidia-cusolver-cu12, cohere, transformers, torch, sentence-transformers, llama-index-postprocessor-cohere-rerank, llama-index-llms-gradient, llama-index-embeddings-adapter, llama-index-finetuning\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.2\n",
      "    Uninstalling pydantic-2.6.2:\n",
      "      Successfully uninstalled pydantic-2.6.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "zhipuai 2.0.1 requires pydantic>=2.5.2, but you have pydantic 1.10.14 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aenum-3.1.15 cohere-4.53 fastavro-1.9.4 gradientai-1.8.0 llama-index-embeddings-adapter-0.1.3 llama-index-finetuning-0.1.4 llama-index-llms-gradient-0.1.2 llama-index-postprocessor-cohere-rerank-0.1.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pydantic-1.10.14 safetensors-0.4.2 scikit-learn-1.4.1.post1 scipy-1.12.0 sentence-transformers-2.5.1 threadpoolctl-3.3.0 torch-2.2.1 transformers-4.38.2 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement llama-index-finetuning-callbacks (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for llama-index-finetuning-callbacks\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-openai in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-llms-openai) (0.10.18.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2023.12.2)\n",
      "Requirement already satisfied: httpx in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.12.0)\n",
      "Requirement already satisfied: pandas in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.10.14)\n",
      "Requirement already satisfied: anyio in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.0.4)\n",
      "Requirement already satisfied: idna in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-finetuning\n",
    "%pip install llama-index-finetuning-callbacks\n",
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5368,
     "status": "ok",
     "timestamp": 1701355429441,
     "user": {
      "displayName": "dmeck zhang",
      "userId": "07529216131586326578"
     },
     "user_tz": -480
    },
    "id": "q8wHXkjur0Y_",
    "outputId": "3909d9c2-6a4f-4e49-e6d9-d0a440786f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pydantic) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /media/gpt4-pdf-chatbot-langchain/pyenv-jsonformer/lib/python3.10/site-packages (from pydantic) (4.10.0)\n",
      "Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydantic\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradientai 1.8.0 requires pydantic<2.0.0,>=1.10.5, but you have pydantic 2.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-2.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xILA5KnIPwYX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    " \n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import (\n",
    "    OpenAIEmbedding,\n",
    ")  # pants: no-infer-dep\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO5qOTQgPwYY"
   },
   "source": [
    "## Data Setup\n",
    "\n",
    "Here, we first down load the PDF that we will use to generate training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-hyv9T6PwYZ"
   },
   "source": [
    "The next step is generating a training and eval dataset.\n",
    "\n",
    "We will generate 40 questions on different sections of the PDF we downloaded.\n",
    "\n",
    "We can use GPT-3.5 on the eval questions to get our baseline performance.\n",
    "\n",
    "Then, we will use GPT-4 on the train questions to generate our training data. The training data will be collected with out `OpenAIFineTuningHandler`.\n",
    "\n",
    "This step is entirely optional if you don't want to spend the time/tokens -- the eval and training questions are also provided in this folder, as well as the training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQyXK_oBPwYZ"
   },
   "source": [
    "### Train Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TsDrXdSAPwYa"
   },
   "outputs": [],
   "source": [
    " \n",
    "llm = OpenAI(model=\"gpt-4\", temperature=0.3, api_key = \"sk-ApUK41y73g8qMbrz36A81641752946449f10BbBe32Ff2b7c\",api_base=\"http://localhost:3000/v1\")\n",
    "embeddings = OpenAIEmbedding(api_key = \"EMPTY\",api_base=\"http://127.0.0.1:9997/v1\")\n",
    "# os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/marchtest2\"\n",
    "    )\n",
    "    march_index = load_index_from_storage(storage_context)\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/junetest2\"\n",
    "    )\n",
    "    june_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/septtest2\"\n",
    "    )\n",
    "    sept_index = load_index_from_storage(storage_context)\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "if not index_loaded:\n",
    " \n",
    "     # load data\n",
    "    march_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"/home/dmeck/Documents/张毛峰个人简历 - 2024-01-20(1).pdf\"]\n",
    "    ).load_data()\n",
    "    june_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"/home/dmeck/Downloads/个人简历_刘立兼(1).docx\"]\n",
    "    ).load_data()\n",
    "    sept_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"/home/dmeck/Downloads/简历_宋金珂_北京交通大学_网络空间安全.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    march_index = VectorStoreIndex.from_documents(\n",
    "        march_docs,embed_model=embeddings\n",
    "    )\n",
    "    june_index = VectorStoreIndex.from_documents(\n",
    "        june_docs,embed_model=embeddings\n",
    "    )\n",
    "    sept_index = VectorStoreIndex.from_documents(\n",
    "        sept_docs,embed_model=embeddings\n",
    "    )\n",
    " \n",
    "    # persist index\n",
    "    march_index.storage_context.persist(persist_dir=\"./storage/marchtest2\")\n",
    "     \n",
    "    june_index.storage_context.persist(persist_dir=\"./storage/junetest2\")\n",
    "    sept_index.storage_context.persist(persist_dir=\"./storage/septtest2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_engine = march_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "june_engine = june_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "sept_engine = sept_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B5r643l1PwYa"
   },
   "outputs": [],
   "source": [
    "query_tool_march = QueryEngineTool.from_defaults(\n",
    "    query_engine=march_engine,\n",
    "    name=\"march_2022\",\n",
    "    description=(\n",
    "        f\"关于张毛峰的简历信息，包括了langchain-chatchat、InterpretationoDreams、KM 平台、省检修特高压生产指挥管控系统、智能运检移动应用、福建监控系统项目\"\n",
    "\n",
    "    ),\n",
    ")\n",
    "\n",
    "query_tool_june = QueryEngineTool.from_defaults(\n",
    "    query_engine=june_engine,\n",
    "    name=\"june_2022\",\n",
    "    description=(\n",
    "        f\"关于刘立兼的简历信息，包括了•篝火心理、雷鸟365、雷鸟365、网聚宝CRM、AP数据基盘、AP数据基盘等项目\"\n",
    "    ),\n",
    ")\n",
    "query_tool_sept = QueryEngineTool.from_defaults(\n",
    "    query_engine=sept_engine,\n",
    "    name=\"sept_2022\",\n",
    "    description=(\n",
    "        f\"关于宋金珂的简历信息，包括了全球 IPv4 空间内的物联网设备扫描识别和隐私安全分、开源软件生态内的跨项目依赖分析及漏洞影响追溯、已发表论文列表、IoT 设备安全等项目\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "query_engine_tools = [query_tool_march, query_tool_june, query_tool_sept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "trCYwGaVwPcI"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "base_agent = ReActAgent.from_tools(query_engine_tools, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: sept_2022\n",
      "Action Input: {'input': '宋金珂发表了什么论文'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [1] Jinke Song , Qiang Li, Haining  Wang , Limin  Sun. Under the conceali ng su rface: Detecting and understanding \n",
      "live webcams in the wild[J]. Proceedings of the ACM on Measu rement and Analysis of Computing Systems  \n",
      "(SIGMETRICS ), 2020, 4(1): 1 -25. \n",
      "[2] Qiang Li, Jinke Song , Dawei  Tan, Haining Wang, Jiqiang Liu . PDGraph : A Large -Scale Empirica sl Study on \n",
      "Project Dependency o f Security  Vulnerabilitie s[C]. 51st Annual IEEE/IFIP Int ernational Conference on Dependable \n",
      "Systems and Networks ( DSN ). IEEE, 2021: 161 -173. \n",
      "[3] Zhihao  Wang , Qiang Li, Jinke Song , Haining Wang, L imin Sun. Towards IP -based geolocation via fine -grained \n",
      "and s table webcam landmarks[C] . Proceedings of The Web Confer ence (WWW ). 2020: 1422 -1432.  \n",
      "[4] Li, Q., Wang, Z., Tan, D., Jinke Song , Wang, H. etc. (2021). GeoCAM: An IP -Based Geolocation Service \n",
      "Through Fine -Grained and Stable We bcam Landmarks. IEEE/ACM Transact ions on Networking , 29(4), \n",
      "1798 -1812.  \n",
      "[5] 李强，贾煜璇， 宋金珂，李红，朱红松，孙利民， “网络空间物联网信息搜索” ，信息安全学报， 2018\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools.\n",
      "Answer: 宋金珂发表的论文包括：\n",
      "\n",
      "1. Detecting and understanding live webcams in the wild\n",
      "2. PDGraph: A Large-Scale Empirical Study on Project Dependency of Security Vulnerabilities\n",
      "3. Towards IP-based geolocation via fine-grained and stable webcam landmarks\n",
      "4. GeoCAM: An IP-Based Geolocation Service Through Fine-Grained and Stable Webcam Landmarks\n",
      "5. 网络空间物联网信息搜索\n",
      "\u001b[0m宋金珂发表的论文包括：\n",
      "\n",
      "1. Detecting and understanding live webcams in the wild\n",
      "2. PDGraph: A Large-Scale Empirical Study on Project Dependency of Security Vulnerabilities\n",
      "3. Towards IP-based geolocation via fine-grained and stable webcam landmarks\n",
      "4. GeoCAM: An IP-Based Geolocation Service Through Fine-Grained and Stable Webcam Landmarks\n",
      "5. 网络空间物联网信息搜索\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5 generally gives the right response here\n",
    "response = base_agent.chat(\n",
    "    \"宋金柯发表了什么论文,详细的是什么\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0u9vBLPPwYi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1NgyCJVyrC2xcZ5lxt2frTU862v6eJHlc",
     "timestamp": 1701354535100
    },
    {
     "file_id": "1KsIj852X0GEPn0ctwuwp3wbJb4ivJGlE",
     "timestamp": 1693261441944
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
