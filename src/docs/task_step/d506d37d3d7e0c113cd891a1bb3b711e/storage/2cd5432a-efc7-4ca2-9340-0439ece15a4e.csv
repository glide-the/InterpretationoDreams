角色,内容,分镜
2cd5432a-efc7-4ca2-9340-0439ece15a4e,评估学术界的技术进步与局限性,2
2cd5432a-efc7-4ca2-9340-0439ece15a4e,"### 问题

在评估学术界的技术进步与局限性时，如何有效平衡模型性能的提升（如精度和效率）与模型偏差和数据依赖等局限性？具体来说，有哪些创新方法（如偏差缓解、少样本学习）可以在减少对大量高质量标注数据依赖的同时，确保模型在实际应用中的鲁棒性和可靠性？",2
2cd5432a-efc7-4ca2-9340-0439ece15a4e,"ref_ids: 454959888553742592, chunk_ids: 0, Score: 0.3516, Text: # G.2 Limitation
While this work has provided prevalent methods, representative datasets, and several powerful benchmarks, this section explores the limitations expected to be addressed in future studies.  

Training Limination. In pursuit of a fair comparison, we maintain the model architecture and model size with the original paper. However, specific architecture improvements or larger model size may yield enhanced results.  

Benchmark Limination. Although we have implemented 12 methods in our benchmark, we will provide more methods in the future to provide a wider method spectrum. Besides, we have meticulously calibrated the dataset protocol, but there is still a lot of work to be done, such as the impact of the number of input frames.  

Table 8: computational efficiency analysis for each model.   


<html><body><table><tr><td>Model ConvLSTM E3D-LSTM</td><td></td><td></td><td>MAU</td><td>PhyDNet PredRNNv1 PredRNN++ PredRNNv2 SimVPv1 SimVPv2</td><td></td><td></td><td></td><td></td><td></td><td>TAU</td><td></td><td>Earthformer MCVD</td></tr><tr><td>params</td><td>12.09M</td><td>51.35M</td><td>4.475M</td><td>3.092M</td><td>23.84M</td><td>36.028M</td><td>23.86M</td><td>57.95M</td><td>46.77M</td><td>44.66M</td><td>6.702M</td><td>54.29M</td></tr><tr><td>FLOPs</td><td>58.80G</td><td>299.0M</td><td>17.79G</td><td>15.33G</td><td>116.0M</td><td>175.0M</td><td>117.0M</td><td>19.43G</td><td>16.53G</td><td>15.95G</td><td>33.65G</td><td>29.15G</td></tr><tr><td>FPS</td><td>247.9</td><td>36.1</td><td>156.8</td><td>340.4</td><td>119.4</td><td>84.6</td><td>115.1</td><td>428.3</td><td>435.3</td><td>442.1</td><td>54.4</td><td>261.7</td></tr></table></body></html>  

<html><body><table><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>9</td><td>64</td><td>16</td><td>64</td><td>16</td><td>9</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>5e-4</td><td>4e-5</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Schd</td><td>OneCy</td><td>None</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCyOneCy</td><td></td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>100</td><td>100</td><td>100</td><td>100</td><td>100</td><td>50</td><td>09</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Evaluation Limination. Due to resource limitations, our human evaluation only recruits 100 participants. Our human evaluation also lacks diversity in terms of participant background, as it only includes a few attributes such as age and gender. We hope that future work can improve the diversity and size of the participants. Furthermore, we hope explore more evaluation approaches and metrics to present a holistic assessment of models.  

Table 10: Hyper-parameters of E3D-LSTM [59]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td>Config M-MNIST KTHHuman3.6M BAIR RoboNetBridgeData CityScapesKITTI nuScenes TaxiBJ Traffic4Cast ENSOSEVIR WeatherBench</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>BS</td><td>16</td><td></td><td>16</td><td>64</td><td>9</td><td>64</td><td>9</td><td>16</td><td>64</td><td>16</td><td>64</td><td>32</td><td>9</td><td>9</td></tr><tr><td>LR</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>2e-4</td><td>1e-4</td><td>1e-3</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>None</td><td>OneCy</td><td></td><td>OneCyOneCy</td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2+L1</td><td>L2</td><td>L2+L1L2+L1</td><td></td><td>L2+L1</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 11: Hyper-parameters of MAU [6]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td colspan=""10"">Config M-MNIST KTH Human3.6M BAIR RoboNet BridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4Cast ENSO SEVIR WeatherBench</td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>64</td><td>16</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>1e-3</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td></td><td>OneCyOneCy</td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>BF16</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td></td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 12: Hyper-parameters of PhyDNet [23]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .CM represents its proposed kernel moment loss, and $\\lambda_{C M}$ is its scaling factor.   


<html><body><table><tr><td colspan=""10"">ConfigM-MNIST KTH Human3.6MBAIR RoboNet BridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4Cast ENSO</td><td colspan=""4"">SEVIRWeatherBench</td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>9</td><td>64</td><td>16</td><td>9</td><td>16</td><td>64</td><td>64</td><td>32</td><td>9</td></tr><tr><td>LR</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td>L2+CM</td><td></td><td>L2+CM L2+CM</td><td>L2+CM</td></tr><tr><td>入CM</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 13: Hyper-parameters of PredRNNv1 [60]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td>HHuman3.6M BAIR RoboNetBridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4CastENSO SEVIR WeatherBench</td><td>ConfigM-MNISTKTH</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>64</td><td>16</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>5e-4</td><td>4e-5</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam Adam</td><td></td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCyOneCy</td><td></td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 14: Hyper-parameters of PredRNN $^{++}$ [58]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td></td><td colspan=""10"">ConfigM-MNIST KTH Human3.6M BAIR RoboNetBridgeData CityScapesKITTI nuScenes TaxiBJ Traffic4CastENSO SEVIRWeatherBench</td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>64</td><td>16</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>1e-4</td><td>4e-5</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCyOneCy</td><td></td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 15: Hyper-parameters of PredRNNv2 [61]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .DC means decouple loss proposed in PredRNNv2, and $\\beta_{D C}$ is its scaling factor.   


<html><body><table><tr><td colspan=""10"">ConfigM-MNIST KTH Human3.6M BAIR RoboNet BridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4Cast ENSO SEVIR WeatherBench</td><td colspan=""4""></td></tr><tr><td>BS</td><td></td><td>16</td><td>16</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>9</td><td>16</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>5e-4</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td>L2+DC</td><td></td><td>L2+DC L2+DC</td><td>L2+DC</td></tr><tr><td>βDc</td><td>0.1</td><td>0.01</td><td>0.1</td><td>0.01</td><td>0.01</td><td>0.01</td><td>0.01</td><td>0.01</td><td>0.01</td><td>0.1</td><td>0.01</td><td>0.01</td><td>0.01</td><td>0.01</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 16: Hyper-parameters of SimVPv1 [18]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td colspan=""10"">ConfigM-MNIST KTH Human3.6M BAIR RoboNet BridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4Cast ENSO SEVIR WeatherBench</td></tr><tr><td>BS</td><td></td><td></td><td>16</td><td>64</td><td></td><td>9</td><td>64</td><td>16</td><td>64</td><td>16</td><td>64</td><td>9</td><td>32</td><td>9</td></tr><tr><td>LR</td><td>16 1e-3</td><td>16 1e-3</td><td>1e-4</td><td>1e-4</td><td>9 1e-3</td><td>1e-3</td><td>1e-4</td><td>5e-3</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td></td><td>OneCy</td><td>OneCyOneCy</td><td></td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>OneCy 50</td><td></td><td>100</td><td>100</td><td>09</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td></td><td></td><td></td><td></td><td>50</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 17: Hyper-parameters of SimVPv2 [50]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ .  


<html><body><table><tr><td>Config M-MNIST KTH Human3.6M BAIR RoboNetBridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4CastENSO SEVIR WeatherBench</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>BS</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>64</td><td>16</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>LR</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>5e-3</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCyOneCy</td><td></td><td>OneCy</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>50</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 18: Hyper-parameters of TAU [51]. In TaxiBJ [69], we adopt $p c t\\_s t a r t=0.1$ in the OneCycleLR scheduler rather than the default $p c t\\_s t a r t=0.3$ . DDR denotes the differential divergence regularization proposed in TAU, and $\\alpha_{D D R}$ is its scaling factor.   


<html><body><table><tr><td colspan=""2"">ConfigM-MNIST</td><td>KTH</td><td>Human3.6M</td><td>BAIR</td><td>RoboNet BridgeData CityScapes</td><td></td><td></td><td>KITTI</td><td>nuScenes TaxiBJ Traffic4Cast</td><td></td><td></td><td>ENSO</td><td>SEVIR</td><td>WeatherBench</td></tr><tr><td>BS</td><td>64</td><td>64</td><td>64</td><td>64</td><td>16</td><td>16</td><td>16</td><td>16</td><td>64</td><td>64</td><td>32</td><td>16</td><td>64</td><td>64</td></tr><tr><td>LR</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-4</td><td>5e-3</td><td>1e-3</td><td>1e-3</td><td>le-3</td><td>le-3</td><td>le-3</td><td>1e-3</td><td>1e-4</td><td>le-4</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>Cosine</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td></tr><tr><td>Epoch</td><td>100</td><td>100</td><td>100</td><td>100</td><td>50</td><td>100</td><td>100</td><td>200</td><td>200</td><td>200</td><td>100</td><td>50</td><td>50</td><td>50</td></tr><tr><td>Loss</td><td>L2+DDR</td><td>L2+DDR</td><td>L2+DDR</td><td>L2+DDR L2+DDR</td><td></td><td>L2+DDR</td><td>L2+DDR</td><td></td><td>L2+DDR L2+DDR L2+DDR</td><td></td><td>L2+DDR</td><td></td><td>L2+DDR L2+DDR</td><td>L2+DDR</td></tr><tr><td>αpDR</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 19: Hyper-parameters of Earthformer [19]. In the first column, WD means weight decay of the optimizer, and Clip represents that clip _grad is adopted with $m a x\\_n o r m=1.0$ .  


<html><body><table><tr><td>ConfigM-MNIST RoboNet BridgeData CityScapes KITTI nuScenes TaxiBJ Traffic4Cast ENSO</td><td></td><td>KTH</td><td>Human3.6M BAIR</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>SEVIRWeatherBench</td><td></td></tr><tr><td>BS</td><td>32</td><td>32</td><td>32</td><td>9</td><td>64</td><td>64</td><td>64</td><td>32</td><td>64</td><td>32</td><td>64</td><td>64</td><td>32</td><td>64</td></tr><tr><td>Optim</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW</td><td>AdamW AdamW</td><td></td><td>AdamW</td></tr><tr><td>Sch</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td><td>OneCy</td></tr><tr><td>WD</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td><td>1e-5</td></tr><tr><td>Clip</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>LR</td><td>1e-3</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-3</td><td>1e-3</td><td>1e-4</td><td>1e-4</td><td>1e-3</td><td>1e-4</td></tr><tr><td>Epoch</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>100</td><td>100</td><td>100</td><td>200</td><td>50</td><td>50</td><td>100</td><td>100</td><td>50</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

Table 20: Hyper-parameters of MCVD [56]. Linear means the LinearLR scheduler with 5000 iterations for warm-up. WD means weight decay of the optimizer, and Clip represents that clip _grad is adopted with $m a x\\_n o r m=1.0$ .  


<html><body><table><tr><td>Config</td><td>gM-MNIST KTH Human3.6M BAIR RoboNet BridgeData CityScapesKITTI nuScenes TaxiBJ Traffic4Cast ENSO SEVIR WeatherBench</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>BS</td><td>64</td><td>64</td><td>64</td><td>64</td><td>128</td><td>128</td><td>64</td><td>64</td><td>128</td><td>64</td><td>128</td><td>64</td><td>128</td><td>9</td></tr><tr><td>Optim</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td><td>Adam</td></tr><tr><td>Sch</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td><td>Linear</td></tr><tr><td>WD</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0'0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>Clip</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr><tr><td>LR</td><td>2e-4</td><td>2e-4</td><td>1e-4</td><td>1e-4</td><td>4e-4</td><td>1e-4</td><td>1e-4</td><td>2e-4</td><td>1e-4</td><td>1e-4</td><td>4e-4</td><td>1e-4</td><td>4e-4</td><td>1e-4</td></tr><tr><td>Iter</td><td>5e5</td><td>5e5</td><td>1e6</td><td>5e5</td><td>1e6</td><td>1e6</td><td>5e5</td><td>5e5</td><td>1e6</td><td>5e5</td><td>2e6</td><td>5e5</td><td>1e6</td><td>1e6</td></tr><tr><td>Loss</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td><td>L2</td></tr><tr><td>dtype</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td><td>BF16</td></tr></table></body></html>  

  
Fig. 2: Qualitative results on BAIR [14] (2 frames $\\longrightarrow10$ frames).  

  
Fig. 3: Qualitative results on BridgeData [57] (2 frames $\\rightarrow10$ frames).  

  
Fig. 4: Qualitative results on CityScapes [9] (2 frames −→ 5 frames).  

  
sequences are visualized at the interval of 3 frames. Fig. 5: Qualitative results on ICAR-ENSO [54] (12 frames −→ 14 frames). The  

  
Fig. 6: Qualitative results on Human3.6M [30] (4 frames −→ 4 frames).  

  
Fig. 7: Qualitative results on KITTI [21] (10 frames −→ 10 frames).  

  
Fig. 8: Qualitative results on KTH [45] (10 frames −→ 10 frames).  

  
Fig. 9: Qualitative results on Moving-MNIST [48] (10 frames −→ 10 frames).  

  
Fig. 10: Qualitative results on nuScenes [4] (10 framse $\\longrightarrow10$ frames).  

  
Fig. 11: Qualitative results on RoboNet [10] (2 framse −→ 10 frames).  

  
Fig. 12: Qualitative results on SEVIR [55] (13 framse $\\rightarrow12$ frames). The sequences are visualized at the interval of 2 frames.  

  
Fig. 13: Qualitative results on TaxiBJ [69] (4 framse $\\longrightarrow4$ frames).  

  
Fig. 14: Qualitative results on Traffic4Cast2021 [15] (9 framse $\\longrightarrow3$ frames).  

  
Fig. 15: Qualitative results of t2m on WeatherBench [20] (2 framse $\\longrightarrow20$ frames). The target and predicted sequences are visualized at the interval of 4 frames. The models are learned to predict 1 frame based on 2 context frames, and the 2-20 frames in the predicted sequences are generated through extrapolation.  

  
Fig. 16: Qualitative results of $\\mathrm{t}850$ on WeatherBench [20] (2 framse $\\longrightarrow20$ frames). The target and predicted sequences are visualized at the interval of 4 frames. The models are learned to predict 1 frame based on 2 context frames, and the 2-20 frames in the predicted sequences are generated through extrapolation.  

  
Fig. 17: Qualitative results of $z500$ on WeatherBench [20] (2 framse $\\longrightarrow20$ frames). The target and predicted sequences are visualized at the interval of 4 frames. The models are learned to predict 1 frame based on 2 context frames, and the 2-20 frames in the predicted sequences are generated through extrapolation.  

  
Fig. 18: An example of the human assessment questionnaire. Given the groundtruth sequence, the user is required to select the predicted sequence that has the highest quality compared with the target. The predicted sequences for options A, B, C, and D Forms are generated from Earthformer [19], MCVD [56], PredRNN $^{++}$ [58], and TAU [51]. To ensure a fair and unprejudiced comparison, we have deliberately concealed the specific model information in the option descriptions.",2
2cd5432a-efc7-4ca2-9340-0439ece15a4e,"ref_ids: 454848129553553028, chunk_ids: 1, Score: 0.3125, Text: # 主动弱监督学习的偏差和方差平衡
语萨普克塔hxs1943 @rit.edu 罗切斯特理工学院罗切斯特，纽约州，美国  

齐豫 qi.yu @rit.edu 罗切斯特理工学院罗切斯特，纽约州，美国

# 摘要
作为一种广泛使用的弱监督学习方案，现代多实例学习(MIIL)模型在袋级上实现了竞争性能。然而，对于许多重要应用至关重要的实例级预测在很大程度上仍然不令人满意。我们建议进行新颖的主动深度多实例学习，对一小部分信息实例进行采样以进行标记，旨在显著提高实例级预测。设计方差正则化损失函数来适当平衡实例级预测的偏差和方差，旨在有效适应MIL中高度不平衡的实例分布和其他基本挑战。我们没有直接最小化非凸的方差正则化损失，而是优化了一个分布鲁棒的袋级似然作为其凸代理。鲁棒袋级似然提供了基于方差的MIL损失的良好近似，具有很强的理论保证。它还自动平衡偏差和方差，使其有效地识别潜在的积极实例来支持主动采样。鲁棒袋似然可以自然地与深度架构集成，以支持使用小批量的正负袋对进行深度模型训练。最后，开发了一种新颖的P-F抽样函数，该函数结合了概率向量和预测的实例分数，通过优化鲁棒袋似然获得。通过利用关键的MIL假设，采样函数可以探索最具挑战性的袋，并有效地检测它们的正实例进行注释，从而显着提高了实例级预测。在多个真实世界数据集上进行的实验清楚地证明了所提出模型所实现的最先进的实例级预测。

# CCS的概念
·计算方法 $\\rightarrow$ 主动学习设置;知识设置;机器学习。

# 关键字
多实例学习;主动学习;弱监督

# ACM参考格式：
HiteshSapkota和Qi ${\\mathrm{Yu}}_{\\circ}$ 2022.ac-active弱监督学习的平衡偏差和方差。第28届ACMSIGKDD知识发现与数据挖掘会议论文集 $\\mathrm{KDD}^{\\prime}\\,22,$ ，2022年8月14-18日，USA华盛顿特区。ACM，USA，纽约，11页。https://doi.org/10.1145/3534678.3539264

# 1介绍
多实例学习(Multiple Instance Learning,MIL)提供了一种有吸引力的弱监督学习范式，其中实例被自然地组织到袋中，并且在袋级分配训练标签以降低标注成本[6,19,25,27]。最先进的MIL模型在袋级上实现了竞争性的性能。然而，对于许多重要应用(例如，监控视频的异常检测[27]和医学图像分割[12])至关重要的实例级预测在很大程度上仍然不令人满意。  

在MIL中，如果至少有一个实例是阳性的，否则是阴性的，则认为一个包是阳性的[6,10]。为了实现高袋级预测，大多数现有的MIIL模型主要关注来自阳性袋的最阳性实例，该阳性袋主要负责确定袋标签[1,10,14,27]。然而，它们有两个主要的局限性，这导致了较差的实例级预测。首先，仅仅关注最积极的实例对异常值很敏感，这些异常值是看起来与其他消极实例非常不同的消极实例[3]。因此，这些实例可能会被错误地赋予一个高分，表明它们是积极的。其次，单个包中可能存在多种类型(即多模态)的阳性实例(例如，监控视频中不同类型的异常或皮肤科图像中不同类型的皮肤病变)。因此，专注于一个最积极的实例将会错过其他积极的实例。这两种情况都会导致较低的实例级预测性能。提高正实例检测的一个可能的解决方案是考虑顶部-K最正的实例。然而，在不同的包中，正实例的数量可能会有很大的差异，使用相同的Kto所有包可能是不合适的。此外，找到一个最优的Kfor每个包是极具挑战性的，因为它需要一个离散的值。  

实例级预测不太准确的根本原因是缺乏实例标签。对于跨袋相 对罕见的正实例，仅依靠袋标签来检测它们本质上是具有挑战性的，因为弱监督信号(即袋标签)在没有足够的统计证据的情况下无法传播到实例级。解决这一挑战的一个有希望的方向是用主动学习(AL)来增强MIL。多实例AL(或MI-AL)旨在选择少量的信息实例来改善 MIL中的实例级预测。在大多数MIL问题中，数据在实例级高度不平衡，其中正数据更加稀疏。自  

  
图1:(a)挑战性袋子的例子;(b)实例级预测的MI-AL性能;(c)-(e)不同MI-AL步骤中袋子中实例的预测分数  

积极实例通常携带更重要的信息，MI-AL的一个主要目标是从一个由消极实例占主导地位的候选池中有效地抽取积极实例。如果一个真正的积极实例可以被采样和标记，它可以帮助识别相同和不同包中的其他类似的积极实例，这将显着提高实例级预测。  

然而，现有的MIL模型可能很容易遗漏一些罕见的正实例[27]。由于对异常值的敏感性或无法处理多式联运包，它们也可能专注于错误识别的负面实例。因此，真正的积极实例可能会被分配一个较低的预测分数，表明它们被预测为具有高置信度的消极实例。因此，常用的基于不确定性的抽样将错过这些重要的实例。图1 (a)显示了一个具有挑战性的袋子，它是一个包含鸟的阴影的图像(作为正类)。正面实例是覆盖(部分)鸟影的补丁。图1 (b)显示，将不确定性采样与基于最大分数的MIL模型(绿色曲线)相结合，无法有效采样，因此在AL过程中，实例级预测仍然非常低。图1 (c)进一步证实了正实例的初始预测分数(F-score)接近于o，使得其很难被采 样。  

我们提出了一种新的MI-AL模型，用于有效的实例抽样，以显著提高ML中的实例级预测。我们设计了一个独特的方差正则化MIL损失，鼓励高方差的预测分数来解决具有高度不平衡的实例分布和/或具有离群值和多模态场景的包。由于方差正则化器是非凸的，我们提出了一个优化的分布鲁棒袋似然(DRBL)，它为基于方差的损失提供了一个良好的凸近似,并具有很强的理论保证。DRBL自动调整袋级方差的影响，使其更有效地检测潜在的积极实例，以支持主动采样。它还可以自然地与深度架构集成，使用小批量的正-负袋对来支持深度MIL模型训练。最后，开发了一个新的P-F抽样函数，该函数结合了概率向量(即p)和通过优化DRBL获得的预测实例分数(即f)。通过利用关键的MIIL假设，采样函数可以探索最具挑战性的袋，并有效地检测它们的正实例进行注释，从而显着提高了实例级预测。开发了一种新的批处理模式采样与深度MIL无缝工作，从而产生了强大的有源深度MIL（ADMIL)模型，以支持大多数MIL应用中使用的高维数据采样。图1 (b)显示了  

提出的模型(紫色曲线)，它显着提高了实例预测。图1 (c)-(e)显示了P-F采样动态更新概率p和得分f值，以便在几个步骤中有效地从极具挑战性的包中采样阳性实例。  

我们的主要贡献包括：(i)一个独特的方差正则化MIL损失及其凸代理，它解决了固有的MIL挑战，以最好地支持主动采样;(i)一个新颖的P-F采样函数，以有效地探索具有罕见正实例的最具挑战性的包;(ii)在更广泛的MIIL应用中支持ADMIL的小批量训练和批处理模式主动采样;(iv)在MIL中最先进的实例预测性能，同时保持低实例注释。

# 2 相关工作
多实例学习(MIL)。现有的监督学习模型已经被用来解决MIL问题，包括SVM[1]、boosting[29]、基于图的模型[31]、基于注意力的模型[11,12]、条件随机场[5]和高斯过程[10,14]。其他方法尝试放宽MIL假设，允许负包中的正实例处理有噪声的包[19]。由于MIL通常应用于涉及高维数据的视频异常检测和图像分割，深度神经网络(dnn)已成为训练MIL模型的热 门选择[11,12,27]。尽管到目前为止取得了重大进展，但大多数现有模型都侧重于改进袋级预测。因此，在关键应用中,实例级性能仍然达不到高标准[10,12,27]。所提出的ADMIL模型旨在填补这一关键空白，通过采用新颖的主动采样策略来增强MIL，使用有限的标记实例来显著提高实例预测，以保持较低的注释成本。  

主动学习(AL)。现有的AL模型通常利用不确定性和基于边际的度量来实现有效的数据采样[23]。在多类AL中也采用分布鲁棒优化来解决抽样偏差和数据分布不平衡问题[32]。深度学习模型具有高维数据处理和自动特征提取能力，是AL的理想选择。现有模型主要针对提高网络的不确定性量化，以实现可靠的采样[9,13,18,28]。批模式采样通常用于主动DL，以避免频繁的模型再训练。它侧重于构建有代表性的批次，以避免相似实例给出的冗余信息[2,15,22]。MIL环境下的AL很少被研究。一个例外是MI logistic模型及其同时考虑实例和袋级不确定性的三个不确定性度量[24]。然而，不确定性抽样对于探索具有挑战性的袋是无效的，其中所有实例  

都被认为是消极的。此外，原始模型是一个简单的线性模型，不能为高维数据提供足够的能力。也没有系统的方法来支持批处理模式的采样。在[4]中开发了一种基于强化学习的AL技术，其中在每个AL步骤中选择片段进行标记。然而，在训练过程中，需要分段级标注来计算奖励，这违背了MIL的假设。[30]中针对MIL任务开发了另一个AL框架。然而，采样是在袋级进行的(即选择袋而不是实例)。因此，它本质上是一个多标签AL模型，旨在用更少的标注袋来提高袋级预测。这与 ADMIL的设计目标有本质的不同。

# 3方法
让{x1，…, $\\mathrm{\\Deltax_{N}}\\}$ 表示与每个包B相关的一组实例，其中每个 $\\mathrm{x_{I}\\!\\in}$ Ris是一个特征向量。设 $\\mathbf{\\nabla}\\mathbf{T}^{\\mathbf{B}}\\!\\in\\!\\{+1$ ，-1)表示袋子的类型。按照前面讨论的标准MIL假设，主动采样将集中于正袋中的实例，因为负袋中的所有实例都是负的。我们还允许实例的数量因袋而异。

# 3.1方差正规化
设x $\\bar{+}$ (或xJ)为正袋BPOS(或负袋 $\\mathrm{\\mathbf{B}_{N E G})}$ )中的 $\\geqslant$ T(或JT)实例。根据MIL假设，训练深度MIL模型常用的损失函数是使来自正袋的实例的最大预测分数高于负袋 $[27]_{\\circ}$ 我们定义为  

$$
\\mathcal{L}^{\\mathrm{MS}}=\\left\\{1-\\operatorname*{max}_{i\\in\\mathcal{B}_{p o s}}\\left[f(\\mathbf{x}_{i}^{+};\\mathbf{w})\\right]+\\operatorname*{max}_{j\\in\\mathcal{B}_{n e g}}\\left[f(\\mathbf{x}_{j}^{-};\\mathbf{w})\\right]\\right\\}_{+}
$$  

$\\mathrm{F}(\\mathbf{x};\\mathbf{W}){\\in}[0,1]$ 是由W和 $[\\mathrm{A}]+=\\operatorname*{max}\\{0,\\ \\mathrm{A}\\}$ 参数化的深度神经网络提供的实例x的预测分数。我们将从 $_{\\ z}(\\mathbf{x};\\mathbf{w})$ 中省略w，以保持符号的整洁。上述目标函数旨在最大化来自正袋的实例的最大预测分数与来自负袋的最大分数之间的差距。模型训练可以通过对正袋和负袋进行采样 $({\\bf{B}}_{\\mathrm{{POS}}}$  $\\mathrm{\\bfB}_{\\mathrm{NEG}})$ ，使用它们的袋级标签来评估损失，并进行反向传播。基于最大分数的ML(称为MS-MIL)模型主要是为袋子标签预测而设计的，因为它旨在从一个阳性袋子中识别出一个最阳性的实例，并最大化其预测分数。通过这种方式，它充分利用了MIL假设(即Bpos)中至少有一个正实例)和弱监督信号(即袋级标签)。  

如前所述，MS-MIL及其顶级K扩展受到影响其实例级预测性能的关键限制。同时，它们提供的支持不足，无法对最具信息量的实例进行抽样，以增强实例预测。受最近在风险最小化中自动平衡偏差和方差的学习理论进展的启发[7]，我们提出了一种新的方差正则化MIL损失函数来捕捉MIL的固有特征，旨在共同解决高度不平衡的实例分布、异常值的存在和多模态场景。因此，最小化新的MIL损失可以有效地提高正实例的预测分数，使它们更容易被所提出的采样函数采样以进行  

注释。特别是，方差正则化损失对(1)引I入了两个新颖的变化,形式化如下：  

$$
\\mathcal{L}^{\\mathrm{VAR}}=\\left\\{1-\\left[\\frac{1}{n}\\sum_{i=1}^{n}f(\\mathbf{x}_{i}^{+})+C\\sqrt{\\frac{\\mathrm{Var}_{n}[f(X^{+})]}{n}}\\right]+\\operatorname*{max}_{j\\in\\mathcal{B}_{n e g}}\\left[f(\\mathbf{x}_{j}^{-})\\right]\\right\\}_{+}
$$  

其中 $\\forall\\!\\in\\![1$ ， $\\mathrm{NJ}$ ， $\\mathbf{x}+\\in\\mathbf{B}\\mathrm{POS}$ ，Nis是B的大小POS，VarNis是F $\\mathrm{X+}$ 的经验方差， $X^{+}$ 是一个随机变量，代表一个来自正包的实例，参数平衡平均分数和方差。  

第一个关键的变化是使用平均分数来代替(1)中的最大分数，这避免了模型只关注包中最积极的实例，使其对异常值和多模态场景具有鲁棒性。由于正袋保证包含正实例，而负袋中的实例都是负的，因此希望正袋的平均分数应该高。使用复杂模型(例如，DNN)最大化正袋中的平均分数可以有效地减少估计袋级标签的训练损失(通过减少偏差)。然而，单独使用平均分数是有问题的，因为在典型的MIL设置中，正袋中的大多数实例通常是负的。因此，这样一个低偏差的模型将导致非常高的假阳性率，从而对整体实例级预测产生负面影响。所提出的损失函数通过新颖的方差项解决了这个问题，有效地处理了高度不平衡的实例分布。由于只有少数实例是真正正的，经验方差Varvfor这个包应该是高的，因为少数高分与大多数低分有很大的偏差。值得注意的是，在标准监督学习中，(2)中的方差项比风险最小化起着明显的作用，在标准监督学习中，方差项被最小化以控制估计误差。相比之下，(2)中的方差被鼓励较大，以允许袋子中的一小组实例为正，旨在精确捕获不平衡分布。据我们所知，这是MIL设置中的第一个偏差-方差公式。  

使用方差正则化进行MI-AL仍然面临两个挑战。首先，它的有效性取决于平均得分和经验方差之间的最优平衡，而经验方差是由超参数<e:1>控制的。与标准的监督学习类似，缺乏一种系统的方法来设置这样的超参数来实现最优权衡。其次，方差项是非凸的，具有多个局部极小值[7]，这使得模型训练更加困难和耗时。因此，不适合用于支持主动采样的实时交互。

# 3.2分布鲁棒袋似然（distributionalRobust Bag Likelihood)
为了解决上述挑战，我们提出构建一个分布鲁棒袋级似然(DRBL)作为(2)中方差正则化损失的凸代理。通过扩展为监督学习中风险最小化而开发的分布鲁棒优化框架[7,20]，我们从理论上证明了DRBL与方差正则化之间的高概率等价。DRBL 是凸的，更容易优化，有利于MIL模型训练，支持快速主动采样。此外，通过设置适当的不确定性集，我们证明了在优化DRBL时直接获得的参数Cis，其中袋中的实例分布是受约束的通过不确定性集。因此，它实现了平均预测分数和方差之间的自动权衡。  

我们首先引入一个概率向量 $\\scriptstyle\\mathbf{\\delta}=(\\mathbf{P}1,\\quad\\dotsc,\\quad\\mathbf{p}_{\\mathbf{N}})\\bigotimes$ ，其中 $\\mathrm{\\tilde{I}}_{\\mathrm{IPI}}{=}$ 1, $\\mathrm{PI}^{\\geqslant0}$  $\\forall\\!\\in\\!\\{1,\\ \\ \\cdots,\\ \\mathrm{N}\\}$ ，并设prdenote为实例 $\\mathrm{\\Deltax_{I}+\\in{\\cal B}_{P O S}}$ can代表袋子的概率。我们进一步引入一个二元指标向量 ${\\boldsymbol{Z}}=$ (1，“，望而生畏，其中P(望而生畏) $\\mathrel{\\mathop{:}}1=\\mathsf{P}_{\\mathrm{I}_{\\circ}}$ 设Ybe为表示袋子标签的二进制随机变量。对袋子中的所有实例进行条件作用，袋子B的(有条件的)袋子似然POSis由 $\\mathsf{P}(\\mathbf{Y}=1|\\mathbf{z},\\mathbf{f})=\\hat{\\mathrm{IF}}(\\mathbf{x}+)$ ，其中f $\\mathbf{\\mu=}(\\mathbf{F}(\\mathbf{x}+_{1})$  $_\\mathrm{F}(\\mathrm{x_{N}+)})^{\\infty}\\infty\\infty_{\\circ}$ 通过积分出指标变量，我们得到边际袋似然为F $\\mathbf{\\dot{\\rho}}_{(\\mathrm{Y=1}|\\mathrm{p,f})}=\\mathbf{\\dot{IPF}}(\\mathbf{x+})_{\\mathrm{o}}$ 我们没有让一个最正的实例来确定袋子标签，其中P(萨拉赫 $\\mathrel{\\mathop:}=1\\|\\mathbf{p},\\mathbf{f})\\mathop{=}\\!\\mathrm{F}(\\mathbf{x}\\mathbf{K}\\!+\\!)$ 与 $\\mathrm{K}{=}$ argmaxIF $\\mathbf{\\lambdax}_{\\mathrm{I}^{+}})$ (相当于MS-MIL)，或者为每个实例分配相等的概率(即 $_\\mathrm{PI}{=}1/\\mathrm{N},$ ，这相当于平均分数，我们引入了一个不确定性集 $\\mathrm{{P_{N}t h a t}}$ ，允许p在一定程度上偏离均匀分布：  

$$
\\mathcal{P}_{n}:=\\left\\{\\mathbf{p}\\in\\mathbb{R}^{n},\\mathbf{p}^{\\top}\\mathbb{1}=1,0\\leq\\mathbf{p},D_{f}\\left(\\mathbf{p}||\\frac{\\mathbb{1}}{n}\\right)\\leq\\frac{\\lambda}{n}\\right\\}
$$  

其中 $\\mathrm{D}_{\\mathrm{F}}({\\mathsf{p}}\\|{\\mathsf{q}})$ 是两个分布p和q之间的F-divergence,1是一个N-dimensional单位向量，入controls是p可以偏离均匀向量的程度,它本质上对应于袋子中不平衡的实例分布。注意， $\\mathrm{P_{N}}$ only指定了一个p可能偏离均匀分布的邻域。由于Pvis是一个凸集，通过根据特定的不平衡实例分布优化鲁棒袋的似然，可以很容易地计算出每个特定袋的最优p。这从根本上比top-K方法更有优势，因为ris是离散的，很难优化。接下来，我们证明了最优鲁棒袋似然相当于方差正则化的高概率平均预测分数，这使我们能够基于DRBL定义新的MIL损失。  

定理1。让 $X^{+}$ 随机变量代表一个实例从一个积极的袋子 $\\mathrm{\\Delta_{PF}}$  $(\\mathbf{X}{+})\\!\\in\\![0,1]$ 是分配给的分数 $\\scriptstyle\\tau^{2=\\ V a r(F(X+)]}$ 和 $\\mathrm{Var_{N}[F(X+)]}$ 表示F $\\mathrm{\\DeltaX+})$ 的人口和样本方差，分别 $\\mathrm{DF}$ takesX2-divergence的形式。为固定入andN $\\geqslant\\!\\operatorname*{max}(2,\\!\\upsigma\\uplambda2\\,\\operatorname*{max}(8\\upsigma44))$  

$$
\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\sum_{i=1}^{n}{p}_{i}f(\\mathbf{x}_{i}^{+})=\\frac{1}{n}\\sum_{i=1}^{n}{f(\\mathbf{x}_{i}^{+})}+\\sqrt{\\frac{\\lambda V a r_{n}[f(X^{+})]}{n}}
$$  

概率至少为 $1\\mathrm{-exp}{}^{-}\\mathrm{7N}_{220}$ ，其中PNis为不确定性  

由(3)定义的集合。  

值得注意的是，给定典型MIL设置中高度不平衡的正实例，真实方差 $\\scriptstyle\\cdot\\sigma^{2}.$ 应该很高。对于一个尺寸合适的袋子，它以高概率保证了(4)中的等价性。此外，在(4)的1.h.s.上给出的 $\\surd$ the鲁棒袋似然最大化分配了(4)的<s:1>鲁棒袋似然，它根据不确定性集自动调整方差的影响。下面的定理2进一步将这一结果推广到k1-散度。  

定理2。让 $X^{+}$ 随机变量代表一个实例从一个积极的袋子,F $(\\mathbf{X}{+})\\!\\in\\![0,1]$ 是分配给的分数 $\\scriptstyle{\\sigma^{2=}}\\mathbf{Var}(\\mathbf{F}(\\mathbf{X}+)]$ 和 $\\mathrm{Var_{N}[F(X+)]}$ 表示、样本  

方差 $\\mathrm{F}^{(\\mathrm{X}+),}$ 分别DrtakesKL-divergence的形式。我们有  

$$
\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\sum_{i=1}^{n}p_{i}f(\\mathbf{x}_{i}^{+})=\\frac{1}{n}\\sum_{i=1}^{n}f(\\mathbf{x}_{i}^{+})+\\sqrt{\\frac{2\\lambda V a r_{n}[f(X^{+})]}{n}}+\\epsilon\\left(\\frac{\\lambda}{n}\\right)
$$  

$\\begin{array}{r}{w h e r e\\,\\epsilon\\left(\\frac{\\lambda}{n}\\right)=\\frac{\\lambda}{3n}\\frac{\\kappa_{3}\\left(f\\left(X^{+}\\right)\\right)}{V a r_{n}\\left[f\\left(X^{+}\\right)\\right]}+O\\left(\\left(\\frac{\\lambda}{n}\\right)^{3/2}\\right)\\,w i t h\\,\\kappa_{3}=\\mathbb{E}_{0}[\\left(f\\left(X^{+}\\right)-\\left(\\frac{\\lambda}{n}\\right)^{3/2}\\right)],}\\end{array}$ $\\underset{\\mathrm{E0[F}}{\\mathbb{E}}(f(X^{+})])^{3}]$ and $\\mathbb{E}_{0}$ denotestheexpectation takenover ${\\bf p}_{0}$  

备注:给定一个尺寸合适的袋子 $\\mathrm{\\DeltaN}{\\gg}1$ ，由于 $\\lambda$ is通常设置为 $\\uplambda\\ll$ 1(我们的实验中使用0.01)，我们有： $_\\mathrm{N<s:}2>\\rightarrow0_{\\circ}$ 当经验方差VarN$\\left[\\mathrm{F}(\\mathbf{X}+)\\right]$ 足够大时(对于MIL来说是正确的)，(5)的r.h.s.由前两项 主导，这意味着  

$$
\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\sum_{i=1}^{n}{p_{i}f(\\mathbf{x}_{i}^{+})}\\approx\\frac{1}{n}\\sum_{i=1}^{n}{f(\\mathbf{x}_{i}^{+})}+\\sqrt{\\frac{2\\lambda\\mathrm{Var}_{n}[f(X^{+})]}{n}}
$$  

详细的证明见附录 $\\mathbf{{a}}_{0}$ 利用上述理论结果，我们将基于drbl的MIL损失公式为  

$$
\\mathcal{L}^{\\mathrm{DRBL}}=\\left\\{1-\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\left[\\sum_{i=1}^{n}\\rho_{i}f(\\mathbf{x}_{i}^{+})\\right]+\\operatorname*{max}_{j\\in\\mathcal{B}_{n e g}}\\left[f(\\mathbf{x}_{j}^{-})\\right]\\right\\}_{+}
$$  

DRBL损失对新引I入的概率向量p提供了非常直观的解释。由于它可能偏离不确定性集 $\\mathrm{\\nabla{P_{N}}}$ 指定的均匀分布，因此每个条目PIessentially对应于 $\\mathrm{\\Deltax_{I}+}$ 对袋可能性的贡献(或权重)(为正)。因此,为了最大化反胸袋可能性，具有较高预测分数的实例应该获得更高的权重。同时，在 $\\mathrm{\\nabla{P_{N}}}$ 的约束下，多个实例将对具有相当大权重的袋子可能性做出贡献，因为p不能偏离均匀太多。因此,它们的预测分数将同时由模型提高。这使得DRBL对异常值和多模态情况具有鲁棒性，因为它增加了真阳性实例或多种真阳性实例获得高预测分数的机会。这为提出的P-F主动抽样函数提供了基本支持，该函数以一种新颖的方式将概率向量p和预测分数结合起来，以选择包中信息最多的实例进行注释。

# 3.3P-F主动采样
由于我们有预测分数 $\\mathrm{F^{(x_{I}+)\\in[0,1]}}$ ，因此可以自然地将其解释为实例 $|\\mathbf{x}_{\\mathrm{I}^{+}}$ 为正的概率。执行基于不确定性的实例抽样的一种直接方法是计算基于F-score的实例熵，称为f-熵:  

$$
\\mathbf{x}_{*}=\\arg\\operatorname*{max}_{i\\in\\mathcal{B}_{p o s}}H[f(\\mathbf{x}_{i}^{+})],
$$  

在H[F] $=-$ [F日志F $\\mathsf{i}+(1-\\mathsf{F})$ 日志 $(1-\\mathrm{F})\\mathrm{\\ensuremath{j}_{\\circ}}$ 由于采样实例具有最大的预测不确定性(根据f-熵)，标记这样的实例可以有效地提高模型的实例级性能。使用(8)的主动抽样是直接的，它涉及对来自正训练袋的所有实例(注意所有的实例)评估 $\\mathrm{H}^{\\mathrm{[F(x+)]}}$  

在一个负的袋子是负的)。由于我们认为深度学习模型可以更好地适应高维数据，因此每次采样一个实例需要频繁的模型训练，这在计算上是昂贵的。相反，我们在每一步中根据预测的f-熵对一小批实例进行抽样。值得注意的是，由于高度不平衡的实例分布，包括许多正实例在内的大多数预测分数可能非常低。我们的目标是为潜在的正实例分配一个相对较高的分数，使它们的熵不会太低，表明一个自信的负预测，这将被抽样函数错过。  

如前所述，使用鲁棒袋似然作为MIL损失可以直接使实例采样受益，因为它增加了为正实例分配更高预测分数的机会，从而使其更有可能被采样。然而，f-熵抽样仍然有两个主要的局限性。首先，对于一些非常困难的袋子，例如图1(a)所示的样本图像，识别积极实例(例如，图像中包含鸟的阴影的补丁)可能非常具有挑战性。因此，它们可能会被分配一个非常低的Fscore。事实上，如图1 (c)所示，这个袋子中的所有实例都得到了非常低的分数，最高的分数小于0.01，导致熵值非常低。附录B的图8显示了来自20NewsGroup数据集的一些额外的具有挑战性的袋的示例，其中所有实例都以非常低的分数进行预测。因此，所有这些实例都被预测为具有低不确定性的负实例，使它们不太可能被基于熵的抽样选择。其次，由于采用批处理模式采样来降低深度网络的训练成本，因此必须使同一批中选择的实例多样化，以最小化标注成本。然而，单纯根据预测的熵来选择数据实例可能会导致对相似实例的标注，这是不划算的。  

本文提出的P-F主动抽样方法，根据概率向量p和预测分数f在袋子中的不同作用，通过最小最大函数将它们结合起来，通过有效的袋子探索，同时克服了上述两个限制。P-F采样的关键设计原理植根于标准MIL假设，该假设确保每个阳性袋中至少有一个阳性实例，以指导有效的袋探索。在袋子探索过程中，p's和f's以及袋子结构都会动态更新，以增加在未被探索的袋子中采样阳性实例的机会。混合损失函数进一步利用在同一袋子中采样的负实例的标签来提高正实例的预测分数。更具体地说， 设Bbe总正训练袋数，P-F抽样将选择以下数据实例：  

$$
\\mathbf{x}_{*}^{P F}=\\arg\\operatorname*{min}_{b\\in\\{1,...,B\\}}f(\\mathbf{x}_{b_{*}}^{+}),\\quad\\mathrm{and}\\;b_{*}=\\arg\\operatorname*{max}{\\mathbf{p}_{b}}
$$  

其中 $|\\mathrm{p}_{\\mathrm{B}}\\mathrm{is}$ 为袋的概率向量B。对于每个袋子，抽样函数首先识别每个袋子中P值最大的实例 $|\\mathbf{xB}+\\mathbf{*}$ 。这样的实例可以被认为是包中最具代表性的实例，因为它对包的可能性贡献最大(根据 $\\mathsf{p}_{\\mathrm{{B}}}{}.$ 根据 $\\mathrm{XB+*}$ 的预测分数，我们可以将袋子分为三组：(1)容易的袋子，其中自信地F( $\\operatorname{xB}\\!+\\!\\!\\operatorname{\\mathbb{E}}[\\60]$ )采取预测，一个大的值， (2)表示混淆的袋子,其中模型F(xmakesB $+$ 是  

相当大但不确定，表明模型仍然对其预测感到困惑，(3)困难袋，其中F $\\left(\\mathrm{xB}{+}^{\\ast}\\right)$ 非常低，表明模型自信地做出了错误的预测。我们希望从令人困惑和困难的袋子中取样，因为模型已经对容易的袋子做出了准确的实例预测。由于模型做出了不确定的预测，因此可以通过提出的f-熵从混乱的袋子中采样实例，这导致了高熵。最后，由于整个袋子的预测分数较低，从困难的袋子中抽样从根本上来说更具挑战性。然而，MIL假设为正实例的袋级探索提供了一个总体方向，因为每个正包中必须至少有一个正实例。(9)中的P-F抽样函数从预测分数最低的袋子中选择代表性实例。这样的实例被保证从一个未被探索的(即困难的)袋子中抽样，因为尽管它被预测为袋子中最积极的实例，但它具有最低的预测分数。  

批处理模式抽样的扩展在两个方向上进行，在一个袋子内和跨袋子，以便在确保抽样实例的多样性的同时更有效地进行探索。首先，我们建议抽样K>1个实例，而不是只从已识别的未探索的袋子中抽样最积极的实例，因为根据当前的预测分数，积极实例的排名可能低于袋子中的多个消极实例(示例见图1(c))。这有助于更有效地探索非常困难的袋子。为了确保采样实例之间的多样性，我们保持??small但是同时跨多个包进行采样。只有最大预测分数F $(\\mathrm{x}??\\!+\\!\\ast)$ 小于阅值(0.3在我们的实验中使用)的袋将被探索，因为这些代表上面讨论的困难袋。对于具有较大 $\\mathrm{F}^{\\left(\\mathrm{x}_{\\mathrm{{B}}}+\\right)}$ 的袋，  

它们要么是简单的袋子，要么是令人困惑的袋子，可以使用f-熵有效地采样。我们的整体P-F抽样函数集成了袋子探索和f-熵，并优先考虑前者，首先进行多样性感知的袋子探索。随着越来 越多的袋子与MI-AL一起被成功探索，越来越少的实例将被探索采样，重点将自然地转移到f-熵来执行模型微调。详细的采样过程由算法1总结。  

与标准监督学习中的AL类似，应该使用采样和标记的实例来提高模型的预测性能。然而，由于缺乏实例标签，MIL损失主要集中在袋级标签上。为此，我们提出了一个集成了包和实例标签的混合损失函数。设 $\\mathrm{{XL=\\{XL_{1}}}}$ ， $\\mathrm{XL}_{2}$  $\\mathbf{{x}_{M}^{\\mathrm{~L~}}}\\}$ 为提出的主动学习函数查询的 $\\overset{\\cdot}{\\mathbf{M}}^{\\phantom{\\cdot}}$ labeled个实例, $\\scriptstyle{\\mathrm{tL}}=\\{\\mathrm{TL}_{1},\\mathrm{T}_{2}\\mathrm{L}$ ，， $\\mathrm{T}_{\\mathrm{M}}^{\\mathrm{~\\scriptsize~L~}}\\}$ 其中 $\\mathrm{~\\stackrel{\\cal~T~}{\\cal~L}~}^{\\mathrm{~I~}}\\in\\{0,\\ \\ 1\\}$ 为对应的实例标签。我们将有监督的二元交叉熵(BCE)损失表述为  

$$
L^{\\mathrm{BCE}}=-\\frac{1}{m}\\sum_{i=1}^{m}\\left[t_{i}^{l}\\log(f(\\mathbf{x}_{i}^{l}))+(1-t_{i}^{l})\\log(1-f(\\mathbf{x}_{i}^{l}))\\right]
$$  

很明显，采样的正实例提供了重要的监督信号，使模型能够预测相似的正实例的高分，这将直接有利于实例级预测。相比之下，采样的负实例，特别是那些从未充分探索的袋子中选择的负实例，对提高预测性能的贡献较小，因为它们的原始预测分数已经很低了。然而，它们在实现更有效的袋级探索方面发挥着微妙但必不可少的作用。首先，如果一个采样实例被标记为负，它将被从袋子中移除，这并不违反MIL假设。同时，由于我们有 $\\mathrm{{}^{1}_{I P I}}{=}1$ ，pvalues将被重新分配，因此每个剩余实例被抽样的机会增加了。此外，BCE的损失会进一步降低与被采样实例相似的负面实例的预测分数。这可能有助于提高正实例的分数，从而使其在未来有更高的被抽样的机会。最后，在查询新一批实例后,使用结合MIL损失和监督损失的混合损失对模型进行重新训练：  

$$
\\mathcal{L}^{\\mathrm{Hybrid}}=\\mathcal{L}^{D R B L}(\\mathcal{B}_{p o s},\\mathcal{B}_{n e g})+\\beta\\mathcal{L}^{B C E}(\\mathbf{X}^{l},\\mathbf{t}^{l})
$$  

其中pis用于权衡包级和实例级的损失。

# 4实验
我们在多个真实世界的MIL数据集上进行了广泛的实验，以证明所提出的ADMIL模型的有效性。我们实验的目的是证明：i)通过与现有竞争基线的比较，最先进的实例预测性能;(i)通过与其他抽样机制的比较，所提出的P-F主动抽样函数的有效性;(ii)通过详细的消融研究，关键模型参数的影响;(iv)通过具体实例进行定性评估，以对所提出模型的工作原理提供更深入和直观的见解。

# 4.1实验装置
数据集。我们的实验涉及四个涵盖文本和图像数据的数据集：20NewGroup[31]、Cifar10[16]、Cifar100[16]和Pascal VOC[8]。下面给出了每个数据集的详细描述，表1总结了袋级统计数据  

·20NewsGroup:在这个数据集中，一个实例指的是来自特定主题的帖子。对于每个主题，如果一个包至少包含一个来自该主题的实例，则被认为是积极的，否则是消极的。这个数据集特别具有挑战性，因为严重的不平衡，每个阳性包中只有很少( $\\approx$  $3\\%$ )的阳性实例。虽然每个包的实例数量可能会有所不同，但平均每个包大约有40个实例。  

·Cifar10:在原始数据集中，有50.000个训练图像和10,000个测试图像，其中10个类表示不同的图像。这些袋子的构造如下。首先，我们选择“汽车”、“鸟”和“狗”相关的图像作为积极实例，其余的作为消极实例。为了构造一个正包，我们从1到3中随机选择一个数字，并选择与随机生成的数字相等的正实例。其余的实例则从一个负实例池中选择。对于负面包，所有实例都是从负面实例池中选择的。对于每个包，我们考虑32个实例。  

$\\cdot$ Cifar100:数据集由50.000个训练图像和10,000个测试图像组成，其中有20个不同的超类表示不同的物种。袋子构造类似于Cifar10，其中超类花卉中的图像被视为正图像，其余图像被视为负图像。  

$\\cdot$ PascalVOC:该数据集由2,913张图像组成，其中图像用于分割。将每张图像视为一个包，得到的实例如下。我们定义了一个 $60~\\times$ 的网格大小  

$$
\\begin{array}{r l}&{H[f(\\mathbf{x}_{i}^{+})]=}\\\\ &{-\\left[f(\\mathbf{x}_{i}^{+}\\log f(\\mathbf{x}_{i}^{+}))+\\left(1-f(\\mathbf{x}_{i}^{+})\\right)\\log(1-f(\\mathbf{x}_{i}^{+}))\\right]\\qquad\\star/}\\end{array}
$$  

$$
\\begin{array}{r l}&{Q_{F}[b_{i}]\\gets\\mathbf{x}_{i}^{+}}\\\\ &{\\mathrm{~count}\\gets\\mathrm{count}{+}1}\\\\ &{\\bar{\\iota}=Q_{p r e v}\\cup Q_{F}}\\end{array}
$$  

75并对图像进行分区。根据映像大小，实例的数量可能会有所不同。如果给定实例中至少有 $5\\%$ 的总像素与感兴趣的对象相关，否则为负，我们将该实例视为正的。在我们的例子中，我们将鸟视为感兴趣的对象。所有由鸟组成的图像都被认为是积极的袋子，而其他的被认为是消极的。  

评价指标和模型训练。为了评估模型的性能，我们报告了实例级平均平均精度(mAP)分数，它将精度-召回曲线总结为每个阈值下达到的精度的加权平均值，并将前一个阈值的召回增加作为权重。mAP明确地更加强调少数排名靠前的实例的正确性，而不是其他指标(例如AUC)[26]。  

表1:不同数据集上阳性和阴性袋的数量  


<html><body><table><tr><td rowspan=""2"">Split</td><td colspan=""2"">20NewsGroup</td><td colspan=""2"">Cifar10</td><td colspan=""2"">Cifar100</td><td colspan=""2"">PascalVOC</td></tr><tr><td>Positive</td><td>Negative</td><td>Positive</td><td>Negative</td><td>Positive</td><td>Negative</td><td>Positive</td><td>Negative</td></tr><tr><td>Train</td><td>30</td><td>30</td><td>500</td><td>500</td><td>500</td><td>500</td><td>124</td><td>124</td></tr><tr><td>Test</td><td>20</td><td>20</td><td>100</td><td>100</td><td>100</td><td>100</td><td>84</td><td>84</td></tr></table></body></html>  

  
图3:P-F主动采样的有效性  

这使得它特别适合于实例预测评估，因为具有最高预测分数的一小部分实例最终将被识别为阳性，以便(由人类专家)进一步检查，其余的将被忽略。对于Cifar10、Cifar100和PascalVOC数据集，我们从使用imagenet数据集预训练的VGG16网络的倒数第二层提取视觉特征，为每个实例生成4,096维特征向量。对于20NewsGroup，我们使用可用的200维特征向量。在网络架构方面，我们使用了3层FC神经网络。第一层有32个单元，然后是16个单元和1个单元FC层。我们在FC层之间采用 $60\\%$ 的差值。ReLU和s型激活用于第一层和最后一层FC。除20NewsGroup为01外，所有数据集的学习率均为0.01。

# 4.2性能比较
为了证明所提出的ADMIL模型所取得的实例预测性能，我们将其与竞争基线进行了比较。首先，本文包括了MIlogistic模型中的两种MI-AL采样策略:MIAL-Uncertainty和MIAL-MIU[24]。由于我们的数据集涉及高维数据，我们用ADMIL中使用的精确DNN模型取代了原始的线性模型，因此我们可以专注于比较MI主动采样。由于评估每个实例输出相对于大量DNN参数的梯度的计算成本过高，[24]中的EGL采样技术未被包括在内。我们还实现了一个MS-MIL模型及其top-K变体，使用熵进行不确定性采样。考虑到数据集的大小不同，我们在20NewsGroup中每步最多查询15个实例，在PascalVOC中查询30个实例，在Cifar10和Cifar100中查询150个实例。图2显示了  

表2:被动设置下MIL性能  


<html><body><table><tr><td>Approach</td><td>20NewsGroup</td><td>Cifar10</td><td>Cifar100</td><td>PascalVOC</td></tr><tr><td>Ilse et al. [12]</td><td>60.85</td><td>65.16</td><td>40.15</td><td>40.15</td></tr><tr><td>Hsu et al. [11]</td><td>42.08</td><td>63.84</td><td>41.57</td><td>34.83</td></tr><tr><td>ADMIL</td><td>73.47(75.42)</td><td>64.41(74.50)</td><td>40.41(51.26)</td><td>45.15(60.79)</td></tr></table></body></html>  

所有四个数据集的MI-AL曲线具有一个标准偏差(在三次运行中计算)，由垂直黑线表示。ADMIL在所有情况下都能达到最佳性能。对于大多数数据集，它显示出更好的初始性能，这是由于所提出的基于drbl的MIL损失，在被动学习中显著有利于MIL性能。总体而言，在整个MI-AL过程中，ADMIL始终保持最佳状态，并最终收敛到更高的点。对于PascalVOC，采用熵采样的top-KMIL模型在接近终点时获得了更接近的性能，这主要是由于该数据集中的正实例有限。因此，在P-F取样探索的挑战性袋子中，没有测试袋包含类似的阳性实例。虽然ADMIL在这些包中实现了更好的实例预测，但这种优势并没有转移到测试包中。作为参考，我们还将ADMIL与Ilse等[12]和Hsu等[11]这两种最近开发的MIL模型在被动设置下进行了比较。如表2所示，与这些竞争性基线相比，ADMIL实现了更好或至少相当的性能。这清楚地证明了使用ADMIL作为主动采样的基本模型是正确的。在标记一小部分主动采样实例后，性能显著提升(如括号所示)，这进一步证明了将AL与MIL相结合的好处，我们的定性研究将对此提供更详细的分析。  

主动采样的有效性。为了证明所提出的P-F主动采样函数的有效性，我们对其进行了比较  

  
图6:超参数的影响K  

使用另外两种抽样方法，f-熵和随机抽样，同时保持模型的所有其他部分相同。如图3所示，在前三个数据集中，P-F采样明显优于其他采样，并且有很大的差距。在PascalVOC上，它比f-熵的优势更小，原因与上面解释的相同。性能的提高主要归功于在最具挑战性的袋子上有效地探索P-F采样。

# 4.3烧蚀研究
入and时延对模型性能的影响:图4和图5展示了 $(\\leqslant1)/(\\leqslant0.01)$ 的时延对模型性能的影响。特别是，入can要根据包内实例分布的不平衡情况来设置，其中入corresponds越大表示分布的不平衡程度越高。我们改变 $\\lambda^{\\mathrm{in}[10-10,1]}$ ，并且由于MIL设置中的大多数包都是高度不平衡的，因此相对较高的 $<\\!\\mathrm{s}\\!:\\!2\\!>$ 值通常会给出非常好的性能。图4显示， $<\\!\\mathrm{s};2\\!>=0.0001$ 明显优于过大(或过小)入values。至于 $\\mathrm{<s;}1\\mathrm{>}$ ，不太强调实例级损失(小的时延)，我们可能无法充分利用查询实例的标签。同时，由于过于强调实例级损失(大的时延)，模型过度关注有限的查询实例，而较少关注包标签。因此，良好的平衡会产生最佳性能，如图图所示。  

K的影响：图6显示了超参数K(即每个未探索包中查询的实例数量)对模型性能的影响。可以看到， $K\\!=2$ 在所有数据集上实现了总体上不错的性能。对于规模较大的数据集(例如Cifar100),较大的Kleads可以获得稍好的性能。

# 4.4定性分析
为了进一步证明为什么所提出的ADMIL模型及其P-F抽样函数比其他基线工作得更好，我们提供了一些说明性示例，以更深入地了解其良好的性能。首先，除了图1(a)所示的袋子外，我们还展示了两个具有挑战性的袋子。如图7(a-b)所示，B2展示了一只鸟的侧视图，而B3中只看到鸟的一小部分。对于那些困难的情况，该模型最初以高置信度将所有实例预测为负值。然而，通过耦合P-F采样和(11)中的混合损失，成功地查询了这些袋子中的正实例。图7(c)显示了P-F抽样和f-熵在mAP分数上的明显优势。作为进一步的证据，我们调查了P-F抽样和f-熵正在探索的真阳性(TP)袋的数量。TP包是指模型能够查询至 少一个真正实例的包。我们没有报告受数据集大小影响的袋的实际数量，而是显示了通过P-F抽样探索的TP袋的额外百分比图7 (d).值得注意的是，两种方法都没有尝试查询简单袋，因为它们的正实例是高置信度正确预测的。主要的区别在于具有挑战性的包，这些包的百分比在不同的数据集之间是不同的。然而，在所有数据集上，P-F抽样始终比f-熵更有效地进行探索。  

  
:(a-b)Pascal VOC中未被充分探索的袋子;(c)这些袋子的说明及其mAP分数;(d)P-F取样成功探索了其他真阳性袋

# 5结论
为了解决对于许多关键应用至关重要的现有MIL模型的低实例级预测性能，我们开发了一种新的MI-AL模型来采样少量最具信息量的实例，特别是那些来自令人困惑和具有挑战性的包，以增强实例级预测，同时保持较低的注释成本。我们建议优化鲁棒袋似然作为方差正则化MIL损失的凸代理，以识别潜在正实例的子集。主动抽样是通过适当地平衡探索具有挑战性的包(通过P-F抽样)和通过抽样最令人困惑的实例(通过f-熵)来改进模型来进行的。损失函数的设计自然支持小批量训练，加上批处理模式采样，使MI-AL模型与深度神经网络无缝工作，以支持涉及高维数据的更广泛的MIL应用。我们在多个MIL数据集上进行的广泛实验显示出比现有基线明显的优势。

# 确认
本研究得到了NSFⅡIS奖IIS-1814450和ONR奖N00014-18-1-2875的部分支持。本文中包含的观点和结论仅代表作者个人观点和结论，不应被解释为代表任何资助机构。



# 定理的证明
在本节中，我们将提供两个定理的详细证明。  

定理1的证明。我们对定理1的证明改编自[7]，做了符合分布鲁棒袋似然(DRBL)独特设计的扩展。我们首先引I入以下引[理，这些引理将在稍后的证明中使用。  

引理3 (Maurer and Pontil Theorem 10)。设ybe一个取[0,L]内值的随机变量。让 ${\\mathrm{{\\sigma}}}_{\\mathrm{{\\sigma}}}2={\\mathrm{{Va}}}$ 的总秘差和样峨差分别为N1我NN  

分别Y。然后for $\\mathrm{for}_{\\mathrm{N}}{\\geqslant}2$  

$$
P(\\sigma-t\\leq\\sqrt{V a r_{n}[Y]}\\leq\\sigma+t)\\geq1-\\exp\\left(-\\frac{n t^{2}}{2L^{2}}\\right)
$$  

分布鲁棒袋似然(DRBL)即式(4)的1.h.s.可表示为以下约束优化问题：  

$$
\\begin{array}{r l}&{\\displaystyle\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\sum_{i=1}^{n}{p_{i}f(\\mathbf{x}_{i}^{+})}}\\\\ &{\\quad\\mathrm{s.t.}\\ \\mathcal{P}_{n}:=\\left\\{\\mathbf{p}\\in\\mathbb{R}^{n},\\mathbf{p}^{\\top}\\mathbb{1}=1,0\\leq\\mathbf{p},D_{f}\\left(\\mathbf{p}||\\frac{\\mathbb{1}}{n}\\right)\\leq\\frac{\\lambda}{n}\\right\\}}\\end{array}
$$  

由于假设 $\\mathrm{DF}({\\mathrm{p}}\\|{\\mathrm{q}})^{*}{\\mathrm{y}}_{\\upchi}2$ divergence，且q遵循均匀分布，因此 ${\\mathrm{DF}}({\\mathsf{p}}\\|{\\mathsf{q}})$ 被简化为欧氏距离的平方。我们首先引入 $\\mathrm{F}^{(\\mathrm{X}_{\\mathrm{{I}}}+)}$ ’s的均值，将其记为F $\\mathsf{\\bar{\\Gamma}}=\\!\\!\\mathsf{N}\\boldsymbol{1}$  $\\scriptstyle\\mathrm{[N=1F(x+)_{\\circ}}$ 另外，回想一下，我们用f $\\mathsf{=}(\\mathrm{F}(\\mathbf{x}\\mathbf{+}_{1})$ 表示分数向量，……· $\\mathrm{F^{(x_{N}+))}}\\mathrm{{boxtimes}\\mathrm{{in}}}$ 章节 $3.2_{\\circ}$ 因此,实证vari-anceF $({\\mathrm{X}}+)$ 是由VarN[F $(\\mathrm{X}+)\\textstyle{\\left|{\\mathrm{=}}\\mathrm{N}{1}\\right|}\\,{\\big|}\\,{\\mathrm{f}}\\,{\\big|}\\,{\\big|}\\,{\\underline{{22^{-}}}}\\mathrm{F}^{-}2\\,\\textstyle{\\=}\\mathrm{N}{1}\\,{\\big|}\\,{\\big|}\\,{\\mathrm{f}}\\mathrm{-}\\mathrm{F}^{-}1\\,{\\big|}\\,{\\big|}\\,{22_{\\circ}}$ 我们进一步引入 $.\\mathsf{u}=\\mathsf{p}^{-\\mathsf{N}1}$ ，因此(13)中的目标可以转化为  

$$
\\mathbf{p}^{\\mathsf{T}}\\mathbf{f}=(\\mathbf{u}+{\\frac{\\mathbb{I}}{n}})^{\\mathsf{T}}\\mathbf{f}={\\bar{f}}+\\mathbf{u}^{\\mathsf{T}}\\mathbf{f}={\\bar{f}}+\\mathbf{u}^{\\mathsf{T}}(\\mathbf{f}-{\\bar{f}}\\mathbb{I})
$$  

其中最后一个等式成立，因为 $\\mathtt{u}\\!\\in\\!1=0_{\\circ}$ 因此，式(13)中的优化问题可以进一步转化为  

$$
\\operatorname*{max}_{\\mathbf{u}\\in\\mathbb{R}^{n}}\\bar{f}+\\mathbf{u}^{\\top}(\\mathbf{f}-\\bar{f}\\mathbb{1})\\quad\\mathrm{s.t.}\\quad||\\mathbf{u}||_{2}^{2}\\leq\\frac{\\lambda}{n^{2}},\\mathbf{u}^{\\top}\\mathbb{1}=0,\\mathbf{u}\\geq-\\frac{1}{n}
$$  

其中第一个约束是通过替换 $\\chi^{2}$ -divergence。现在，利用Cauchy-Schwarz不等式，即 $\\mathbf{u}\\!\\in\\!\\mathbf{v}\\!\\leqslant\\!\\|\\mathbf{u}\\|\\dot{2}\\|$ vll2，给出了以下条件  

$$
\\mathbf{u}^{\\top}(\\mathbf{f}-\\bar{f}\\mathbb{1})\\leq\\frac{\\sqrt{\\lambda}}{n}||\\mathbf{f}-\\bar{f}\\mathbb{1}||_{2}=\\sqrt{\\frac{\\lambda\\mathrm{Var}_{n}[f(X^{+})]}{n}}
$$  

当且仅当 $\\surd\\ V$  

$$
u_{i}=\\frac{\\sqrt{\\lambda}(f(\\mathbf{x}_{i}^{+})-\\bar{f})}{n||\\mathbf{f}-\\bar{f}||_{2}}=\\frac{\\sqrt{\\lambda}(f(\\mathbf{x}_{i}^{+})-\\bar{f})}{n\\sqrt{n\\mathrm{Var}_{n}[f(X^{+})]}}
$$  

因为我们还有一个约束 $\\smash{\\u^{3}\\geq-\\sum_{x^{\\prime}}1}$ 它满足当日仅当  

$$
\\operatorname*{min}_{i\\in[n]}\\frac{\\sqrt{\\lambda}(f(\\mathbf{x}_{i}^{+})-\\bar{f})}{\\sqrt{n\\mathrm{Var}_{n}[f(X^{+})]}}\\geq-1
$$  

$$
\\operatorname*{max}_{\\mathbf{p}\\in\\mathcal{P}_{n}}\\mathbf{p}^{\\top}\\mathbf{f}=\\bar{f}+\\sqrt{\\frac{\\lambda\\mathrm{Var}_{n}[f(X^{+})]}{n}}
$$  

剩下的就是证明不等式(18)有很高的概率成立。为了证明这一点，我们利用引理3给出的浓度不等式。因为F(xI+)E[0,1],我们有|F $(\\mathrm{xI+})^{-}\\mathrm{F}^{-}|\\!\\leqslant\\!1_{\\circ}$ ，为了满足不等式(18)，有  

$$
{\\frac{\\lambda}{n\\mathrm{Var}_{n}[f(X^{+})]}}\\leq1\\quad{\\mathrm{or}}\\quad\\mathrm{Var}_{n}[f(X^{+})]\\geq{\\frac{\\lambda}{n}}
$$  

让我们定义下面的事件  

$$
\\epsilon_{n}:=\\left\\{\\mathrm{Var}_{n}[f(X^{+})]\\geq\\frac{1}{43}\\sigma^{2}\\right\\}
$$  

在定理1中，我们假设 $\\mathrm{N}{\\geqslant}\\sigma4<\\mathrm{s}{\\cdot}2{\\>}\\;2\\;\\mathrm{max}\\{2,11\\})_{\\circ}$ 然后，在事件 $<\\!s$  $_{2}{>}\\mathrm{N}$ 上，我们有 $[\\Delta\\!\\cdot\\!44\\,2\\!\\geqslant\\!\\mathrm{varN}[{\\mathrm{F}}\\!<\\!\\mathrm{s};2\\!>\\!({\\mathrm{X}}\\!+\\!)]$ ，使得充分条件(20)成立，式(19)为真。  

现在我们利用引理3求出上述事件在(21)中发生的概率。首先,在我们的例子中 $\\stackrel{}{\\mathrm{L}}=1$ ，它给出  

$$
P(\\sigma-t\\leq\\sqrt{\\operatorname{Var}_{n}[f(X^{+})]}\\leq\\sigma+t)\\geq1-\\exp\\left(-{\\frac{n t^{2}}{2}}\\right)
$$  

以下内容也成立:  

$$
P\\left(\\sigma-t\\leq{\\sqrt{\\operatorname{Var}_{n}[f(X^{+})]}}\\right)\\geq P(\\sigma-t\\leq{\\sqrt{\\operatorname{Var}_{n}[f(X^{+})]}}\\leq\\sigma+t)
$$  

$$
\\geq1-\\exp\\left(-{\\frac{n t^{2}}{2}}\\right)
$$  

To(12)得到  

$$
P\\left(\\sqrt{\\frac{1}{43}}\\sigma\\leq\\sqrt{\\mathrm{Var}_{n}[f(X^{+})]}\\right)\\geq1\\mathrm{-exp}\\left(-\\frac{n t^{2}}{2}\\right);P(\\epsilon_{n})\\geq1\\mathrm{-exp}\\left(-\\frac{n t^{2}}{2}\\right)
$$  

进一步代入 $\\mathrm{~T~}_{=1-1}$ 43Ggives得  

$$
P(\\epsilon_{n})\\geq1-\\exp\\left(-0.359n\\sigma^{2}\\right)\\geq1-\\exp\\left(-{\\frac{7n\\sigma^{2}}{20}}\\right)
$$  

这就完成了定理1的证明。  

定理2的证明。为了证明这个定理，我们考虑两个假设，这两个假设对于我们的MIL设置都是成立的。  

假设1:随机变量 $\\mathrm{F}^{(\\mathrm{X+})}$ 在分布pO的0邻域内具有有限指数矩，即对于一些 $\\cdot\\tau0>0$ 的情况，对于 $\\in[-0,0]$ ， $\\mathrm{E0\\,\\,[exp(F(X+))]{<}\\infty_{\\circ}}$  

假设2:随机变量R $(\\mathrm{X}+)$ 在p0下是非常数。  

假设1在我们的情况下是正确的，因为 $\\mathrm{F}^{(\\mathrm{X}+)}$ 在[0,1]中有界；假设2在经验上也是成立的，因为在一个正的袋子里有正的和负的实例，所以输出分数在一个袋子里的不同实例上是不同的。第二个假设确保均匀分布p0不是局部最优的，这意味着存在通过重新平衡正袋中正实例和负实例之间的概率来升级值的机会。  

  
图8:20NewsGroup中来自不同主题的挑战包的例子  

$$
\\operatorname*{max}_{g\\in\\mathcal{L}_{1}({\\bf p}_{0})}\\mathbb{E}_{0}[g f(X^{+})]\\mathrm{~s.t.}\\left\\{\\mathbb{E}_{0}[g\\log g]\\leq\\frac{\\lambda}{n},\\mathbb{E}_{0}[g]=1,g\\geq0\\right\\}
$$  

其中L1 (pO)是相对于度量p0的L1空间。为了解决上面的优化问题，我们将其拉格朗日公式，  

$$
\\operatorname*{max}_{g\\in{\\mathcal{L}}_{1}({\\mathfrak{p}}_{0})}\\mathbb{E}_{0}[g f(X^{+})]-\\alpha\\left(\\mathbb{E}_{0}[g\\log g]-\\frac{\\lambda}{n}\\right)
$$  

其中αis为拉格朗日乘子。上述目标函数的解由以下命题给出[17,21]:  

命题1。在假设1下，当 $\\uprho\\uprho\\textrm{r}>0$ 足够大时，存在一个唯一的优化器(23)，由  

$$
g^{*}(\\mathbf{x}^{+})=\\frac{\\exp(\\frac{f(\\mathbf{x}^{+})}{\\alpha})}{\\mathbb{E}_{0}\\left[\\exp\\frac{f(X^{+})}{\\alpha}\\right]}
$$  

假设这样的 $\\mathrm{a}^{*}$ andg\\*exist和 $\\upalpha^{*}$ is足够大，则  

$$
\\frac{\\lambda}{n}=\\mathbb{E}_{0}[g^{*}\\log g^{*}]=\\frac{\\mathbb{E}_{0}[g^{*}f(X^{+})]}{\\alpha}-\\log\\mathbb{E}_{0}\\left[\\exp\\left(\\frac{f(X^{+})}{\\alpha^{*}}\\right)\\right]
$$  

$$
\\begin{array}{r l}&{=\\frac{\\beta^{*}\\mathbb{E}_{0}[f(X^{+})\\exp(\\beta^{*}f(X^{+}))]}{\\mathbb{E}_{0}[\\exp(\\beta^{*}f(X^{+}))]}-\\log\\mathbb{E}_{0}[\\exp\\beta^{*}f(X^{+})]}\\\\ &{\\qquad\\qquad\\qquad=\\beta^{*}\\psi^{'}(\\beta^{*})-\\psi(\\beta^{*})}\\end{array}
$$  

其中我们定义 $\\beta^{*}{=}_{\\mathrm{a}}1_{\\mathrm{{*}a n d}_{\\Psi}}(\\beta){=}\\log\\mathrm{E}0$ [ex $\\mathrm{p}({<}\\mathrm{s}{:}1{>}\\mathrm{F}(\\mathrm{X}\\!+\\!))$ 是 $\\mathrm{\\Delta_{F}(X+}$ 的对数矩生成函数)。  

我们可以将目标函数(22)的最优解写成  

$$
\\mathbb{E}_{0}[f(X^{+})g^{*}]=\\frac{\\mathbb{E}_{0}[f(X^{+})\\exp(\\frac{f(X^{+})}{\\alpha^{*}})]}{\\mathbb{E}_{0}[\\exp(\\frac{f(X^{+})}{\\alpha^{*}})]}=\\psi^{'}(\\beta^{*})
$$  

现在让我们对下面的式子进行泰勒展开  

$$
\\beta\\psi^{'}(\\beta)-\\psi(\\beta)=\\sum_{m=0}^{\\infty}\\frac{1}{m!}\\kappa_{m+1}\\beta^{m+1}-\\sum_{m=0}^{\\infty}\\frac{1}{m!}\\kappa_{m}\\beta^{m}
$$  

$$
=\\sum_{m=1}^{\\infty}\\left[\\frac{1}{(m-1)!}-\\frac{1}{m!}\\right]\\kappa_{m}\\beta^{m}
$$  

$$
=\\sum_{m=2}^{\\infty}\\frac{1}{m(m-2)!}\\kappa_{m}\\beta^{m}=\\frac{1}{2}\\kappa_{2}\\beta^{2}+\\frac{1}{3}\\kappa_{3}\\beta^{3}+\\frac{1}{8}\\kappa_{4}\\beta^{4}+O(\\beta^{5})
$$  

在上面的表达式中， $\\boldsymbol{\\kappa}\\mathbf{M}^{=}\\boldsymbol{\\Psi}^{(\\mathbf{M})(0)}$ 是 $\\psi$ with的m阶导数在 $\\scriptstyle\\beta=0$ 处求值，O(时延时延)在时延时延中是连续的。根据假设2，我们有 $\\kappa2>0_{\\circ}$ 因此，对于足够小的N<e:2>，上面的方程揭示了有一个小的 $\\beta^{*}\\mathfrak{s}^{0}\\overline{{\\mathfrak{r}}}$ 它是方程N $\\mid x\\times x\\times x\\times x\\times x\\times x\\times x$  

$X\\times\\times\\times\\times\\times\\times\\times\\times\\times\\times\\times\\times\\times\\times$ 的根，并且根是唯一的。这是因为根据假设2， $\\psi^{(.)}$ 是严格凸的，因此,  

$\\begin{array}{r}{\\overline{{\\mathrm{D}({\\upbeta}\\uppsi\\mathrm{-}\\uppsi({\\upbeta})^{\\ast}\\mathrm{\\Delta}{\\mathrm{D}\\upbeta})}}\\mathrm{=}\\beta\\uppsi({\\upbeta})\\mathrm{>}\\mathrm{\\Delta}0\\upbeta\\mathrm{>}\\mathrm{\\Delta}0,}\\end{array}$ 所以βú”(β)-4(β)是严格意义上的增加。  

由于 $\\scriptstyle{<_{\\mathrm{S}:1}>^{*}=\\beta1*}$ ，这表明对于任何足够小的 $\\mathrm{N}{<}\\mathrm{s}{:}2{>}$ ，我们可以找到一个大的 ${\\mathfrak{a}}^{*}{\\mathfrak{d}}$ ，使得24中对应的 $\\mathrm{G^{\\ast}}$ 满足 $\\lambda_{\\mathrm{\\cdotN}}^{\\mathrm{\\lambda}}{=}\\mathrm{E0}[\\mathrm{G^{*}l o g}\\mathrm{G^{*}}]\\mathrm{.}$ 。这 意味着我们可以写出下面的式子  

$$
\\frac{\\lambda}{n}=\\frac{1}{2}\\kappa_{2}{\\beta^{*}}^{2}+\\frac{1}{3}\\kappa_{3}{\\beta^{*}}^{3}+\\frac{1}{8}\\kappa_{4}{\\beta^{*}}^{4}+O({\\beta^{*}}^{5})
$$  

我们可以得到 $\\upbeta^{*}$ asfollow  

$$
\\beta^{*}=\\sqrt{\\frac{2\\lambda}{n\\kappa_{2}}}\\left(1+\\frac{2}{3}\\frac{\\kappa_{3}}{\\kappa_{2}}\\beta^{*}+\\frac{1}{4}\\frac{\\kappa_{4}}{\\kappa_{2}}{\\beta^{*}}^{2}+O(\\beta^{*^{3}})\\right)^{-\\frac{1}{2}}
$$  

$$
=\\sqrt{\\frac{2\\lambda}{n\\kappa_{2}}}\\left(1-\\frac{1}{3}\\frac{\\kappa_{3}}{\\kappa_{2}}\\beta^{*}+O{(\\beta^{*})}^{2}\\right)=\\sqrt{\\frac{2}{\\kappa_{2}}}\\left(\\frac{\\lambda}{n}\\right)^{1/2}-\\frac{2}{3}\\frac{\\kappa_{3}}{\\kappa_{2}^{2}}\\frac{\\lambda}{n}+O\\left(\\left(\\frac{\\lambda}{n}\\right)^{\\frac{3}{2}}\\right)
$$  

在土面的表达式中，首先我们使用二项展开式 $(1+\\#_{\\mathcal{T}}^{\\Sigma})_{-2}\\imath=1\\!-\\!12$ 粽棕 $\\cdot+8–3\\mathrm{X}2...$ 然后在第二项中替换成时延时延为时延的时延为时延的时延。现在，相应的最优解变成如下  

$$
\\mathbb{E}_{0}[f(X^{+})g^{*}]=\\psi^{'}(\\beta^{*})=\\kappa_{1}+\\kappa_{2}\\beta^{*}+\\kappa_{3}\\frac{{\\beta^{*}}^{2}}{2}+O(\\beta^{*^{3}})
$$  

$$
=\\kappa_{1}+\\sqrt{2\\kappa_{2}}\\left(\\frac{\\lambda}{n}\\right)^{\\frac{1}{2}}+\\frac{1}{3}\\frac{\\kappa_{3}}{\\kappa_{2}}\\frac{\\lambda}{n}+O\\left(\\left(\\frac{\\lambda}{n}\\right)^{\\frac{3}{2}}\\right)
$$  

在上面的方程 $\\scriptstyle\\mathtt{!K}1=\\mathtt{F}^{-},\\mathtt{\\hat{x}}^{2}\\,=\\mathrm{Var}_{\\mathrm{N}}[\\mathrm{F}(\\mathrm{X}+)],\\mathtt{K}3=\\mathrm{E}0[(\\mathrm{F}(\\mathrm{X}+)\\mathrm{-}\\mathrm{E}0[\\mathrm{F}(\\mathrm{X}+)))3]_{\\circ}$ 这就完成了定理2的证明。

# B更多具有挑战性的袋子的例子
图8显示了20NewsGroup数据集中来自三个不同主题的三个示例挑战袋的P_F图。如图所示，来自这些袋的最高r-score非常低。这意味着被动学习模型以高置信度预测所有实例为负。使用F-Entropy,由于不确定性低，我们可能无法从这些袋子中查询任何实例。相比之下，通过利用标准MIL假设，提出的P-F抽样将有效地探索这些袋子。我们的实验结果证明，一旦查询到这些包中的阳性实例，它们有助于准确识别相同和不同包中的相似阳性实例，从而提高实例预测性能。

# C链接到源代码
我们的实验源代码，请点击这里。",2
2cd5432a-efc7-4ca2-9340-0439ece15a4e,"ref_ids: 454846731731167836, chunk_ids: 9, Score: 0.2129, Text: # CFurther Discussions
We summarize some empirical observations as follows.  

1) The CLIP with four training tricks yields about $4\\%$ improvement at Rank-1 in Table 1 of the main paper. It can inspire future works in which the model performance could be boosted by applying these training tricks.  

2) Data augmentation and loss function are common technologies used in various methods. The investigation of more than 20 data augmentations and about 10 loss functions on performance in Tables 2-5 of the main paper provides valuable guidance on future works. Researchers can select proper and effective augmentations and losses into the model for improving performance.   
3) We explore the internal properties and functionalities of the model for the first time. These results can light future works on model compression, so as to develop a more lightweight and effective TBPS method.   
4) There are very little research on few-shot TBPS, while this paper makes a preliminary study on CLIP-based fewshot TBPS, providing valuable observation for future research direction.",2
