角色,内容,分镜
73280fb7-b826-4157-9dfd-3771e5ec66d8,蒸馏过程,1
73280fb7-b826-4157-9dfd-3771e5ec66d8,"### 问题：
在模型蒸馏的“蒸馏过程”中，为什么在训练学生模型时，除了使用硬标签损失（学生模型预测与真实标签之间的差异）外，还需要引入软标签损失（学生模型预测与教师模型预测之间的差异）？这两部分损失函数各自的作用是什么，它们如何共同帮助学生模型更好地模仿教师模型的性能？",1
73280fb7-b826-4157-9dfd-3771e5ec66d8,"ref_ids: 454846109840627474, chunk_ids: 5, Score: 0.5430, Text: # (2) Soft Label-Based KD for OD
In order to improve the performance of student models and reduce their dependence on ground truth labels, related works typically guide student models using soft labels or pseudo-labels output by teacher models [16] ,[19] ,[78] . In addition, we need to successfully use the predictions of teacher models as soft labels for student models, and we should also know how to reasonably assign the labels of teacher models, even the hard labels. For example,LADin [72] cansignificantlyimprovetheperformance of a student model with a lightweight teacher model, and the performance of the student model will in fact be superior to that of its teacher. LAD requires a trained teacher to provide guidance (soft and hard labels) for its student. However, in practice, it is difficult to obtain excellent teacher models capable of providing effective guidance information. Therefore, Zhang et al. [57] proposed a self-distillation framework for OD, called label-guided self-distillation (LGD), which can generate the required guidance information using only the internal relationship between objects. Moreover, there are also some other methods that have tried to obtain better OD results by combining soft and hard labels [39] ,[71] .  

In label guided KD-based OD models, pseudo-labels can also play important roles in the training of student models. For example, Feng et al. [97] proposed an adaptive pseudo-label selection strategy to selectively calculate the distillation loss using the pseudo-labels. The student model carries out feature learning by using pseudo-labels of the teacher model first, and fine-tunes the network according to the ground truth labels. This KD strategy can not only reduce the demand for labeled samples [59] ,[60] , but also achieves higher OD performance than traditional methods based on the single-stage KD strategy [142] .In addition, for KD-based 3D OD models, using high-beam point clouds with pseudo-labels to train student models is a good way to solve the problem of high-cost 3D sample data labeling; thus, low-beam pseudo-LiDAR needs to be generated by down-sampling high-beam point clouds [108] .  

2) Feature Distillation for OD: Another KD strategy for feature distillation in intermediate feature layers can also effectively improve the performance of OD models. In this subsection, we will provide an overview of different feature distillation strategies embedded in OD models, including the basic ideas of feature distillation, full trust feature distillation, selective trust feature distillation, and so on.  

In general, the methods based on feature distillation use the features output from the middle layers of teacher models to supervise the training of student models, so that the student models can mimic the features output from the teacher models to the greatest extent possible. The essence of the idea is to continuously optimize the loss function consisting of both the activation functions of the teacher and student models’ feature layers. Therefore, feature distillation is carried out by using a loss function to train the student model. A general formulation of the loss function for feature distillation has been provided by Gou et al. [10] :  

$$
{\\cal L}={\\cal L}_{F e a D}(f_{t}(x),f_{s}(x))={\\cal L}_{F}(\\Phi_{t}(f_{t}(x)),\\Phi_{s}(f_{s}(x))),
$$  

where $f_{t}(x)$ and $f_{s}(x)$ are the output features from the middle layers of the teacher and student models respectively. Considering that the different network structures of the teacher and student models may lead to different sizes of the output features from their middle layers, a transformation function $\\Phi(.)$ is used to match these features. $L_{F}(.)$ denotes the loss function between the features of teacher and student models.  

According to the related works on feature distillation published in recent years, there are two main distillation strategies employed for feature distillation on OD models: full trust feature distillation and selective trust feature distillation. In the below, we will provide a description of these methods in detail.  

(1) Full Trust Feature Distillation  

Full trust feature distillation means that the student model learns all the knowledge from the teacher model unconditionally, without considering whether the knowledge to be learned is correct or not. Methods based on full trust feature distillation can further be divided into global feature distillation and local feature distillation.  

Global Feature Distillation is an approach in which the student model imitates the entire feature maps of the middle layers of the teacher model. For example, the fast scene text detector uses all feature maps of the teacher model to guide the training of the student model [92] . In addition, the related works in [115] ,[116] , and [93] also designed their models through the strategy of full trust feature distillation. These methods are in essence the applications of the most basic feature distillation strategy; they do not make any improvements to the feature maps, but instead simply guide the student models to learn all feature information directly from the teacher models. However, there are limitations on the capacity to improve the performance of student models by learning the global features of the teacher model indiscriminately. Therefore, researchers have gradually explored optimizing the output feature maps to further improve the performance of student models. For example, Qi et al. [24] aligned the feature maps at different resolutions using a feature pyramid, dynamically fused these features, and finally extracted these fused features from the teacher model to provide better guidance to the student model. The work of He et al. [88] ranks the feature maps by calculating the channel strengths of these feature maps in the teacher and student models for feature distillation. The feature distillation strategies proposed in [24] and [88] perform knowledge learning between the same layers of the teacher and student models; moreover, the multi-layer feature maps of the teacher model can also be used to guide the single-layer feature learning of the student model [28] ,[89] .  

Local Feature Distillation refers to the simulation of a student model learning those local features that are more helpful for the final prediction, rather than the entire feature maps of the teacher model. In recent years, an increasing number of related works have explored corresponding distillation strategies for local feature learning; these methods mainly try to learn the visual features at key locations in the feature maps. Chen et al. [70] used a region distillation strategy to train a lightweight pedestrian detector that crops features corresponding to RoI regions, after which the cropped local feature maps are used as the guidance information for the student model. In addition, the anchors in object detectors are widely used to locate the key local features for training student models [17] ,[91] ,[95] ; these anchors can also be ranked to enable the student model to learn feature maps with different significance [143] . It can be readily observedthatthelocalfeaturedistillationintheabovementioned methods is performed directly around the feature maps. The attentional mechanisms can also be used to make the student models pay more attention to the key local visual features. For example, spatial attention on feature maps is introduced for local feature distillation [144] , while the attention mechanism used to highlight foreground regions as well as contextual information is also helpful for OD [47] . Furthermore, Yang et al. [76] considered that the teacher and student models pay different levels of attention to the foreground and background, while the uneven differences in the feature maps in turn impact the effect of KD. Therefore, these authors proposed a strategy combining focal distillation and global distillation, in which focal distillation is guided to the student model by using spatial and channel attention masks during model training. The goal here is to make the student model focus only on the key pixels and channels on the feature map, thereby improving the performance of the student model. There are also some other local feature distillation strategies, such as the key proposal generation of the student and teacher models for local feature distillation [75] .  

These above mentioned OD methods based on whether global feature distillation or local feature distillation place full trust in the guidance information of the teacher model. However, it shouldbenotedthattheguidancefeatureinformationusedbythe teacher model to supervise the training of the student model may be incomplete or even incorrect, which has a negative impact on the performance improvements of the student model.  

(2) Selective Trust Feature Distillation  

To address the detrimental effects on the student model of incorrectinformationprovidedbytheteachermodel,thestrategy of selective trust feature distillation is introduced in KD-based OD models. Selective trust feature distillation means that the guidance information provided by the teacher model to the student model should be selected first: in short, it is necessary to remove the incorrect information and leave only the feature information that has a positive impact on the detection performance. For example, Heo et al. [145] proposed a margin ReLu to suppress the unfavorable feature information from the teachermodel,sothatthestudentmodellearnsonlythefavorable features and thus achieves performance improvement.  

In summary, whether full trust feature distillation or selective trust feature distillation is employed, this is ultimately optimized through the loss function. However, it is challenging to quickly and accurately select the substantial and beneficial features from the large amount of prior guidance information provided by the teacher model. There are thus many scientific problems worthy of further study associated with OD models based on selective trust KD.  

3) Various Network Structures of Teacher-Student Models: ThissectionwillexploretheKDstrategyfromanewperspective. Specifically, we found that different network structures can be designed for the teacher and student models respectively, and the knowledge extracted from multimodal data can facilitate significant performance improvements on the part of the student model. Therefore, this section will summarize and analyze the network structures of the teacher-student models and the feature learning from multimodal data.  

ItisacommonKDstrategythattheteacherandstudentmodels have similar network structures. Many different backbone networks have been adopted by teacher and student models, such as ResNet [18] ,[58] , ResNext [146] , SSD [80] , VGG [146] ,and so on. In addition, some studies do not directly use the classical network model as the backbone network, but instead adjust existing networks [32] ,[138] . However, these methods areKD-basedODmodelsusingtraditionaldistillationstrategies, whether they directly use typical networks or employ adjusted networks as the backbone of the teacher and student models. Most KD-based OD models with similar teacher-student network structures extract the knowledge from single-modal data (RGB images), although there also are some methods that try to learn knowledge from other modalities for guiding the lightweight student model. For example, the student model can learn semantic knowledge provided by the teacher model [111] ,learn the textual and visual features extracted by the teacher model on text information [147] , or jointly learn the visual features from RGB images and heat-like images under the guidance of the trained teacher model on these two modes of data [14] .  

Furthermore, for 3D OD, there are also common approaches involving teacher and student models using similar network structures as their backbones. For example, Wei et al. [108] opt to use the KD strategy to generate a lightweight 3D detector; here, the network structure of teacher and student models in the distillation framework is the same 3D convolutional neural network. In addition, ItKD, designed by Cho et al. [106] ,uses an autoencoder in combination with KD to improve the performance of a 3D object detector. The teacher and student models in ItKD are composed of the same backbone CenterPoint and autoencoder, and the same point cloud data is used for training the teacher and student networks. In the KD-based 3D OD tasks, multi-modal data is also used as the input of the distillation models. In methods employing this strategy, the student model is trained using 3D point cloud data, while the teacher model is trained using other modalities. For example, Qin et al. [31] proposed a cross-modal KD method, in which RGB images are used to train the teacher model and the point cloud is used to train the student model. This method aims to transfer the knowledge from the RGB domain to the point cloud domain, thereby reducing the labeling cost of 3D OD. Moreover, multimodal data can be used to train the teacher model, which is more beneficial to the performance of the student model [45] ,[109] . Multimodal data (LiDAR-image, which consists of point clouds and RGB images after segmentation) is used for training the teacher model in [45] ,[109] ; here, the student model is expected to learn the knowledge from the teacher model and to obtain the similar outputs to the teacher model using only LiDAR.  

(2) Different Network Structures of Teacher and Student Models  

Another KD strategy involves the teacher and student models using different network structures as their backbones. For example, the method in [82] uses DarkNet-53 based SSD as the teacher model’s backbone and MobileNet v2/ShuffleNet v1 as the student model’s backbone. Su et al. [55] use ResNet-based networksastheteachermodel’sbackboneandaself-built3-layer CNN as the student model’s backbone. A similar strategy is used in [5] . In addition to those listed above, there are also many more similar methods with different combinations of teacher-student models. Notably, while the teacher and student models can choose various networks as their own backbones, it is necessary to choose the appropriate networks according to the specific problems to be solved, especially given the lack of capacity of the student model. Similarly, different network structures can also be used for KD-based 3D OD tasks. Sautier et al. [46] use a 2D-to-3D distillation strategy to improve 3D OD in an autonomous driving context. The backbone of the teacher model is ResNet50 trained with RGB images, and the student model uses U-Net as its backbone trained with LiDAR data. The final experiments show that the model with this strategy outperforms the state-of-the-art methods.  

  
Fig. 5. The structure of multiple teacher models guiding one student model to learn the knowledge.  

This section lists several KD-based OD models using various teacher-student model network structures. Similar/different networks are used as the backbones of the teacher and student models to extract features from multimodal data. Through analysis of the existing relevant methods, we determine that the methods using different network structures as the backbone of the teacher model to extract knowledge from the multi-modal data have relatively more advantages, when it comes to guiding the feature learning of the student models. However, there are no fixed KD strategies of combining teacher-student model structures and multimodal data, we should design/choose appropriate networks for KD according to the specific tasks.  

4) Multiple Teacher Models: KD is similar to the learning processes used by humans. The traditional technology of KD involves a teacher model guiding a student model to learn the knowledge. Notably, however, human teaching activities involve morepatternsthantraditionalKD.Therefore,severalKDmodels based on human teaching patterns have been proposed.  

(1) Multiple Teachers Guiding One Student  

As previously discussed, the first commonly used human teaching mode is that in which multiple teachers teach one student. For example, if teachers with different areas of specialization all teach one student, the student can acquire higher-quality knowledge. Similarly, we can use different types of teacher models to learn different knowledge from large-scale datasets, then try to transfer the learned knowledge to one student model, so as that this student model can learn more comprehensive and significant visual features, as shown in Fig. 5 . For example, in [37] ,[53] ,[54] , multiple teacher models are used to guide one student model to improve its OD performance. There are some key differences between these three works: Kuang et al. [53] carried out weighted fusion of different teacher models to improve the accuracy of OD networks; Chen et al. [37] used two teacher networks trained with different strategies to ensure that the knowledge could be fully transferred to the student network; Li et al. [54] designed an asymmetric two-path learning framework to train the student model.  

(2) One Teacher Guiding Multiple Students  

The second commonly used teaching pattern is that one teacher teaches multiple students. For example, multiple student models are guided by one teacher model, after which one student model with the best performance is selected from all the student models. The work in [65] uses a KD framework in which one teacher model guides multiple student models to solve the problem of Siamese trackers being limited by high cost.",1
73280fb7-b826-4157-9dfd-3771e5ec66d8,"ref_ids: 454845516142612392, chunk_ids: 12, Score: 0.5430, Text: # Learning From Biased Soft Labels
Hua Yuan, Ning Xu, Yu Shi, Xin Geng and Yong Rui

# Abstract
Knowledge distillation has been widely adopted in a variety of tasks and has achieved remarkable successes. Since its inception, many researchers have been intrigued by the dark knowledge hidden in the outputs of the teacher model. Recently, a study has demonstrated that knowledge distillation and label smoothing can be unified as learning from soft labels. Consequently, how to measure the effectiveness of the soft labels becomes an important question. Most existing theories have stringent constraints on the teacher model or data distribution, and many assumptions imply that the soft labels are close to the ground-truth labels. This paper studies whether biased soft labels are still effective. We present two more comprehensive indicators to measure the effectiveness of such soft labels. Based on the two indicators, we give sufficient conditions to ensure biased soft label based learners are classifier-consistent and ERM learnable . The theory is applied to three weakly-supervised frameworks. Experimental results validate that biased soft labels can also teach good students, which corroborates the soundness of the theory.

# 1 Introduction
Recently, knowledge distillation Buciluˇa et al. (2006 ); Ba and Caruana (2014 ); Hinton et al. (2015 )has engendered remarkable achievements in a wide range of applications. Although it was firstly proposed for model compression by distilling knowledge from the big model (teacher) to the small model (student), considerable efforts have been devoted to figuring out the dark knowledge hidden in the outputs of the teacher model. The dark knowledge is compatibly utilized for transfer learning Vapnik et al. (2015 ); Zagoruyko and Komodakis (2016a ); Noroozi et al. (2018 ).  

In practice, the student loss is defined as the tradeoffbetween imitating the ground-truth label and imitating the output of the teacher model. Many studies Rusu et al. (2015 ); Furlanello et al. (2018 ) have demonstrated that learning from the teacher model can be more effective than the ground-truth labels. This seems counterintuitive since it challenges the correctness of the groundtruth labels. Apart from knowledge distillation, label smoothing Szegedy et al. (2016 ); Zoph et al. (2018 ) also softens the labels by incorporating uniform noise, which is a useful trick to improve generalization. Knowledge distillation and label smoothing are often analyzed together, and Yuan et al. (2020 ) elucidates that they can be unified as learning from soft labels. The essence of both is why the soft labels are effective.  

In this paper, we mainly focus on the effectiveness of these soft labels. To be clarified, this paper investigates when the soft labels are effective, rather than when the soft labels are superior to ground-truth labels. It is apparent that, when the soft labels are close to the ground-truth labels, the student model will have an adequate performance. A straightforward question is,  

  
Figure 1: (a) Images of the birds in CIFAR-10. (b) Defective knowledge distillation with $\\alpha=0.9$ and $\\tau=20$ . (c) Label smoothing with $\\alpha=0.9$ . (d) Our customized soft labels.  

Yuan et al. (2020 ) empirically demonstrates the poorly-trained teacher model can also improve the student model. However, it sets the tradeoff $\\alpha=0.9$ and temperature $\\tau=20$ , which means the defective soft labels are still close to the ground-truth label. Figure 1 illustrates defective soft labels, label smoothing (with $\\alpha=0.9$ ) and our customized soft labels (detailed in subsection 3.3 ).  

To measure the effectiveness of the soft labels, without accuracy, we propose two intuitive indicators, unreliability degree and ambiguity degree. Furthermore, based on the two indicators, we prove that learning from the biased soft labels is classifier-consistent and Empirical Risk Minimizing (ERM) learnable under a moderate condition. The theory is applicable not only to learning from poor teachers, but to all soft label based learners. This result significantly extends the application scope of soft labels. We apply it to three classic weakly-supervised frameworks: parital label learning, learning with additive noise, learning with incomplete data.  

Among the weakly-supervised frameworks, soft labels of parital label learning and additive noise are spoiled by human or during collection. In incomplete supervision, where only part of the data is labeled, the typical strategy is to label the unlabeled data and learn with all data iteratively. Soft labels in these weakly-supervised frameworks are usually biased and we provide a guarantee for the learners in these fields. Specifically, for the incomplete data, we delineate the dynamics of the model performance with an ideal accuracy funtion and give conditions to ensure the existence of the final accuracy.  

To illustrate the soundness of our theory, we train the teacher models with some heuristic losses to generate soft labels with low accuracy but fulfilling the criteria in Theorem 3.2 . Training on these biased soft labels, the student model can achieve an adequate performance as if training on ground-truth labels, which is consistent with our theory. In addition, the experiments of weaklysupervised learning also validate the effectiveness of biased soft labels. Our contributions can be summarized as follows:  

•We focus on the effectiveness of soft labels and find that learning from biased soft labels may also achieve an adequate performance. A heuristic method is devised to generate biased soft labels that can train a good student.   
•We give sufficient conditions to guarantee the effectiveness of the soft labels. It is proved that learning from such soft labels is classifier-consistent and ERM learnable. Experimental results validate our theory.   
•Our theory is applied to three weakly-supervised frameworks where the soft labels are biased. In incomplete supervision, We delineate the dynamics of the model performance with an ideal  

accuracy function, and give the final accuracy.",1
73280fb7-b826-4157-9dfd-3771e5ec66d8,"ref_ids: 454846239382763602, chunk_ids: 3, Score: 0.5430, Text: # Model Optimization
Training. Our framework first undergoes a preprocessing phase in which the teacher model is trained on real seen samples. The teacher model then extracts knowledge, either in the form of logits or as intermediate features. This extracted knowledge is subsequently used to guide the training of the student model during the distillation process. The cross-entropy loss in the preprocessing phase is as follows:  

$$
\\mathcal{L}_{p r e}(x,y)=-\\sum_{i=1}^{S}y^{(i)}\\log\\frac{\\exp(\\phi(x)^{(i)})/\\tau_{o})}{\\sum_{k=1}^{S}\\exp(\\phi(x)^{(k)})/\\tau_{o})}.
$$  

After completing the pre-training of the OOD detection model, we jointly train the FG, $\\mathrm{ID^{2}\\bar{S}D}$ and $\\mathrm{O^{2}D B D}$ end-toend. We utilize the real seen samples $x^{\\prime}$ and the unseen samples $x^{\\prime\\prime}$ generated by the FG as inputs for the $\\mathrm{ID^{2}S D}$ module. Then, we calculate the OOD confidence labels from the output of the teacher network, and map the softmax probability of student network to the OOD representation embedding space. Thus, the total loss of $\\mathrm{D^{3}G Z\\bar{S}L}$ is formulated as:  

$$
\\operatorname*{min}_{G,E_{s},C_{s},H}\\mathcal{L}_{g e n}+\\lambda(\\mathcal{L}_{i d}+\\mathcal{L}_{o d}),
$$  

<html><body><table><tr><td rowspan=""2"">Method</td><td colspan=""3"">AWA1</td><td colspan=""3"">AWA2</td><td colspan=""3"">CUB</td><td colspan=""3"">FLO</td></tr><tr><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td></tr><tr><td>cycle-CLSWGAN (Felixet al. 2018)</td><td>56.9</td><td>64.0</td><td>60.2</td><td>-</td><td>-</td><td></td><td>45.7</td><td>61.0</td><td>52.3</td><td>59.2</td><td>72.5</td><td>65.1</td></tr><tr><td>CADA-VAE (Schonfeld et al.2019)</td><td>57.3</td><td>72.8</td><td>64.1</td><td>55.8</td><td>75.0</td><td>63.9</td><td>51.6</td><td>53.5</td><td>52.4</td><td></td><td></td><td></td></tr><tr><td>LisGAN (Li et al.2019)</td><td>52.6</td><td>76.3</td><td>62.3</td><td></td><td></td><td></td><td>46.5</td><td>57.9</td><td>51.6</td><td>57.7</td><td>83.8</td><td>68.3</td></tr><tr><td>IZF (Shen et al. 2020)</td><td>61.3</td><td>80.5</td><td>69.6</td><td>60.6</td><td>77.5</td><td>68.0</td><td>52.7</td><td>68.0</td><td>59.4</td><td></td><td></td><td>-</td></tr><tr><td>SE-GZSL (Kim,Shim,and Shim 2022)</td><td>61.3</td><td>76.7</td><td>68.1</td><td>59.9</td><td>80.7</td><td>68.8</td><td>53.1</td><td>60.3</td><td>56.4</td><td></td><td></td><td></td></tr><tr><td>TDCSS (Feng et al. 2022)</td><td>54.4</td><td>69.8</td><td>60.9</td><td>59.2</td><td>74.9</td><td>66.1</td><td>44.2</td><td>62.8</td><td>51.9</td><td>54.1</td><td>85.1</td><td>66.2</td></tr><tr><td>DUET (Chen et al. 2023)</td><td></td><td></td><td>-</td><td>63.7</td><td>84.7</td><td>72.7</td><td>62.9</td><td>72.8</td><td>67.5</td><td></td><td></td><td>1</td></tr><tr><td>GKU (Guo et al. 2023)</td><td></td><td></td><td></td><td></td><td>-</td><td>-</td><td>52.3</td><td>71.1</td><td>60.3</td><td></td><td></td><td></td></tr><tr><td>f-CLSWGAN(Xianet al.2018b)</td><td>57.9</td><td>61.4</td><td>59.6</td><td></td><td></td><td></td><td>43.7</td><td>57.7</td><td>49.7</td><td>59.0</td><td>73.8</td><td>65.6</td></tr><tr><td>f-CLSWGAN+D?GZSL</td><td>57.1</td><td>69.8</td><td>62.8</td><td></td><td></td><td></td><td>52.3</td><td>61.5</td><td>56.5</td><td>61.1</td><td>86.7</td><td>71.7</td></tr><tr><td>TF-VAEGAN (Narayan et al. 2020)</td><td></td><td>-</td><td>-</td><td>59.8</td><td>75.1</td><td>66.6</td><td>52.8</td><td>64.7</td><td>58.1</td><td>62.5</td><td>84.1</td><td>71.7</td></tr><tr><td>TF-VAEGAN+D?GZSL</td><td>-</td><td></td><td></td><td>60.2</td><td>74.9</td><td>66.8</td><td>57.3</td><td>64.5</td><td>60.7</td><td>65.6</td><td>81.4</td><td>72.7</td></tr><tr><td>DDGAN</td><td>58.1</td><td>63.5</td><td>60.7</td><td>61.7</td><td>68.4</td><td>64.9</td><td>47.5</td><td>61.5</td><td>53.6</td><td>61.1</td><td>85.2</td><td>71.2</td></tr><tr><td>DDGAN+D?GZSL</td><td>59.5</td><td>68.3</td><td>63.6</td><td>62.9</td><td>67.7</td><td>65.2</td><td>54.2</td><td>59.7</td><td>56.8</td><td>63.4</td><td>82.1</td><td>71.5</td></tr><tr><td>CE-GZSL(Han et al.2021)</td><td>65.3</td><td>73.4</td><td>69.1</td><td>63.1</td><td>78.6</td><td>70.0</td><td>63.9</td><td>66.8</td><td>65.3</td><td>69.0</td><td>78.7</td><td>73.5</td></tr><tr><td>CE-GZSL+D?GZSL</td><td>65.7</td><td>76.2</td><td>70.5</td><td>64.6</td><td>76.7</td><td>70.1</td><td>66.7</td><td>69.1</td><td>67.8</td><td>68.6</td><td>80.9</td><td>74.2</td></tr></table></body></html>  

whe and L$\\mathcal{L}_{o d}$ $\\lambda$ towards the generator. is the hyper-parameters indicating the effect of $\\mathcal{L}_{i d}$  

Inference. We no longer train a separate classifier for classification. Once the training is completed, we map the $D_{t e}=\\{x_{i},y_{i}\\}_{i=N+1}^{N+M}$ to the embedding space using the embedding function $E_{s}$ of the student network. Then, we employ the classifier $C_{s}$ to predict the class label $\\hat{y}$ :  

$$
\\hat{y}=\\arg\\operatorname*{max}_{i}\\frac{\\exp(\\psi(x)^{(i)})}{\\sum_{k=1}^{S+U}\\exp(\\psi(x)^{(k)})}.
$$

# Experiment
Datasets. We perform experiments on four ZSL benchmark datasets that are widely used: the Animals with Attributes1&2 (AWA1 (Lampert, Nickisch, and Harmeling 2013) & AWA2 (Xian et al. 2018a)) dataset, Caltech-UCSD Birds-200-2011 (CUB (Wah et al. 2011)) dataset, and Oxford Flowers (FLO (Nilsback and Zisserman 2008)) dataset.  

Evaluation Protocols. We evaluate the top-1 accuracy separately on both seen classes $(S)$ and unseen classes $(U)$ in the generalized zero-shot learning (GZSL). We also use mean of these two accuracies $\\langle H=(2\\times S\\times$ $U)/(S+U))$ ) as a performance measure for GZSL.  

Implementation Details. We set the embedding dimension $z$ to 2048 on all datasets. The classifier $C_{s}$ outputs logits on all classes, and the classifier $C_{o}$ outputs logits on seen classes. The projector $H$ maps softmax probabilities into a two-dimensional space that encodes both ID and OOD information. The input noise dimension $w$ in the generator is equal to that of the corresponding attributes. In batch distillation, instances of the same class within a batch serve as positive samples for each other, while those of different class are treated as negative samples. Here are some of the parameter settings when employing f-CLSWGAN as the baseline model. We set batch size of 4096 for AWA1, 256 for CUB, 512 for FLO. The number of generated samples for each unseen category is as follows: 200 for AWA1, 5 for CUB, and 30 for FLO. We empirically set the loss weights $\\lambda=0.0001$ for AWA1, CUB. We set $\\lambda=0.001$ for FLO.

# Comparisons with Previous Methods
In Table 1, we applied our framework to three previous baseline methods and the DDGAN which is a new generative method of ZSL we introduced to demonstrate the improvement of our framework on diffusion models. The results show that we achieved improvements on the AWA1, AWA2, CUB, and FLO datasets. The most significant improvement was observed with the f-CLSWGAN method, with increases of $3.2\\%$ on the AWA1 dataset, $6.8\\%$ on the CUB dataset, and $6.1\\%$ on the FLO dataset. The best-performing dataset was CUB, with improvements of $6.8\\%$ ,$2.6\\%$ ,$2.5\\%$ , and $3.2\\%$ on the four baseline methods, respectively.  

Within the CE-GZSL baseline, our $H$ metric delivered the top performance on the AWA1, CUB, and FLO datasets, while ranking second on the AWA2 dataset, only surpassed by DUET (Chen et al. 2023). Strikingly, when compared to the $S$ metric, our $U$ metric demonstrated a substantial improvement, achieving the highest scores on AWA1, AWA2 and CUB, with $65.7\\%$ ,$64.6\\%$ and $66.7\\%$ respectively. It also secured the second-highest performance on the FLO dataset, recording $68.6\\%$ . The experimental results demonstrate that aligning the distribution of generated samples with that of real samples through out-of-distribution detection is an effective method to address seen bias.

# Ablation Study
Training Strategy Analysis. In this section, we compare the outcomes of three different experimental groups. Table 2 shows the comparison results. The first comprises our proposed one-stage end-to-end training method. The second involves a Two-Stage (TS) classification method based on OOD detection. The third represents an idealized version of the Two-Stage (IV-TS) classification method based on OOD detection. This idealized experiment is designed to simulate the performance of seen and unseen expert classifiers under conditions where the process of OOD detection can classify seen and unseen samples with complete accuracy. In an ideal scenario, the results of the domain expert classifiers surpass those of our method. In fact, the OOD detection in TS cannot achieve a $100\\%$ accuracy rate. Some data that is not within the training distribution is mistakenly assigned to the expert classifiers for classification. This results in the performance of the TS approach being inferior to that of our proposed method because of the compounding of errors from OOD detection and the expert classifiers (error accumulation).  

<html><body><table><tr><td rowspan=""2"">Method</td><td rowspan=""2"">IV-TS</td><td rowspan=""2"">TS</td><td rowspan=""2"">Ours</td><td colspan=""3"">AWA1</td><td colspan=""3"">AWA2</td><td colspan=""3"">CUB</td><td colspan=""3"">FLO</td></tr><tr><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td></tr><tr><td rowspan=""3"">f-CLSWGAN</td><td>√</td><td></td><td></td><td>67.4</td><td>88.9</td><td></td><td></td><td></td><td></td><td>56.1</td><td>70.0</td><td></td><td>65.2</td><td>87.4</td><td></td></tr><tr><td></td><td>√</td><td></td><td>58.9</td><td>71.8</td><td>64.7</td><td></td><td></td><td></td><td>39.7</td><td>46.1</td><td>42.7</td><td>60.6</td><td>62.3</td><td>61.4</td></tr><tr><td></td><td></td><td>人</td><td>57.1</td><td>69.8</td><td>62.8</td><td></td><td></td><td></td><td>52.3</td><td>61.5</td><td>56.5</td><td>61.1</td><td>86.7</td><td>71.7</td></tr><tr><td rowspan=""3"">CE-GZSL</td><td></td><td></td><td></td><td>69.2</td><td>88.3</td><td></td><td>69.7</td><td>91.8</td><td>=</td><td>78.7</td><td>73.5</td><td></td><td>68.1</td><td>89.4</td><td></td></tr><tr><td></td><td>√</td><td></td><td>57.5</td><td>72.3</td><td>64.1</td><td>55.5</td><td>76.7</td><td>64.4</td><td>61.1</td><td>42.8</td><td>50.3</td><td>58.3</td><td>70.8</td><td>64.0</td></tr><tr><td></td><td></td><td>√</td><td>65.7</td><td>76.2</td><td>70.5</td><td>64.6</td><td>76.7</td><td>70.1</td><td>66.7</td><td>69.1</td><td>67.8</td><td>68.6</td><td>80.9</td><td>74.2</td></tr></table></body></html>

Table 2: The performance comparison of our proposed $\\mathrm{D^{3}G Z S L}$ framework (our), the two-stage classification method based on OOD detection (TS) and idealized version of the two-stage classification method based on OOD detection (IV-TS).  

<html><body><table><tr><td>Datasets</td><td>Baseline ID²SD</td><td>O'DBD</td><td>U</td><td>S</td><td>H</td></tr><tr><td rowspan=""4"">CUB</td><td>×</td><td>×</td><td>50.4</td><td>59.8</td><td>54.7</td></tr><tr><td>√</td><td>×</td><td>49.4</td><td>63.8</td><td>55.6</td></tr><tr><td>×</td><td></td><td>51.3</td><td>59.6</td><td>55.1</td></tr><tr><td>人 人</td><td>人</td><td>52.3</td><td>61.5</td><td>56.5</td></tr><tr><td rowspan=""4"">FLO</td><td>√</td><td>×</td><td>×</td><td>58.6</td><td>83.3</td><td>68.8</td></tr><tr><td></td><td>人</td><td>×</td><td>61.8</td><td>84.3</td><td>71.3</td></tr><tr><td></td><td>×</td><td></td><td>59.9</td><td>86.3</td><td>70.7</td></tr><tr><td>√</td><td></td><td>√</td><td>61.1</td><td>86.7</td><td>71.7</td></tr></table></body></html>  

Table 3: The baseline model includes the FG and the classification los losses, while O $\\mathrm{O^{2}D B D}$ $\\mathcal{L}_{c l s}$ DBD represents the use of $\\mathrm{ID^{2}S D}$ indicates the us L$\\mathcal{L}_{o d}$ loss. $\\mathcal{L}_{b e}$ and $\\mathcal{L}_{k l}$   
Table 4: The performance of our framework is demonstrated under various OOD detection methods, employing f-CLSWGAN as the baseline model in our framework.   


<html><body><table><tr><td rowspan=""2"">Method</td><td colspan=""3"">CUB</td><td colspan=""3"">FLO</td></tr><tr><td>U</td><td>S</td><td>H</td><td>U</td><td>S</td><td>H</td></tr><tr><td>Baseline</td><td>43.7</td><td>57.7</td><td>49.7</td><td>59.0</td><td>73.8</td><td>65.6</td></tr><tr><td>Energy</td><td>49.1</td><td>62.3</td><td>54.9</td><td>60.3</td><td>87.2</td><td>71.3</td></tr><tr><td>Softmax</td><td>52.3</td><td>61.5</td><td>56.5</td><td>61.1</td><td>86.7</td><td>71.7</td></tr></table></body></html>  

Component Analysis. Here, we set up an ablation study to examine the impact of various components on our $\\mathrm{D^{3}G Z S L}$ framework. The baseline model includes the FG and the classification loss experiments on two benchmark datasets to validate the in$\\mathcal{L}_{c l s}$ . We conducted three sets of dividual and combined effects of our $\\mathrm{ID^{2}S D}$ and $\\mathrm{O^{2}D B D}$ modules. Through the experimental results presented in Table 3, we can draw the following conclusions: (1) Employing modules $\\mathrm{ID^{2}S D}$ and $\\mathrm{O^{2}D B\\bar{D}}$ separately has led to an enhancement in our performance over the baseline method. (2) When the two modules operate in conjunction, there is a marked enhancement in performance on the $H$ metric. This suggests that our framework is effective in reducing the discrepancy between the distribution of generated samples and the distribution of real samples. It accomplishes this by optimizing both the in-distribution and out-of-distribution aspects, thereby creating a more cohesive alignment between the two distributions.  

OOD Scoring Strategy Analysis. In this paper, we experimented with two different architectures to verify the impact of using different OOD detection methods on our framework. We conducted experiments using two methods, Softmax score (Hendrycks and Gimpel 2016) and Energy (Liu et al. 2020), on the f-CLSWGAN baseline model. The experimental results in Table 4 showed that no matter which architecture was used, the performance was significantly improved. This provides strong evidence for our framework, demonstrating its effective adaptability and scalability, and its ability to be successfully applied to different architectures.",1
