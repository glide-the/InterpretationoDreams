{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c82d29-20bd-47b0-85fa-e5a8711a55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dreamsboard -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54271263-a5c7-4584-9dc9-7efb51113e60",
   "metadata": {},
   "source": [
    "### 介绍\n",
    "使用langchain进行任务规划，构建子任务的会话场景资源，通过MCTS任务执行器，来让每个子任务通过在上下文中资源，通过自身反思探索来获取自身对问题的最优答案；这种方式依赖模型的对齐偏好，我们在每种偏好上设计了一个工程框架，来完成自我对不同答案的奖励进行采样策略\n",
    "\n",
    "\n",
    "## 使用\n",
    "\n",
    "### 构建任务\n",
    "\n",
    "- 初始化任务引擎 StructuredTaskStepStoryboard传入需要的任务\n",
    "\n",
    "- loader_task_step_iter_builder 构建任务的子任务，完成后SimpleTaskStepStore可获取子任务信息\n",
    "\n",
    "- init_task_engine_dreams 初始化场景加载资源，对子任务进行规划，获取会话的资源信息\n",
    "\n",
    "```\n",
    "\n",
    "    os.environ[\"AEMO_REPRESENTATION_PROMPT_TEMPLATE\"] = AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST\n",
    "    os.environ[\"STORY_BOARD_SCENE_TEMPLATE\"] = STORY_BOARD_SCENE_TEMPLATE_TEST\n",
    "    os.environ[\"STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE\"] = STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST\n",
    "    os.environ[\"EDREAMS_EVOLUTIONARY_TEMPLATE\"] = EDREAMS_EVOLUTIONARY_TEMPLATE_TEST\n",
    "    os.environ[\"EDREAMS_PERSONALITY_TEMPLATE\"] = EDREAMS_PERSONALITY_TEMPLATE_TEST\n",
    "    os.environ[\"DREAMS_GEN_TEMPLATE\"] = DREAMS_GEN_TEMPLATE_TEST\n",
    "```\n",
    "\n",
    "- init_task_engine_storyboard_executor 构建会话场景执行器，初始化一个会话\n",
    "\n",
    "- storyboard_code_gen_builder 构建会话场景执行器, 对会话存储进行加载，加载失败重新构建\n",
    "\n",
    "- generate_step_answer 通过会话场景 获取任务的答案\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0192e12b-5e15-4c43-b20e-1a46d3334aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/weaviate/init_networkx_concept.py:9: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "from dreamsboard.engine.storage.task_step_store.simple_task_step_store import SimpleTaskStepStore\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dreamsboard.dreams.builder_task_step.base import StructuredTaskStepStoryboard\n",
    "from dreamsboard.engine.utils import concat_dirs\n",
    "from dreamsboard.engine.storage.task_step_store.types import DEFAULT_PERSIST_FNAME\n",
    "from dreamsboard.common.try_parse_json_object import try_parse_json_object\n",
    "from dreamsboard.engine.memory.mctsr.prompt import RefineResponse\n",
    "from dreamsboard.dreams.task_step_md.base import TaskStepMD\n",
    "from dreamsboard.common import _get_assistants_tool\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from dreamsboard.dreams.task_step_to_question_chain.weaviate.prepare_load import get_query_hash\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 控制台打印\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7950075d-2cbc-4eea-932b-e2928e4b0e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:460: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response = response.dict()\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:460: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response = response.dict()\n",
      "/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/storage/task_step_store/utils.py:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  DATA_KEY: doc.dict(),\n",
      "73d44403-c400-4948-967f-1c884e56e9a8\n",
      "62265bf6-3bed-4ced-a662-390fc0524848\n",
      "7e7979ce-c5b1-4c9c-8fec-2a7b469c8f9c\n",
      "42dd0728-7a06-4cc2-9385-b484a5be6362\n",
      "286b9f75-7989-4f61-b387-148fff268a19\n",
      "d890e1a4-2a4a-4aad-bf00-4d8bbdb726e7\n",
      "9b6fafc8-e6c8-4661-b809-c33ace5f6bc4\n",
      "fdb2fd2f-5ded-41a5-a43c-2a179f7ca441\n",
      "64db7ee7-af18-49c3-96c4-1c3d752da151\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"5fae8f96c5ed49c2b7b21f5c6d74de17.A0bcBERbeZ1gZYoN\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"ZHIPUAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://open.bigmodel.cn/api/paas/v4\"\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base='https://open.bigmodel.cn/api/paas/v4',\n",
    "    model=\"glm-4-plus\",\n",
    "    openai_api_key=os.environ.get(\"ZHIPUAI_API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "kor_dreams_task_step_llm = ChatOpenAI(\n",
    "    openai_api_base='https://open.bigmodel.cn/api/paas/v4',\n",
    "    model=\"glm-4-plus\",\n",
    "    openai_api_key=os.environ.get(\"ZHIPUAI_API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.95,\n",
    "    top_p=0.70,\n",
    ")\n",
    "\n",
    "\n",
    "tools= [ { \"type\": \"web_search\",   \"web_search\": {\"enable\": False ,\"search_result\": False   }}]\n",
    "llm_with_tools = llm.bind(   tools=[_get_assistants_tool(tool) for tool in tools] )\n",
    "kor_dreams_task_step_llm_with_tools = kor_dreams_task_step_llm.bind(   tools=[_get_assistants_tool(tool) for tool in tools] )\n",
    "\n",
    "from tests.test_builder_task_step.prompts import (\n",
    "    AEMO_REPRESENTATION_PROMPT_TEMPLATE as AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST,\n",
    "    STORY_BOARD_SCENE_TEMPLATE as STORY_BOARD_SCENE_TEMPLATE_TEST,\n",
    "    STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE as STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST,\n",
    "    EDREAMS_EVOLUTIONARY_TEMPLATE as EDREAMS_EVOLUTIONARY_TEMPLATE_TEST,\n",
    "    EDREAMS_PERSONALITY_TEMPLATE as EDREAMS_PERSONALITY_TEMPLATE_TEST,\n",
    "    DREAMS_GEN_TEMPLATE as DREAMS_GEN_TEMPLATE_TEST,\n",
    ") \n",
    "os.environ[\"AEMO_REPRESENTATION_PROMPT_TEMPLATE\"] = AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST\n",
    "os.environ[\"STORY_BOARD_SCENE_TEMPLATE\"] = STORY_BOARD_SCENE_TEMPLATE_TEST\n",
    "os.environ[\"STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE\"] = STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST\n",
    "os.environ[\"EDREAMS_EVOLUTIONARY_TEMPLATE\"] = EDREAMS_EVOLUTIONARY_TEMPLATE_TEST\n",
    "os.environ[\"EDREAMS_PERSONALITY_TEMPLATE\"] = EDREAMS_PERSONALITY_TEMPLATE_TEST\n",
    "os.environ[\"DREAMS_GEN_TEMPLATE\"] = DREAMS_GEN_TEMPLATE_TEST\n",
    "\n",
    "cross_encoder_path = \"/mnt/ceph/develop/jiawei/model_checkpoint/jina-reranker-v2-base-multilingual\"\n",
    "start_task_context = \"什么是损失函数？\"\n",
    "builder = StructuredTaskStepStoryboard.form_builder(\n",
    "    llm_runable=llm_with_tools,\n",
    "    kor_dreams_task_step_llm=kor_dreams_task_step_llm_with_tools,\n",
    "    start_task_context=start_task_context, \n",
    "    cross_encoder_path=cross_encoder_path\n",
    ")\n",
    "# 初始化任务引擎\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"ZHIPUAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://open.bigmodel.cn/api/paas/v4\"\n",
    "task_engine_builder = builder.loader_task_step_iter_builder(allow_init=True)\n",
    "while not task_engine_builder.empty():\n",
    "    task_engine = task_engine_builder.get()  \n",
    "    logger.info(task_engine.task_step_id)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4ee8a0-d50b-4728-8b18-a2d33860d5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_step_id</th>\n",
       "      <th>shot_number</th>\n",
       "      <th>scene_number</th>\n",
       "      <th>start_task_context</th>\n",
       "      <th>aemo_representation_context</th>\n",
       "      <th>task_step_name</th>\n",
       "      <th>task_step_description</th>\n",
       "      <th>task_step_level</th>\n",
       "      <th>task_step_question</th>\n",
       "      <th>task_step_question_context</th>\n",
       "      <th>task_step_question_answer</th>\n",
       "      <th>ref_task_step_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73d44403-c400-4948-967f-1c884e56e9a8</td>\n",
       "      <td>1</td>\n",
       "      <td>story_board0</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>损失函数（Loss Function）</td>\n",
       "      <td>损失函数在机器学习和优化问题中，是一个用来评估模型预测值与实际值之间差异的函数。损失函数的值...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62265bf6-3bed-4ced-a662-390fc0524848</td>\n",
       "      <td>2</td>\n",
       "      <td>story_board1</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>均方误差（Mean Squared Error, MSE）</td>\n",
       "      <td>预测值与实际值之间差的平方的平均值。应用于回归问题，如房价预测、股票价格预测等。</td>\n",
       "      <td>0&gt;1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7e7979ce-c5b1-4c9c-8fec-2a7b469c8f9c</td>\n",
       "      <td>3</td>\n",
       "      <td>story_board2</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>交叉熵损失（Cross-Entropy Loss）</td>\n",
       "      <td>用于分类问题，衡量预测概率分布与真实概率分布之间的差异。应用于二分类和多分类问题，如图像分类...</td>\n",
       "      <td>0&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42dd0728-7a06-4cc2-9385-b484a5be6362</td>\n",
       "      <td>4</td>\n",
       "      <td>story_board3</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>对数损失（Log Loss）</td>\n",
       "      <td>交叉熵损失的一种特例，常用于二分类问题。应用于二分类问题，如垃圾邮件检测。</td>\n",
       "      <td>0&gt;3</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286b9f75-7989-4f61-b387-148fff268a19</td>\n",
       "      <td>5</td>\n",
       "      <td>story_board4</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>hinge损失（Hinge Loss）</td>\n",
       "      <td>主要用于支持向量机（SVM）中，衡量模型的分类边界。应用于分类问题，尤其是SVM。</td>\n",
       "      <td>0&gt;4</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d890e1a4-2a4a-4aad-bf00-4d8bbdb726e7</td>\n",
       "      <td>6</td>\n",
       "      <td>story_board5</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>绝对误差损失（Mean Absolute Error, MAE）</td>\n",
       "      <td>预测值与实际值之间差的绝对值的平均值。应用于回归问题，对异常值较为鲁棒。</td>\n",
       "      <td>0&gt;5</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9b6fafc8-e6c8-4661-b809-c33ace5f6bc4</td>\n",
       "      <td>7</td>\n",
       "      <td>story_board6</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>Huber损失（Huber Loss）</td>\n",
       "      <td>结合了MSE和MAE的优点，对小的误差使用平方项，对大的误差使用绝对值项。应用于回归问题，尤...</td>\n",
       "      <td>0&gt;6</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fdb2fd2f-5ded-41a5-a43c-2a179f7ca441</td>\n",
       "      <td>8</td>\n",
       "      <td>story_board7</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>Kullback-Leibler散度（KL Divergence）</td>\n",
       "      <td>衡量两个概率分布之间的差异。应用于概率模型、变分自编码器（VAE）等。</td>\n",
       "      <td>0&gt;7</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64db7ee7-af18-49c3-96c4-1c3d752da151</td>\n",
       "      <td>9</td>\n",
       "      <td>story_board8</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...</td>\n",
       "      <td>损失函数的选择和优化</td>\n",
       "      <td>损失函数的选择依赖于具体任务的需求和数据特性。通过分析不同损失函数在不同任务中的应用效果，可...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           task_step_id  shot_number  scene_number  \\\n",
       "0  73d44403-c400-4948-967f-1c884e56e9a8            1  story_board0   \n",
       "1  62265bf6-3bed-4ced-a662-390fc0524848            2  story_board1   \n",
       "2  7e7979ce-c5b1-4c9c-8fec-2a7b469c8f9c            3  story_board2   \n",
       "3  42dd0728-7a06-4cc2-9385-b484a5be6362            4  story_board3   \n",
       "4  286b9f75-7989-4f61-b387-148fff268a19            5  story_board4   \n",
       "5  d890e1a4-2a4a-4aad-bf00-4d8bbdb726e7            6  story_board5   \n",
       "6  9b6fafc8-e6c8-4661-b809-c33ace5f6bc4            7  story_board6   \n",
       "7  fdb2fd2f-5ded-41a5-a43c-2a179f7ca441            8  story_board7   \n",
       "8  64db7ee7-af18-49c3-96c4-1c3d752da151            9  story_board8   \n",
       "\n",
       "  start_task_context                        aemo_representation_context  \\\n",
       "0           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "1           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "2           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "3           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "4           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "5           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "6           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "7           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "8           什么是损失函数？  损失函数（Loss Function），在机器学习和优化问题中，是一个用来评估模型预测值与实...   \n",
       "\n",
       "                      task_step_name  \\\n",
       "0                损失函数（Loss Function）   \n",
       "1      均方误差（Mean Squared Error, MSE）   \n",
       "2          交叉熵损失（Cross-Entropy Loss）   \n",
       "3                     对数损失（Log Loss）   \n",
       "4                hinge损失（Hinge Loss）   \n",
       "5   绝对误差损失（Mean Absolute Error, MAE）   \n",
       "6                Huber损失（Huber Loss）   \n",
       "7  Kullback-Leibler散度（KL Divergence）   \n",
       "8                         损失函数的选择和优化   \n",
       "\n",
       "                               task_step_description task_step_level  \\\n",
       "0  损失函数在机器学习和优化问题中，是一个用来评估模型预测值与实际值之间差异的函数。损失函数的值...               0   \n",
       "1           预测值与实际值之间差的平方的平均值。应用于回归问题，如房价预测、股票价格预测等。             0>1   \n",
       "2  用于分类问题，衡量预测概率分布与真实概率分布之间的差异。应用于二分类和多分类问题，如图像分类...             0>2   \n",
       "3              交叉熵损失的一种特例，常用于二分类问题。应用于二分类问题，如垃圾邮件检测。             0>3   \n",
       "4          主要用于支持向量机（SVM）中，衡量模型的分类边界。应用于分类问题，尤其是SVM。             0>4   \n",
       "5               预测值与实际值之间差的绝对值的平均值。应用于回归问题，对异常值较为鲁棒。             0>5   \n",
       "6  结合了MSE和MAE的优点，对小的误差使用平方项，对大的误差使用绝对值项。应用于回归问题，尤...             0>6   \n",
       "7                衡量两个概率分布之间的差异。应用于概率模型、变分自编码器（VAE）等。             0>7   \n",
       "8  损失函数的选择依赖于具体任务的需求和数据特性。通过分析不同损失函数在不同任务中的应用效果，可...               1   \n",
       "\n",
       "  task_step_question task_step_question_context task_step_question_answer  \\\n",
       "0                                            []                             \n",
       "1                                            []                             \n",
       "2                                            []                             \n",
       "3                                            []                             \n",
       "4                                            []                             \n",
       "5                                            []                             \n",
       "6                                            []                             \n",
       "7                                            []                             \n",
       "8                                            []                             \n",
       "\n",
       "  ref_task_step_id  \n",
       "0                   \n",
       "1                   \n",
       "2                   \n",
       "3                   \n",
       "4                   \n",
       "5                   \n",
       "6                   \n",
       "7                   \n",
       "8                   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dreamsboard.document_loaders.structured_storyboard_loader import StructuredStoryboard\n",
    "store_load = SimpleTaskStepStore.from_persist_dir(persist_dir=\"./60f9b7459a7749597e7efa71d1747bc4/storage\")\n",
    " \n",
    "structured_storyboard = StructuredStoryboard(json_data=[step.__dict__ for step in list(store_load.task_step_all.values())])\n",
    "\n",
    "structured_storyboard.parse_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa90a7-8d6d-4a5b-bbd5-5415d4cecef1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 场景加载模块设计方案\n",
    "```\n",
    "\n",
    "编写符合计算机科学领域的 故事情境提示词，生成研究情境（story_scenario_context），替换现有的langchain会话模板，\n",
    "1、对这个提示词所要求的输入拆分成子任务，\n",
    "2、对每个子任务指令转换为子问题，召回问题前3条，\n",
    "3、对召回内容与问题拼接，合成会话内容变量（scene_content）\n",
    "\n",
    "\n",
    "对每个子问题相关的召回内容，转换为第一人称的会话总结（研究场景（scene_monologue_context）），\n",
    "\n",
    "1、对召回内容与问题拼接，对每个前3条组成一个总结任务的提示词，为每个任务标记唯一编号，组成任务上下文（story_board_summary_context）\n",
    "2、加载编号和story_board_summary_context，转换会话信息\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c75b99-e062-458f-993d-e58a048497b9",
   "metadata": {},
   "source": [
    "\n",
    "#### MCTS设计方案\n",
    "\n",
    "```\n",
    "MCT 自优化算法代表了蒙特卡洛树搜索（MCTS）与大型语言模型的结合，将不同的场景执行任务过程抽象为搜索树结构。树上的节点代表当前不同视角下的选择策略，而边表示主体对自身的反思。该算法的操作流程遵循 MCTS 算法的一般模式。\n",
    "\n",
    "具体来说，我们采用模型的先验知识，来让每个子任务通过在上下文中资源，通过自身反思探索来获取自身对问题的最优答案；这种方式依赖模型的对齐偏好，我们在每种偏好上设计了一个工程框架，来完成自我对不同答案的奖励进行采样策略\n",
    "\n",
    "\n",
    "1、对问题生成的子任务，生成一个合理的规划的节点\n",
    "2、对每个节点创建一个MCTS任务，\n",
    "3、输入 problem（总问题的子任务相关的子问题）\n",
    "4、评分代码重构，将片段摘录器模块集成到一个关于_evaluate_answer逻辑提示模板，模板主要作用：将每个子问题相关的loader_cosplay_builder构建一个关于evaluate_system_prompt 的生成策略，具体的为编写一个关于带有评估的评估器，由loader_cosplay_builder方法返回场景执行器（CodeGeneratorBuilder），使用add_generator添加一个问答策略(CodeGenerator)中构成问答交互，build_executor后执行  executor.chat_run() 返回_ai_message\n",
    "\n",
    "5、自我反思代码重构,将片段摘录器模块集成到一个关于self_refine逻辑提示模板，模板主要作用：将每个子问题相关的loader_cosplay_builder构建一个关于critic_system_prompt和refine_system_prompt的生成策略，critic_system_prompt为生成一个关于子问题相关的loader_cosplay_builder中自身不完美的评价内容，refine_system_prompt为不完美评价的思考过程和评分值。\n",
    "具体的为编写一个关于带有评价的生成器和反思生成器，它们由loader_cosplay_builder方法返回场景执行器（CodeGeneratorBuilder），使用add_generator添加一个问答策略(CodeGenerator)中构成问答交互，build_executor后执行  executor.chat_run() 返回_ai_message\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### MCTS执行中的重要环节\n",
    "```\n",
    "MCTS中的约束规则如下，需要保证这些节点必须符合下面所定义的基本规则\n",
    "\n",
    "提示约束：模型在奖励评分期间必须遵守最严格的标准。生成结果需要为JSON Response format\n",
    "{\n",
    "    \"thought\": \"The thought process behind the answer.\",\n",
    "    \"answer\": \"A float representing the answer to the problem.\"\n",
    "}\n",
    "\n",
    "\n",
    "高分抑制：评分节点中不存在满分反馈机制；任何超过 95 分的奖励都会按固定金额减少，以遏制过高分数。\n",
    "\n",
    "重复采样：每次访问搜索树节点都涉及对节点奖励的重复采样，以增强自我评估的可靠性。需要注意的是，当对节点的子节点进行奖励采样时，我们也会对其父节点进行奖励采样，以增加奖励采样的样本量。\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564d9451-6f2b-4685-ab6c-669ad626790f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/develop/jiawei/weaviate-python-client/weaviate/warnings.py:133: DeprecationWarning: Dep005: You are using weaviate-client version 0.1.dev3117+gae1bb03. The latest version is 4.10.4.\n",
      "            Consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/flash_attn/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/flash_attn/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:460: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response = response.dict()\n",
      "/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/storage/task_step_store/utils.py:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  DATA_KEY: doc.dict(),\n",
      "Searching papers for query: ### 提出的问题\n",
      "\n",
      "**问题：** 在机器学习和优化问题中，如何根据具体任务的需求和数据特性选择合适的损失函数，以确保模型的预测结果尽可能接近真实值并提升模型的整体性能？\n",
      "Found 100 papers.\n",
      "Found 86 unique paper IDs.\n",
      "Fetching details for paper ID: 62c28ae55aee126c0f8a1db1\n",
      "Fetching details for paper ID: 64e2e14f3fda6d7f064665d6\n",
      "Fetching details for paper ID: 65499d88939a5f4082be9b60\n",
      "Fetching details for paper ID: 6356022390e50fcafd336957\n",
      "Fetching details for paper ID: 64f59fb33fda6d7f0648d313\n",
      "Fetching details for paper ID: 6476d20cd68f896efaf72788\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b6508\n",
      "Fetching details for paper ID: 634f6ae490e50fcafdcb66c7\n",
      "Fetching details for paper ID: 65939159939a5f4082e677fa\n",
      "Fetching details for paper ID: 65cad50c939a5f4082f3f508\n",
      "Fetching details for paper ID: 64e2e14f3fda6d7f06466467\n",
      "Fetching details for paper ID: 657bbe35939a5f4082f217f9\n",
      "Fetching details for paper ID: 60bee4b291e01184918178e3\n",
      "Fetching details for paper ID: 651f6e093fda6d7f06d0c5bb\n",
      "Fetching details for paper ID: 632d240290e50fcafd91b2bc\n",
      "Fetching details for paper ID: 64c09a9c3fda6d7f06e3e938\n",
      "Fetching details for paper ID: 65543326939a5f40820ac7e5\n",
      "Fetching details for paper ID: 650a566d3fda6d7f067ecbf5\n",
      "Fetching details for paper ID: 61a839b15244ab9dcbb1d761\n",
      "Fetching details for paper ID: 63e9aa5e90e50fcafd1335cc\n",
      "Fetching details for paper ID: 64927546d68f896efa88a03b\n",
      "Fetching details for paper ID: 656d38ac939a5f408261cfe8\n",
      "Fetching details for paper ID: 64927546d68f896efa88a323\n",
      "Fetching details for paper ID: 652d3699939a5f40824941a4\n",
      "Fetching details for paper ID: 66fbc1c001d2a3fbfccee23c\n",
      "Fetching details for paper ID: 626b49615aee126c0fffce85\n",
      "Fetching details for paper ID: 648000a9d68f896efaa1238f\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1baba\n",
      "Fetching details for paper ID: 6464affad68f896efa357239\n",
      "Fetching details for paper ID: 630ed16590e50fcafd793932\n",
      "Fetching details for paper ID: 64e941d03fda6d7f06958aec\n",
      "Fetching details for paper ID: 629ec1f95aee126c0fb7053a\n",
      "Fetching details for paper ID: 64e6d5bd3fda6d7f0652c761\n",
      "Fetching details for paper ID: 61f8a4c35aee126c0fee01f1\n",
      "Fetching details for paper ID: 648fd298d68f896efa163b8c\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b606c\n",
      "Fetching details for paper ID: 659e219b939a5f408289679a\n",
      "Fetching details for paper ID: 6456389bd68f896efacf68fd\n",
      "Fetching details for paper ID: 65ea893113fb2c6cf62e55f9\n",
      "Fetching details for paper ID: 62afe5495aee126c0f6689ae\n",
      "Fetching details for paper ID: 66ecdacf01d2a3fbfcdfd661\n",
      "Fetching details for paper ID: 6268a6795aee126c0f14307f\n",
      "Fetching details for paper ID: 64951856d68f896efa1ef4c9\n",
      "Fetching details for paper ID: 6221834e5aee126c0f23c344\n",
      "Fetching details for paper ID: 5f86cf4d91e011dbc7eba377\n",
      "Fetching details for paper ID: 6401669c90e50fcafd688d3c\n",
      "Fetching details for paper ID: 65d6b0cb939a5f40827a4192\n",
      "Fetching details for paper ID: 619c5bbf5244ab9dcbf22191\n",
      "Fetching details for paper ID: 65ea8c8f13fb2c6cf6313ca1\n",
      "Fetching details for paper ID: 66ac3f0701d2a3fbfc8a2d89\n",
      "Fetching details for paper ID: 632d23fb90e50fcafd91a1fd\n",
      "Fetching details for paper ID: 65cad432939a5f4082f2a2a2\n",
      "Fetching details for paper ID: 65cd7183939a5f408236499d\n",
      "Fetching details for paper ID: 65309159939a5f4082843d43\n",
      "Fetching details for paper ID: 64741c33d68f896efaa7b684\n",
      "Fetching details for paper ID: 63bcd73090e50fcafdef99b0\n",
      "Fetching details for paper ID: 63d340ef90e50fcafd91158d\n",
      "Fetching details for paper ID: 651390ac3fda6d7f06035198\n",
      "Fetching details for paper ID: 64af99ff3fda6d7f065a64cb\n",
      "Fetching details for paper ID: 6164fcc15244ab9dcb24d2ee\n",
      "Fetching details for paper ID: 6464b018d68f896efa3580fc\n",
      "Fetching details for paper ID: 64fa84403fda6d7f06700704\n",
      "Fetching details for paper ID: 627332775aee126c0f18d483\n",
      "Fetching details for paper ID: 6583b18a939a5f408229ae5a\n",
      "Fetching details for paper ID: 633ba44890e50fcafdfe4f8d\n",
      "Fetching details for paper ID: 64f933e53fda6d7f067a12ee\n",
      "Fetching details for paper ID: 65fc055d13fb2c6cf6df2411\n",
      "Fetching details for paper ID: 6467126bd68f896efaf14c8f\n",
      "Fetching details for paper ID: 63365e7f90e50fcafd1a35e6\n",
      "Fetching details for paper ID: 637c3dd190e50fcafd77c852\n",
      "Fetching details for paper ID: 652377f9939a5f4082e0ff9d\n",
      "Fetching details for paper ID: 65f7a01c13fb2c6cf668eb6c\n",
      "Fetching details for paper ID: 64671272d68f896efaf1518c\n",
      "Fetching details for paper ID: 621ee1835aee126c0f26a8cc\n",
      "Fetching details for paper ID: 65b078e9939a5f4082b3307b\n",
      "Fetching details for paper ID: 65b313a0939a5f4082a4ad09\n",
      "Fetching details for paper ID: 628c4ce15aee126c0ff599dc\n",
      "Fetching details for paper ID: 65dea27813fb2c6cf65463bb\n",
      "Fetching details for paper ID: 6164fcc15244ab9dcb24cfc8\n",
      "Fetching details for paper ID: 65fc055d13fb2c6cf6df2275\n",
      "Fetching details for paper ID: 62c28ae65aee126c0f8a23c9\n",
      "Fetching details for paper ID: 64dd9b053fda6d7f0622e5fc\n",
      "Fetching details for paper ID: 65b9ac90939a5f4082224899\n",
      "Fetching details for paper ID: 6577c976939a5f40822e419a\n",
      "Fetching details for paper ID: 65e7dcad13fb2c6cf6fdc96c\n",
      "Fetching details for paper ID: 6230042f5aee126c0f9b3184\n",
      "Data cached for query: ### 提出的问题\n",
      "\n",
      "**问题：** 在机器学习和优化问题中，如何根据具体任务的需求和数据特性选择合适的损失函数，以确保模型的预测结果尽可能接近真实值并提升模型的整体性能？ at /tmp/query_cache/0da2786a6fbd856fe72961a4cdce82ff.json\n",
      "/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/langchain_community/chat_models/openai.py:460: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response = response.dict()\n",
      "Root nodes:[\"component\", \"function\", \"determines\", \"parameters\", \"approximate\"]\n",
      "Concepts with more than 3 outgoing edges:['consistent']\n",
      "Concepts with more than 3 going edges:['depends', 'initial']\n",
      "No path between component and consistent\n",
      "No path between approximate and consistent\n",
      "Root nodes:[\"component\", \"function\", \"determines\", \"parameters\", \"approximate\"]\n",
      "Concepts with more than 3 outgoing edges:['consistent']\n",
      "Concepts with more than 3 going edges:['depends', 'initial']\n",
      "Path: function -> depends -> consistent\n",
      "Node: function, refIds: ['66ecdacf01d2a3fbfcdfd661', '632d240290e50fcafd91b2bc']\n",
      "Node: depends, refIds: ['632d240290e50fcafd91b2bc', '65cad432939a5f4082f2a2a2', '62c28ae55aee126c0f8a1db1', '6164fcc15244ab9dcb24cfc8', '621ee1835aee126c0f26a8cc', '5f86cf4d91e011dbc7eba377', '64f59fb33fda6d7f0648d313']\n",
      "Node: consistent, refIds: ['62c28ae65aee126c0f8a23c9', '63bcd73090e50fcafdef99b0', '627332775aee126c0f18d483', '632d240290e50fcafd91b2bc', '621ee1835aee126c0f26a8cc', '648000a9d68f896efaa1238f', '5f86cf4d91e011dbc7eba377', '632d23fb90e50fcafd91a1fd', '6476d20cd68f896efaf72788', '66ac3f0701d2a3fbfc8a2d89']\n",
      "ref_ids: 62c28ae55aee126c0f8a1db1, Score: 0.3359, Text: # 3. Algorithms and Analysis\n",
      "Here we present formal versions of Algorithm 1 , and analyze their theoretical performance. To formalize Algorithm 1 fully, we describe how we evaluate which group has the highest loss in each iteration, and how we either sample additional data from that group or reweight and update the model. Both algorithms use their updating schemes to reduce their training error on the min-max objective, and while we also present theorems which bound the test error as well, this work does not use reweighting or resampling to explicitly decrease generalization error.\n",
      "ref_ids: 62c28ae55aee126c0f8a1db1, Score: 0.2871, Text: # 2 Related Work\n",
      "Dataset Distillation. Data-centric AI is an emerging and critical field that optimizes the datasets, including data curation [ 32 ,22 ], distribution shift and class-imbalance learning [ 20 ,2 ,10 ,37 ], and data compression [ 4 ,30 ,36 ,41 ]. Among those, dataset distillation learns a smaller and more representative dataset from large dataset while maintaining the performance, which can be roughly classified into: 1) Meta-Model Matching aligns the transferability of real and synthetic data, by optimizing the empirical loss on the original dataset of models trained on the synthetic data. These methods usually adopt a bi-level optimization. In detail, Wang et al. [36 ] first propose the task of data distillation and use the meta-model matching framework for optimization. Nguyen et al. [24 ] exploit kernel ridge regression to facilitate its inner optimization loop, and they further extend the method to infinite wide networks [ 25 ]. Based on KIP, Zhou et al. [42 ] propose to separate the optimization of synthetic data/classifier and feature extractor. 2) Gradient Matching: Zhao et al. [41 ] first propose gradient matching to align the gradients of the synthetic dataset with those of the real dataset. Zhao and Bilen [ 39 ] further improve it by performing the same image augmentations on both the real and synthetic data. 3) Distribution Matching: Zhao and Bilen first propose a simple but effective method, distribution matching [ 40 ], to match the feature distributions of the synthetic and real data. Wang et al. [35 ] design a layer-wise feature alignment method and propose a few early exit conditions to promote distribution matching. 4) Trajectory Matching: Cazenavette et al. [5 ] propose to match the training trajectory of the model parameters, by aligning the future parameters trained on real data and synthetics data respectively. Cui et al. [6 ] reduce the memory consumption of MTT to extend to large-scale datasets. 5) Factorization: To reduce the storage burden of the synthetic data, multiple methods were proposed to compress the synthetic data. Kim et al. [12 ] use a simple strategy of putting multiple images on one synthetic sample. Deng et al. [8 ] decompose the synthetic data to the linear combination of bases. Liu et al. [18 ] use a hallucination network to combine the bases. Lee et al. [17 ]maintains a smaller base space to further reduce the storage. 6) Bayesian Pseudocoreset: there is also a family of distillation methods that learn the synthetic data from Bayesian inference [ 21 ,11 ,33 ].  \n",
      "\n",
      "Data Selection/Pruning reduces the training data without significantly affecting performance. Classic data selection often calculates a scalar utility score for each sample based on predefined criteria [ 4 ,30 ,34 ] and filters the samples based on scores. Some data pruning methods also consider the interaction between samples. [ 38 ] proposes examining generalization influence to reduce training data, which aims to identify the smallest subset to satisfy the expected generalization ability. In comparison, data distillation [ 36 ] and data condensation [ 41 ] synthesize new and smaller data. The performance of data distillation with the same images per class (IPC) significantly outperforms data pruning.\n",
      "\n",
      "# 3 Preliminaries\n",
      "Data redundancy widely exists in various machine learning tasks. After conducting thorough experiments and comparisons, we first argue that data redundancy is extremely severe in distillation (Sec. 3.1). Then, we model the dynamics of dataset distillation to explain our observations (Sec. 3.2).\n",
      "ref_ids: 62c28ae55aee126c0f8a1db1, Score: 0.2490, Text: # 3.1. Stochastic Optimization\n",
      "Algorithm 2 maintains a validation set, that is a fixed comparison sample set on which the group-specific loss is repeatedly measured. It samples a fresh point from the group with highest loss on the comparison set, then takes a single gradient step in the direction of that fresh sample. Its performance is governed by two quantities: the regret term, which decreases with the number of iterations $T$ , and the uniform deviation bound of the comparisons of group-specific loss.  \n",
      "\n",
      "<html><body><table><tr><td>Algorithm 2 Min-maxStochastic GradientDescent</td></tr><tr><td>1: Init: 0 E ⊙ arbitrary</td></tr><tr><td>2: for t = 1...T - 1 do</td></tr><tr><td>3: compute it = argmax v 0t;D ie[9]</td></tr><tr><td>4: sample zt ～ Dit</td></tr><tr><td>5: compute Vt < Vol(fot; Zt)</td></tr><tr><td>6: update Ot+1 ← PROJe(0t - nVt)</td></tr><tr><td>7: end for ∑T=1 0t 8:return OT = T</td></tr></table></body></html>  \n",
      "\n",
      "As is common in gradient descent, the following proof assumes that the Lipschitz constant $L$ and a domain radius $W$ are known. When this is not the case, the step size $\\nu$ is typically tuned empirically.  \n",
      "\n",
      "$\\mathcal{R}(m_{1},\\ldots,m_{g};\\delta)$ Theorem 1. Assume we have a function which guarantees that $\\mathcal{R}_{\\delta}\\quad=$  \n",
      "\n",
      "$$\n",
      "\\underset{\\theta\\in\\Theta}{\\operatorname*{sup}\\operatorname*{max}}\\left|v\\left(\\theta;D_{i}\\right)-v\\left(\\theta;\\hat{D}_{i}\\right)\\right|\\leq\\mathcal{R}_{\\delta}\n",
      "$$  \n",
      "\n",
      "with $1-\\delta$ $W:=\\operatorname*{sup}_{\\theta\\in\\Theta}\\|\\theta-\\theta_{1}\\|_{2}$ $\\frac{W}{L\\sqrt{T}}$ and $L\\;:=\\;\\operatorname*{sup}_{\\theta\\in\\Theta}\\operatorname*{max}_{i\\in[g]}\\|\\nabla_{\\theta}v\\left(\\theta;D_{i}\\right)\\|_{2}$ , Algorithm ∈2 ensures that ∈∥∇ ∥. With $\\eta\\::=\\:$  \n",
      "\n",
      "$$\n",
      "\\underset{z_{1:T}}{\\mathbb{E}}\\left[\\operatorname*{max}_{i\\in[g]}v\\left(\\bar{\\theta}_{T};D_{i}\\right)\\right]\\leq\\operatorname*{inf}_{\\theta\\in\\Theta}\\operatorname*{max}_{i\\in[g]}v\\left(\\theta;D_{i}\\right)\\!+\\!\\frac{W L}{\\sqrt{T}}\\!+\\!2\\mathcal{R}_{T\\delta}\n",
      "$$  \n",
      "\n",
      "with probability at least $1-\\delta$ Proof. This bound is obtained by combining a number of classical results from empirical process theory, as well as common tricks from using online convex optimization tools to solve min-max problems. This sequence of steps is given in Figure 1 , with further discussion here.  \n",
      "\n",
      "One observes that we need to swap between $v\\left(\\theta;\\hat{D}\\right)$ \u0010\u0011and $v\\left(\\theta;D\\right)$ on two separate inequalities, and on each we have to add the deviation bound because we need a union bound over all $\\mathcal{R}_{T\\delta}$ ; the $T$ Trounds. We then ctor is necessary replace $v\\left(\\theta_{t};D_{i_{t}}\\right)$ with $\\ell(f_{\\theta_{t}};z_{t})$ , which is valid since $\\theta_{t}$ is independent of $z_{t}$ ,$z_{t}$ is distributed according to $D_{i_{t}}$ , and we have the outer expectation over all $z_{1},\\dots,z_{T}$ (more details on this technique can be found in the paper of Cesa-Bianchi et al. ,2004 ). Next, since the $\\theta_{t}$ ’s are chosen using the Online Gradient Descent (OGD) algorithm on loss functions $h_{t}(\\cdot)\\;:=\\;\\ell(f_{\\cdot};z_{t})$ , we can immediately apply the OGD regret bound—see Hazan (2019 ) for details.  \n",
      "\n",
      "The most subtle part of this proof may be the final two observations. The sequence $z_{1:T}$ is generated stochastically and sequentially, where each $z_{t}$ may depend on the previous samples chosen. But in the end, the sample $S^{T}$ is produced by taking some combination of samples from the various the quantity $\\boldsymbol{D}_{1},\\ldots,\\boldsymbol{D}_{g}$ $v\\left(\\theta^{\\star};S^{T}\\right)$ \u0000\u0001over the randomness generated by , and ultimately we marginalize $z_{1},\\dots,z_{T}$ . On average, the $z$ ’s in $S^{T}$ will have been drawn from some mixture over the various groups, and we refer to vation that those mixture weights as $\\mathbb{E}_{z_{1:T}}$ $\\mathbf{\\Psi}_{1:T}\\,\\left[v\\left(\\theta^{\\star};S^{T}\\right)\\right]=v\\left(\\theta^{\\star};D_{\\tilde{\\mathbf{q}}}\\right)$ \u0000$\\tilde{\\mathbf{q}}$ \u0001' . It then follows by this obser. Finally, since $v\\left(\\theta^{\\star};D_{\\tilde{\\mathbf{q}}}\\right)=\\mathbb{E}_{i\\sim\\tilde{\\mathbf{q}}}\\,\\dot{v}\\left(\\theta^{\\star};D_{i}\\right)$ ∼, we upper bound ${\\mathbb E}_{i\\sim{\\tilde{\\mathbf{q}}}}$ with $\\mathrm{max}_{i}$ to complete the proof.  \n",
      "\n",
      "While not the focus of our paper, it is easy enough to give a uniform deviation bound as Theorem 1 employs.  \n",
      "\n",
      "Lemma 1. With probability at least $1-\\delta_{i}$ , for every $\\theta\\in\\Theta$ and for every $\\mathbf{q}\\in\\Delta_{g}$ it holds that  \n",
      "\n",
      "$$\n",
      "v\\left(\\theta;\\hat{D}_{\\mathbf{q}}\\right)\\leq v\\left(\\theta;D_{\\mathbf{q}}\\right)+c\\sqrt{\\frac{P\\mathrm{-}d i m(\\Theta)\\log(g\\cdot m_{\\mathrm{min}}/\\delta)}{\\operatorname*{min}_{i}m_{i}}}\n",
      "$$  \n",
      "\n",
      "where $c\\,>\\,0$ is some constant and $P$ -dim is the pseudodimension of the class ( Pollard ,1990 ).  \n",
      "\n",
      "Proof. This follows from a standard uniform convergence argument over $\\Theta$ for any fixed group $i$ , as $\\hat{D}_{i}$ is a sample of $m_{i}$ IID points drawn from $D_{i}$ . Taking a union bound over all $g$ groups yields the bound.  \n",
      "\n",
      "This implies that the total error of using Algorithm 2 is comprised of two terms, one upper bounding the optimization error (which decays with $\\bar{1/{\\sqrt{T}}})$ ), and the generalization error, which is governed by the sample size of the smallest dataset across all groups.  \n",
      "\n",
      "A key benefit of Theorem 1 is that it provides both an optimization guarantee as well as a sample complexity bound. The proof’s core is the classical “online to batch conversion” ( Cesa-Bianchi et al. ,2004 ) that provides generalization based on regret bounds, combined with tools from min-max optimization.  \n",
      "\n",
      "One downside of this method is that it relies on having two sources of data: a “comparison set” $\\hat{D}_{i}$ for each $i\\,\\in\\,[g]$ ,as well as the ability to draw fresh (independent) samples from each $D_{i}$ . Alternatively, we consider a version that only focuses on training error that reweights rather than samples fresh data, by considering $z_{t}$ drawn from $\\hat{D}_{i}$ . This variant will still allow for the min-max empirical risk to decay at the standard $1/\\sqrt{T}$ rate.  \n",
      "\n",
      "Corollary 1. Consider a version of Algorithm 2 that, on line 4, draws samples IID from the empirical distribution $\\hat{D}_{i_{t}}$ as opposed to fresh samples from $D_{i_{t}}$ . Then, with  \n",
      "\n",
      "Figure 1. Main steps in the proof of Theorem 1 . The proof proceeds along the lines of the classical online-to-batch conversion ( CesaBianchi et al. ,2004 ), but hinges on a few additional tricks.  \n",
      "\n",
      "(Jensen’s inequality )$\\begin{array}{r l}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\operatorname*{max}_{\\ell\\in\\{\\hat{Z}_{i}\\}}\\psi\\left(\\psi_{i},\\hat{D}_{\\ell}\\right)\\right]}\\\\ {\\leq}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\operatorname*{max}_{\\ell\\in\\{\\hat{Z}_{i}\\}}\\sum_{t=r}^{r}\\mathrm{(}\\theta_{i}(\\ell_{i},D_{\\ell})\\right]}\\\\ {\\leq}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}\\left(\\operatorname*{max}_{\\ell\\in\\{\\hat{Z}_{i}\\}}\\psi\\left(\\theta_{i},D_{\\ell}\\right)\\right)\\right]}\\\\ {\\leq}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}\\operatorname*{max}_{\\ell\\in\\{\\hat{Z}_{i}\\}}\\psi\\left(\\theta_{i},\\hat{D}_{\\ell}\\right)\\right]+\\mathrm{R}_{T\\ell}}\\\\ {=}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}\\mathrm{v}\\left(\\theta_{i}(\\ell_{i},\\hat{D}_{u})\\right)\\right]+\\mathrm{R}_{T\\ell}}\\\\ {\\leq}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}v\\left(\\theta_{i},D_{u}\\right)\\right]+2\\mathrm{R}_{T\\ell}}\\\\ {=}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}\\ell\\left(f_{\\ell_{i},\\hat{Z}_{i}}\\right)\\right]+2\\mathrm{R}_{T\\ell}}\\\\ {\\leq}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\frac{1}{r}\\sum_{t=1}^{r}\\ell\\left(f_{\\ell_{i},\\hat{Z}_{i}}\\right)+\\frac{u^{2}}{r}+\\frac{u^{2}}{r\\ell_{1}r}\\right]+2\\mathrm{R}_{T\\ell}}\\\\ {=}&{\\mathrm{E}_{\\mathrm{arr}}\\left[\\mathrm{(}\\theta^{*},\\hat{\\mathcal{Z}}^{\\mathrm{T}}\\right)\\right]+\\frac{u^{4}}{r}+2\\mathrm{R}_{T\\ell}}\\\\ {=}&{\\mathrm{e}(\\theta^{*},D_{\\mathrm{a}})+\\frac{u^{2}}{r}+2\\mathrm{R $   \n",
      "(max sum ≤sum max )  \n",
      "\u0000deviation between $D$ ,$\\hat{D}+$ union bound \u0001  \n",
      "(definition of i t  \n",
      "\u0000additional deviation between D,D\u0001  \n",
      "(since $z_{t}\\sim D_{i_{t}}+$ outer expectation )  \n",
      "(apply OGD regret bound )  \n",
      "$\\begin{array}{r}{\\left(\\eta:=\\frac{W}{L\\sqrt{T}},\\,S^{T}:=\\left\\{z_{1},\\,\\cdot\\,.\\,.\\,,z_{T}\\right\\}\\right)}\\end{array}$ \u0011  \n",
      "\n",
      "$W,L$ defined as in Theorem 1 , we have  \n",
      "\n",
      "$$\n",
      "\\mathbb{E}_{x_{1:T}}\\left[\\operatorname*{max}_{i\\in[g]}v\\left(\\bar{\\theta}_{T};\\hat{D}_{i}\\right)\\right]\\leq\\operatorname*{inf}_{\\theta\\in\\Theta}\\operatorname*{max}_{i\\in[g]}v\\left(\\theta;\\hat{D}_{i}\\right)+\\frac{W L}{\\sqrt{T}}.\n",
      "$$  \n",
      "\n",
      "Remark 2 (Mini-batching) .Many online training scenarios use mini-batch gradient updates, where instead of a single sample a set of samples is taken, an average gradient is computed across these samples, and the average gradient is used to update the current parameter estimate. Indeed, it requires a straightforward modification to implement minibatch training in Algorithm 2 . While this may have practical benefits, providing faster empirical training times, we note that this is not likely to provide improved theoretical guarantees. Our convergence guarantee in Theorem 1 still applies in the mini-batch setting, with convergence depending on the number of updates $T$ , rather than the total amount of data used. Batches of size $k$ then require $k$ times more data overall for the same convergence guarantee. One might hope for a decrease in variance from the mini-batch averaging, and indeed this often empirically leads to better convergence, though not promised by our results.\n",
      "/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/storage/task_step_store/utils.py:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  DATA_KEY: doc.dict(),\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "need to escape, but no escapechar set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m task_engine \u001b[38;5;241m=\u001b[39m task_engine_builder\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task_engine\u001b[38;5;241m.\u001b[39mcheck_engine_init():\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtask_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_task_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     task_engine\u001b[38;5;241m.\u001b[39minit_task_engine_dreams()\n\u001b[1;32m     10\u001b[0m     task_engine\u001b[38;5;241m.\u001b[39minit_task_engine_storyboard_executor()\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py:143\u001b[0m, in \u001b[0;36mTaskEngineBuilder.init_task_engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_step_to_question_chain\u001b[38;5;241m.\u001b[39minvoke_task_step_to_question(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_step_id)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_step_to_question_chain\u001b[38;5;241m.\u001b[39minvoke_task_step_question_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_step_id)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_step_to_question_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_csv_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_step_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py:367\u001b[0m, in \u001b[0;36mTaskStepToQuestionChain.export_csv_file_path\u001b[0;34m(self, task_step_id)\u001b[0m\n\u001b[1;32m    363\u001b[0m     table_data\u001b[38;5;241m.\u001b[39mappend(row3)\n\u001b[1;32m    365\u001b[0m table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(table_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m角色\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m内容\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m分镜\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 367\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/storage/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtask_step_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/storage/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_step_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/core/generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3718\u001b[0m )\n\u001b[0;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/io/formats/format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1188\u001b[0m )\n\u001b[0;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/io/formats/csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/io/formats/csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/io/formats/csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/io/formats/csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    312\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    314\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 315\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/develop/jiawei/conda_env/weaviate_client/lib/python3.10/site-packages/pandas/_libs/writers.pyx:75\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: need to escape, but no escapechar set"
     ]
    }
   ],
   "source": [
    "task_engine_builder = builder.loader_task_step_iter_builder(allow_init=False)\n",
    " \n",
    "task_step_store = builder.task_step_store\n",
    "while not task_engine_builder.empty():\n",
    "    \n",
    "    task_engine = task_engine_builder.get()\n",
    "    if not task_engine.check_engine_init():\n",
    "        task_engine.init_task_engine()\n",
    "        task_engine.init_task_engine_dreams()\n",
    "        task_engine.init_task_engine_storyboard_executor()\n",
    "\n",
    "    try:\n",
    "        code_gen_builder = task_engine.storyboard_code_gen_builder()\n",
    "        task_step = task_engine.task_step_store.get_task_step(task_engine.task_step_id)\n",
    "        if task_step.task_step_question_answer is None or len(task_step.task_step_question_answer) == 0:\n",
    "            task_engine.generate_step_answer(code_gen_builder)\n",
    "        mcts_node = task_engine.get_mcts_node()\n",
    "        answer = mcts_node.run()\n",
    "        \n",
    "        mcts_node.print()\n",
    "        print(answer)\n",
    "        task_step.task_step_question_answer = answer \n",
    "        task_step_id = task_engine.task_step_id\n",
    "        \n",
    "        task_engine.task_step_store.add_task_step([task_step])\n",
    "        task_step_store_path = concat_dirs(dirname=f\"{builder.base_path}/storage/{task_step_id}\", basename=DEFAULT_PERSIST_FNAME)\n",
    "        task_engine.task_step_store.persist(persist_path=task_step_store_path) \n",
    "        \n",
    "        task_step_store.add_task_step([task_step])\n",
    "        task_step_store_path = concat_dirs(dirname=f\"{builder.base_path}/storage\", basename=DEFAULT_PERSIST_FNAME)\n",
    "        task_step_store.persist(persist_path=task_step_store_path) \n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"场景加载失败\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944db87a-cb55-4148-aaf0-4806ffeea663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_load = SimpleTaskStepStore.from_persist_dir(persist_dir=\"./60f9b7459a7749597e7efa71d1747bc4/storage\")\n",
    "task_step_md = TaskStepMD(store_load)\n",
    "md_text =   task_step_md.format_md() \n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(md_text.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f79489-2835-4b70-97ec-3c3bdbeb5fdf",
   "metadata": {},
   "source": [
    "\n",
    "StructuredTaskStepStoryboard\n",
    "    \n",
    "对任务进行规划，生成段落之间组成一个动态上下文，  扩写任务步骤构建MCTS任务\n",
    "    输入：\n",
    "    \tstart_task_context： 起始任务\n",
    "    \tllm： 模型\n",
    "    \tkor_dreams_task_step_llm: 任务抽取模型\n",
    "    \ttask_step_store: 任务存储器（SimpleTaskStepStore）\n",
    "    \tcross_encoder_path: ranking模型路径（sentence_transformers），当前设计耦合了业务，之后会单独设计一个召回模块\n",
    "\n",
    "    任务：\n",
    "\n",
    "        1、对任务（AEMO_REPRESENTATION_PROMPT_TEMPLATE）按照提示词要求进行扩写，将扩写任务步骤收集 （src/dreamsboard/dreamsboard/engine/entity/task_step、src/dreamsboard/tests/test_kor/test_kor3.py）\n",
    "\n",
    "        2、收集每个任务后存储到磁盘（src/dreamsboard/dreamsboard/engine/storage/task_step_store）\n",
    "\n",
    "        3、对每个子任务载入会话场景，然后按照扩写任务步骤构建，MCTS任务 loader_task_step_iter_builder\n",
    "\n",
    "\n",
    "\t》 TaskEngineBuilder 场景加载模块\n",
    "\t\t执行会话场景资源初始化，构建MCTS任务\n",
    "\n",
    "    根据任务步骤，构建场景加载模块，生成资源文件csv\n",
    "    根据每个任务，载入StructuredDreamsStoryboard 会话场景\n",
    "    按照扩写任务步骤构建MCTS任务\n",
    "\n",
    "\t\t输入：\n",
    "\t\t\ttask_step_id\n",
    "\t\t\ttask_step_store: 任务存储器（SimpleTaskStepStore）\n",
    "\t\t\tstart_task_context： 起始任务\n",
    "\t\t\tllm： 模型\n",
    "\n",
    "\t\t任务：\n",
    "\t\t\tinit_task_engine：\n",
    "\t\t\t\t初始化任务引擎\n",
    "        》TaskStepToQuestionChain \n",
    "        \t输入：\n",
    "        \t\tclient： 矢量库客户端\n",
    "        \t\tllm： 模型\n",
    "\t\t\t\t\tinvoke_task_step_to_question：1、 对开始任务进行抽取，得到任务步骤，提示词所要求的输入拆分成子任务， \n",
    "\t\t\t\t\tinvoke_task_step_question_context： 2、对每个子任务指令转换为子问题，召回问题前3条，对任务步骤进行抽取，得到任务步骤的上下文\n",
    "\t\t\t\t\texport_csv_file_path: 3、对召回内容与问题 导出csv文件\n",
    "\n",
    "\t\t\tinit_task_engine_dreams\n",
    "\t\t\t\t初始化场景加载资源\n",
    "\t\t\t\t\tStoryBoardDreamsGenerationChain\n",
    "\t\t\t\t\t对每个子任务通过职业提示词，载入会话场景\n",
    "\t\t\t\t\t\t1、构建场景信息（story_scenario_context），提示词（STORY_BOARD_SCENE_TEMPLATE）\n",
    "\t\t\t\t\t\t2、对任务上下文(story_board_summary_context)，构建第一人称数据(scene_monologue_context),提示词（STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE）\n",
    "\t\t\t\t\t\t3、对任务上下文(story_board_summary_context)，获取任务分析(evolutionary_step), 提示词（EDREAMS_EVOLUTIONARY_TEMPLATE）\n",
    "\t\t\t\t\t\t4、对任务分析(evolutionary_step)，分析对话预设信息（性格）， 提示词（EDREAMS_PERSONALITY_TEMPLATE）\n",
    "\t\t\t\t\t\t5、对任务上下文(story_board_summary_context)，场景信息story_scenario_context, 第一人称数据(scene_monologue_context)，\n",
    "\t\t\t\t\t\t生成关于人物职业的引导话术，提示词（DREAMS_GEN_TEMPLATE）\n",
    "\n",
    "\t\t\tinit_task_engine_storyboard_executor\n",
    "\n",
    "\t\t\t\t构建会话场景执行器 StructuredDreamsStoryboard\n",
    "\t\t\t\t\t对剧本和分析结果进行结构化，将开放问题与性格分析结果进行结合。生成情景扮演会话场景执行器\n",
    "\t\t\t    此过程如下\n",
    "\t\t\t        对开放问题结果进行抽取，得到问题内容\n",
    "\t\t\t        对性格分析结果进行抽取，得到性格分析结果\n",
    "\t\t\t        增加系统提示词\n",
    "\t\t\t        根据剧本与任务性格基础情景扮演代码，根据每步的抽取析得到的问题，生成问题的答案\n",
    "\t\t\t       \t在上下文中增加，关于人物职业的引导话术\n",
    "\t        \t\t导出会话场景执行器\n",
    "\t\t\t\t\t\n",
    "\t    storyboard_code_gen_builder\n",
    "\t    \t构建会话场景执行器\n",
    "\n",
    "\t    generate_step_answer\n",
    "\t    \t获取主进程子任务的答案\n",
    "\t    \n",
    "\t    get_mcts_node\n",
    "\t    \t构建MCTS树, 初始化当前任务相关的MCTS节点，并返回MCTS执行器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7d06a-858a-48c9-80d5-f7dedeb20220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weaviate_client] *",
   "language": "python",
   "name": "conda-env-weaviate_client-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
