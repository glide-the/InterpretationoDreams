{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585bf5f5-284b-465b-9226-84528587e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c82d29-20bd-47b0-85fa-e5a8711a55c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dreamsboard -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54271263-a5c7-4584-9dc9-7efb51113e60",
   "metadata": {},
   "source": [
    "### 介绍\n",
    "使用langchain进行任务规划，构建子任务的会话场景资源，通过MCTS任务执行器，来让每个子任务通过在上下文中资源，通过自身反思探索来获取自身对问题的最优答案；这种方式依赖模型的对齐偏好，我们在每种偏好上设计了一个工程框架，来完成自我对不同答案的奖励进行采样策略\n",
    "\n",
    "\n",
    "## 使用\n",
    "\n",
    "### 构建任务\n",
    "\n",
    "- 初始化任务引擎 StructuredTaskStepStoryboard传入需要的任务\n",
    "\n",
    "- loader_task_step_iter_builder 构建任务的子任务，完成后SimpleTaskStepStore可获取子任务信息\n",
    "\n",
    "- init_task_engine_dreams 初始化场景加载资源，对子任务进行规划，获取会话的资源信息\n",
    "\n",
    "```\n",
    "\n",
    "    os.environ[\"AEMO_REPRESENTATION_PROMPT_TEMPLATE\"] = AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST\n",
    "    os.environ[\"STORY_BOARD_SCENE_TEMPLATE\"] = STORY_BOARD_SCENE_TEMPLATE_TEST\n",
    "    os.environ[\"STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE\"] = STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST\n",
    "    os.environ[\"EDREAMS_EVOLUTIONARY_TEMPLATE\"] = EDREAMS_EVOLUTIONARY_TEMPLATE_TEST\n",
    "    os.environ[\"EDREAMS_PERSONALITY_TEMPLATE\"] = EDREAMS_PERSONALITY_TEMPLATE_TEST\n",
    "    os.environ[\"DREAMS_GEN_TEMPLATE\"] = DREAMS_GEN_TEMPLATE_TEST\n",
    "```\n",
    "\n",
    "- init_task_engine_storyboard_executor 构建会话场景执行器，初始化一个会话\n",
    "\n",
    "- storyboard_code_gen_builder 构建会话场景执行器, 对会话存储进行加载，加载失败重新构建\n",
    "\n",
    "- generate_step_answer 通过会话场景 获取任务的答案\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0192e12b-5e15-4c43-b20e-1a46d3334aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "from dreamsboard.engine.storage.task_step_store.types import BaseTaskStepStore\n",
    "from dreamsboard.engine.task_engine_builder.core import TaskEngineBuilder\n",
    "from dreamsboard.engine.storage.task_step_store.simple_task_step_store import SimpleTaskStepStore\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dreamsboard.dreams.builder_task_step.base import StructuredTaskStepStoryboard\n",
    "from dreamsboard.engine.utils import concat_dirs\n",
    "from dreamsboard.engine.storage.task_step_store.types import DEFAULT_PERSIST_FNAME\n",
    "from dreamsboard.common.try_parse_json_object import try_parse_json_object\n",
    "from dreamsboard.engine.memory.mctsr.prompt import RefineResponse\n",
    "from dreamsboard.dreams.task_step_md.base import TaskStepMD\n",
    "from dreamsboard.common import _get_assistants_tool\n",
    "\n",
    "import logging\n",
    "import threading\n",
    "import os\n",
    "from dreamsboard.dreams.task_step_to_question_chain.weaviate.prepare_load import get_query_hash\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 控制台打印\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7950075d-2cbc-4eea-932b-e2928e4b0e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "flash_attn is not installed. Using PyTorch native attention implementation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=os.environ.get(\"API_BASE\"),\n",
    "    model=os.environ.get(\"API_MODEL\"),\n",
    "    openai_api_key=os.environ.get(\"API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "kor_dreams_task_step_llm = ChatOpenAI(\n",
    "    openai_api_base=os.environ.get(\"API_BASE\"),\n",
    "    model=os.environ.get(\"API_MODEL\"),\n",
    "    openai_api_key=os.environ.get(\"API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.95,\n",
    "    top_p=0.70,\n",
    ")\n",
    "\n",
    "deepseek_llm = ChatOpenAI(\n",
    "    openai_api_base=os.environ.get(\"DEEPSEEK_API_BASE\"),\n",
    "    model=os.environ.get(\"DEEPSEEK_API_MODEL\"),\n",
    "    openai_api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "zhipuai_llm = ChatOpenAI(\n",
    "    openai_api_base=os.environ.get(\"ZHIPUAI_API_BASE\"),\n",
    "    model=os.environ.get(\"ZHIPUAI_API_MODEL\"),\n",
    "    openai_api_key=os.environ.get(\"ZHIPUAI_API_KEY\"),\n",
    "    verbose=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    ")\n",
    "if 'glm' in os.environ.get(\"API_MODEL\"):\n",
    "\n",
    "    tools= [ { \"type\": \"web_search\",   \"web_search\": {\"enable\": False ,\"search_result\": False   }}]\n",
    "else:\n",
    "    tools = []\n",
    "llm_with_tools = llm.bind(   tools=[_get_assistants_tool(tool) for tool in tools] )\n",
    "kor_dreams_task_step_llm_with_tools = kor_dreams_task_step_llm.bind(   tools=[_get_assistants_tool(tool) for tool in tools] )\n",
    "\n",
    "from tests.test_builder_task_step.prompts import (\n",
    "    AEMO_REPRESENTATION_PROMPT_TEMPLATE as AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST,\n",
    "    STORY_BOARD_SCENE_TEMPLATE as STORY_BOARD_SCENE_TEMPLATE_TEST,\n",
    "    STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE as STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST,\n",
    "    EDREAMS_EVOLUTIONARY_TEMPLATE as EDREAMS_EVOLUTIONARY_TEMPLATE_TEST,\n",
    "    EDREAMS_PERSONALITY_TEMPLATE as EDREAMS_PERSONALITY_TEMPLATE_TEST,\n",
    "    DREAMS_GEN_TEMPLATE as DREAMS_GEN_TEMPLATE_TEST,\n",
    ") \n",
    "os.environ[\"AEMO_REPRESENTATION_PROMPT_TEMPLATE\"] = AEMO_REPRESENTATION_PROMPT_TEMPLATE_TEST\n",
    "os.environ[\"STORY_BOARD_SCENE_TEMPLATE\"] = STORY_BOARD_SCENE_TEMPLATE_TEST\n",
    "os.environ[\"STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE\"] = STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE_TEST\n",
    "os.environ[\"EDREAMS_EVOLUTIONARY_TEMPLATE\"] = EDREAMS_EVOLUTIONARY_TEMPLATE_TEST\n",
    "os.environ[\"EDREAMS_PERSONALITY_TEMPLATE\"] = EDREAMS_PERSONALITY_TEMPLATE_TEST\n",
    "os.environ[\"DREAMS_GEN_TEMPLATE\"] = DREAMS_GEN_TEMPLATE_TEST\n",
    "\n",
    "\n",
    "# 存储\n",
    "cross_encoder_path = \"/mnt/ceph/develop/jiawei/model_checkpoint/jina-reranker-v2-base-multilingual\"\n",
    "embed_model_path = \"/mnt/ceph/develop/jiawei/model_checkpoint/m3e-base\"\n",
    "start_task_context = \"什么是损失函数？\"\n",
    "builder = StructuredTaskStepStoryboard.form_builder(\n",
    "    llm_runable=llm_with_tools,\n",
    "    kor_dreams_task_step_llm=kor_dreams_task_step_llm_with_tools,\n",
    "    start_task_context=start_task_context,\n",
    "    cross_encoder_path=cross_encoder_path,\n",
    "    embed_model_path=embed_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b73a946-702a-4702-8a1a-cea0d8b1b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2e3a7c8d-7783-48f5-8344-79a0816bf207\n",
      "c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d\n",
      "ebde806e-4129-49b2-ae14-a53024b4da31\n",
      "94b00ac0-f040-4b86-a4cf-d0a341d92cd8\n",
      "0664ac70-89c3-481c-976f-ae120a264ff4\n",
      "86c7af97-ccb6-4a5a-bbe5-d86ce755bac4\n",
      "0fe8a867-be0a-4937-aa37-5a97fb432a3c\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 初始化任务引擎\n",
    "task_engine_builder = builder.loader_task_step_iter_builder(allow_init=True)\n",
    "while not task_engine_builder.empty():\n",
    "    task_engine = task_engine_builder.get()  \n",
    "    logger.info(task_engine.task_step_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4ee8a0-d50b-4728-8b18-a2d33860d5d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_step_id</th>\n",
       "      <th>shot_number</th>\n",
       "      <th>scene_number</th>\n",
       "      <th>start_task_context</th>\n",
       "      <th>aemo_representation_context</th>\n",
       "      <th>task_step_name</th>\n",
       "      <th>task_step_description</th>\n",
       "      <th>task_step_level</th>\n",
       "      <th>task_step_question</th>\n",
       "      <th>task_step_question_context</th>\n",
       "      <th>task_step_question_answer</th>\n",
       "      <th>ref_task_step_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e3a7c8d-7783-48f5-8344-79a0816bf207</td>\n",
       "      <td>1</td>\n",
       "      <td>story_board0</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>损失函数的定义</td>\n",
       "      <td>损失函数（Loss Function）是一个用于衡量模型预测结果与真实标签之间差异的函数。在...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d</td>\n",
       "      <td>2</td>\n",
       "      <td>story_board1</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>分析近几年研究领域中损失函数相关的技术框架与方法论</td>\n",
       "      <td>在不同研究领域，损失函数的设计与选择紧密关联技术框架与方法论。例如在深度学习框架下，根据任务...</td>\n",
       "      <td>0&gt;1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ebde806e-4129-49b2-ae14-a53024b4da31</td>\n",
       "      <td>3</td>\n",
       "      <td>story_board2</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>研究论文中损失函数在不同任务中的应用与变体</td>\n",
       "      <td>分类任务：交叉熵损失函数是主流选择，如在图像分类的卷积神经网络（CNN）中广泛应用。为应对类...</td>\n",
       "      <td>0&gt;2</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94b00ac0-f040-4b86-a4cf-d0a341d92cd8</td>\n",
       "      <td>4</td>\n",
       "      <td>story_board3</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>评估学术界损失函数相关的技术进步与局限性</td>\n",
       "      <td>技术进步：近年来损失函数的设计不断创新，针对不同任务和数据特点开发出多种有效的变体，显著提升...</td>\n",
       "      <td>0&gt;3</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0664ac70-89c3-481c-976f-ae120a264ff4</td>\n",
       "      <td>5</td>\n",
       "      <td>story_board4</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>探讨损失函数在不同数据集与应用场景下的适用性与泛化能力</td>\n",
       "      <td>在不同数据集上，损失函数的表现差异较大。对于大规模、高质量且分布均匀的数据集，标准的损失函数...</td>\n",
       "      <td>0&gt;4</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86c7af97-ccb6-4a5a-bbe5-d86ce755bac4</td>\n",
       "      <td>6</td>\n",
       "      <td>story_board5</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>分析最新损失函数算法的稳定性与容错性</td>\n",
       "      <td>一些最新的损失函数算法针对稳定性和容错性进行了优化。例如在复杂动态环境下，部分自适应损失函数...</td>\n",
       "      <td>0&gt;5</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0fe8a867-be0a-4937-aa37-5a97fb432a3c</td>\n",
       "      <td>7</td>\n",
       "      <td>story_board6</td>\n",
       "      <td>什么是损失函数？</td>\n",
       "      <td>### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...</td>\n",
       "      <td>评估论文中提出的损失函数相关未来研究方向与挑战</td>\n",
       "      <td>新研究问题：提出了如何设计通用的、不依赖特定任务和数据分布假设的损失函数，以提高模型在不同场...</td>\n",
       "      <td>0&gt;6</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           task_step_id  shot_number  scene_number  \\\n",
       "0  2e3a7c8d-7783-48f5-8344-79a0816bf207            1  story_board0   \n",
       "1  c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d            2  story_board1   \n",
       "2  ebde806e-4129-49b2-ae14-a53024b4da31            3  story_board2   \n",
       "3  94b00ac0-f040-4b86-a4cf-d0a341d92cd8            4  story_board3   \n",
       "4  0664ac70-89c3-481c-976f-ae120a264ff4            5  story_board4   \n",
       "5  86c7af97-ccb6-4a5a-bbe5-d86ce755bac4            6  story_board5   \n",
       "6  0fe8a867-be0a-4937-aa37-5a97fb432a3c            7  story_board6   \n",
       "\n",
       "  start_task_context                        aemo_representation_context  \\\n",
       "0           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "1           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "2           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "3           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "4           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "5           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "6           什么是损失函数？  ### 损失函数的定义\\n损失函数（Loss Function）是一个用于衡量模型预测结果与...   \n",
       "\n",
       "                task_step_name  \\\n",
       "0                      损失函数的定义   \n",
       "1    分析近几年研究领域中损失函数相关的技术框架与方法论   \n",
       "2        研究论文中损失函数在不同任务中的应用与变体   \n",
       "3         评估学术界损失函数相关的技术进步与局限性   \n",
       "4  探讨损失函数在不同数据集与应用场景下的适用性与泛化能力   \n",
       "5           分析最新损失函数算法的稳定性与容错性   \n",
       "6      评估论文中提出的损失函数相关未来研究方向与挑战   \n",
       "\n",
       "                               task_step_description task_step_level  \\\n",
       "0  损失函数（Loss Function）是一个用于衡量模型预测结果与真实标签之间差异的函数。在...               0   \n",
       "1  在不同研究领域，损失函数的设计与选择紧密关联技术框架与方法论。例如在深度学习框架下，根据任务...             0>1   \n",
       "2  分类任务：交叉熵损失函数是主流选择，如在图像分类的卷积神经网络（CNN）中广泛应用。为应对类...             0>2   \n",
       "3  技术进步：近年来损失函数的设计不断创新，针对不同任务和数据特点开发出多种有效的变体，显著提升...             0>3   \n",
       "4  在不同数据集上，损失函数的表现差异较大。对于大规模、高质量且分布均匀的数据集，标准的损失函数...             0>4   \n",
       "5  一些最新的损失函数算法针对稳定性和容错性进行了优化。例如在复杂动态环境下，部分自适应损失函数...             0>5   \n",
       "6  新研究问题：提出了如何设计通用的、不依赖特定任务和数据分布假设的损失函数，以提高模型在不同场...             0>6   \n",
       "\n",
       "  task_step_question task_step_question_context task_step_question_answer  \\\n",
       "0                                            []                             \n",
       "1                                            []                             \n",
       "2                                            []                             \n",
       "3                                            []                             \n",
       "4                                            []                             \n",
       "5                                            []                             \n",
       "6                                            []                             \n",
       "\n",
       "  ref_task_step_id  \n",
       "0                   \n",
       "1                   \n",
       "2                   \n",
       "3                   \n",
       "4                   \n",
       "5                   \n",
       "6                   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dreamsboard.document_loaders.structured_storyboard_loader import StructuredStoryboard\n",
    "store_load = SimpleTaskStepStore.from_persist_dir(persist_dir=\"./60f9b7459a7749597e7efa71d1747bc4/storage\")\n",
    " \n",
    "structured_storyboard = StructuredStoryboard(json_data=[step.__dict__ for step in list(store_load.task_step_all.values())])\n",
    "\n",
    "structured_storyboard.parse_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa90a7-8d6d-4a5b-bbd5-5415d4cecef1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 场景加载模块设计方案\n",
    "```\n",
    "\n",
    "编写符合计算机科学领域的 故事情境提示词，生成研究情境（story_scenario_context），替换现有的langchain会话模板，\n",
    "1、对这个提示词所要求的输入拆分成子任务，\n",
    "2、对每个子任务指令转换为子问题，召回问题前3条，\n",
    "3、对召回内容与问题拼接，合成会话内容变量（scene_content）\n",
    "\n",
    "\n",
    "对每个子问题相关的召回内容，转换为第一人称的会话总结（研究场景（scene_monologue_context）），\n",
    "\n",
    "1、对召回内容与问题拼接，对每个前3条组成一个总结任务的提示词，为每个任务标记唯一编号，组成任务上下文（story_board_summary_context）\n",
    "2、加载编号和story_board_summary_context，转换会话信息\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c75b99-e062-458f-993d-e58a048497b9",
   "metadata": {},
   "source": [
    "\n",
    "#### MCTS设计方案\n",
    "\n",
    "```\n",
    "MCT 自优化算法代表了蒙特卡洛树搜索（MCTS）与大型语言模型的结合，将不同的场景执行任务过程抽象为搜索树结构。树上的节点代表当前不同视角下的选择策略，而边表示主体对自身的反思。该算法的操作流程遵循 MCTS 算法的一般模式。\n",
    "\n",
    "具体来说，我们采用模型的先验知识，来让每个子任务通过在上下文中资源，通过自身反思探索来获取自身对问题的最优答案；这种方式依赖模型的对齐偏好，我们在每种偏好上设计了一个工程框架，来完成自我对不同答案的奖励进行采样策略\n",
    "\n",
    "\n",
    "1、对问题生成的子任务，生成一个合理的规划的节点\n",
    "2、对每个节点创建一个MCTS任务，\n",
    "3、输入 problem（总问题的子任务相关的子问题）\n",
    "4、评分代码重构，将片段摘录器模块集成到一个关于_evaluate_answer逻辑提示模板，模板主要作用：将每个子问题相关的loader_cosplay_builder构建一个关于evaluate_system_prompt 的生成策略，具体的为编写一个关于带有评估的评估器，由loader_cosplay_builder方法返回场景执行器（CodeGeneratorBuilder），使用add_generator添加一个问答策略(CodeGenerator)中构成问答交互，build_executor后执行  executor.chat_run() 返回_ai_message\n",
    "\n",
    "5、自我反思代码重构,将片段摘录器模块集成到一个关于self_refine逻辑提示模板，模板主要作用：将每个子问题相关的loader_cosplay_builder构建一个关于critic_system_prompt和refine_system_prompt的生成策略，critic_system_prompt为生成一个关于子问题相关的loader_cosplay_builder中自身不完美的评价内容，refine_system_prompt为不完美评价的思考过程和评分值。\n",
    "具体的为编写一个关于带有评价的生成器和反思生成器，它们由loader_cosplay_builder方法返回场景执行器（CodeGeneratorBuilder），使用add_generator添加一个问答策略(CodeGenerator)中构成问答交互，build_executor后执行  executor.chat_run() 返回_ai_message\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### MCTS执行中的重要环节\n",
    "```\n",
    "MCTS中的约束规则如下，需要保证这些节点必须符合下面所定义的基本规则\n",
    "\n",
    "提示约束：模型在奖励评分期间必须遵守最严格的标准。生成结果需要为JSON Response format\n",
    "{\n",
    "    \"thought\": \"The thought process behind the answer.\",\n",
    "    \"answer\": \"A float representing the answer to the problem.\"\n",
    "}\n",
    "\n",
    "\n",
    "高分抑制：评分节点中不存在满分反馈机制；任何超过 95 分的奖励都会按固定金额减少，以遏制过高分数。\n",
    "\n",
    "重复采样：每次访问搜索树节点都涉及对节点奖励的重复采样，以增强自我评估的可靠性。需要注意的是，当对节点的子节点进行奖励采样时，我们也会对其父节点进行奖励采样，以增加奖励采样的样本量。\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4056e4e3-32e6-4775-a025-42aa7d0f475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2e3a7c8d-7783-48f5-8344-79a0816bf207\n",
      "c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d\n",
      "ebde806e-4129-49b2-ae14-a53024b4da31\n",
      "94b00ac0-f040-4b86-a4cf-d0a341d92cd8\n",
      "0664ac70-89c3-481c-976f-ae120a264ff4\n",
      "86c7af97-ccb6-4a5a-bbe5-d86ce755bac4\n",
      "0fe8a867-be0a-4937-aa37-5a97fb432a3c\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 初始化任务引擎\n",
    "task_engine_builder = builder.loader_task_step_iter_builder(allow_init=False)\n",
    "while not task_engine_builder.empty():\n",
    "    task_engine = task_engine_builder.get()  \n",
    "    logger.info(task_engine.task_step_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "564d9451-6f2b-4685-ab6c-669ad626790f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step:1, task_step_id:2e3a7c8d-7783-48f5-8344-79a0816bf207, thread 258019，任务开始\n",
      "step:2, task_step_id:c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d, thread 258020，任务开始\n",
      "step:3, task_step_id:ebde806e-4129-49b2-ae14-a53024b4da31, thread 258021，任务开始\n",
      "step:4, task_step_id:94b00ac0-f040-4b86-a4cf-d0a341d92cd8, thread 258022，任务开始\n",
      "step:5, task_step_id:0664ac70-89c3-481c-976f-ae120a264ff4, thread 258023，任务开始\n",
      "step:6, task_step_id:86c7af97-ccb6-4a5a-bbe5-d86ce755bac4, thread 258024，任务开始\n",
      "step:7, task_step_id:0fe8a867-be0a-4937-aa37-5a97fb432a3c, thread 258025，任务开始\n",
      "Searching papers for query: 学术界在损失函数相关方面取得了哪些技术进步，又存在哪些局限性？ \n",
      "Found 30 papers.\n",
      "Found 30 unique paper IDs.\n",
      "Fetching details for paper ID: 628afb4c5aee126c0f04e3e8\n",
      "Searching papers for query: 在小样本、不均衡或存在噪声的数据集上，有哪些具体的针对性损失函数变体可以有效提升模型性能？ \n",
      "Searching papers for query: 在研究论文中，损失函数在分类、回归和生成任务中分别有哪些典型应用及变体，这些应用和变体是如何针对不同任务特点来提升模型性能的？ \n",
      "Fetching details for paper ID: 658b928f939a5f40825cf053\n",
      "Searching papers for query: 在极端复杂、动态变化剧烈的环境中，除了实时对抗性环境会使损失函数剧烈波动影响训练和预测效果外，还有哪些具体情况会对损失函数算法的稳定性和容错性造成挑战？ \n",
      "Searching papers for query: 论文中提出的损失函数相关未来研究方向里，结合元学习、强化学习设计动态自适应损失函数时，具体会面临哪些技术难点来实现根据模型学习过程和环境反馈实时调整损失函数的形式和参数 ？ \n",
      "Searching papers for query: 损失函数是通过衡量模型预测结果与真实标签之间差异来让模型最小化该差异从而使预测接近真实值，那么在实际应用中，如何具体确定模型是否已经将损失函数最小化到了理想程度呢？ \n",
      "Found 30 papers.\n",
      "Found 29 unique paper IDs.\n",
      "Fetching details for paper ID: 660278fd13fb2c6cf6fc64cf\n",
      "Found 30 papers.\n",
      "Found 29 unique paper IDs.\n",
      "Fetching details for paper ID: 6417d04190e50fcafd83e092\n",
      "Fetching details for paper ID: 62a6aabf5aee126c0ff36998\n",
      "Searching papers for query: 在深度学习框架下，除了图像分类任务常用交叉熵损失函数、回归任务常用均方误差损失函数外，其他不同类型的任务（如目标检测、语义分割等）分别适合选择哪些损失函数，其选择依据是什么？ \n",
      "Found 30 papers.\n",
      "Found 30 unique paper IDs.\n",
      "Fetching details for paper ID: 62c28ae55aee126c0f8a18c7\n",
      "Found 30 papers.\n",
      "Found 28 unique paper IDs.\n",
      "Fetching details for paper ID: 65f9014c13fb2c6cf67385a0\n",
      "Found 30 papers.\n",
      "Found 28 unique paper IDs.\n",
      "Fetching details for paper ID: 651390ac3fda6d7f06035198\n",
      "Fetching details for paper ID: 634f6ae490e50fcafdcb6394\n",
      "Fetching details for paper ID: 637c3dd690e50fcafd77ce16\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1baba\n",
      "Found 30 papers.\n",
      "Found 29 unique paper IDs.\n",
      "Fetching details for paper ID: 6417d04190e50fcafd83e092\n",
      "Fetching details for paper ID: 641d14e090e50fcafdf73cc1\n",
      "Fetching details for paper ID: 653b1d19939a5f4082995142\n",
      "Fetching details for paper ID: 65cd719d939a5f4082365010\n",
      "Fetching details for paper ID: 64e432bf3fda6d7f0600b086\n",
      "Fetching details for paper ID: 64eebe873fda6d7f06760831\n",
      "Fetching details for paper ID: 65e144ed13fb2c6cf60f4ea9\n",
      "Fetching details for paper ID: 637c3dd690e50fcafd77ce16\n",
      "Fetching details for paper ID: 6563feef939a5f408221246a\n",
      "Fetching details for paper ID: 633ba44890e50fcafdfe4f8d\n",
      "Fetching details for paper ID: 64741c33d68f896efaa7b684\n",
      "Fetching details for paper ID: 646aeca9d68f896efa05a64d\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1baba\n",
      "Fetching details for paper ID: 609a2fe691e011a44725cb74\n",
      "Fetching details for paper ID: 65fc055c13fb2c6cf6df20f3\n",
      "Fetching details for paper ID: 645dad15d68f896efad9dddc\n",
      "Fetching details for paper ID: 6323e96290e50fcafd8a241b\n",
      "Fetching details for paper ID: 626b49615aee126c0fffce85\n",
      "Fetching details for paper ID: 66ac3f8e01d2a3fbfc8ad784\n",
      "Fetching details for paper ID: 64e2e15a3fda6d7f06466a23\n",
      "Fetching details for paper ID: 669729ba01d2a3fbfc787b0f\n",
      "Fetching details for paper ID: 6630514301d2a3fbfcc144cf\n",
      "Fetching details for paper ID: 660278fd13fb2c6cf6fc64cf\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1baba\n",
      "Fetching details for paper ID: 65fc055b13fb2c6cf6df1ebb\n",
      "Fetching details for paper ID: 64ae66f73fda6d7f0684ad66\n",
      "Fetching details for paper ID: 6614a0e313fb2c6cf6f81048\n",
      "Fetching details for paper ID: 642ea3e190e50fcafd6d3bfb\n",
      "Fetching details for paper ID: 64eebe873fda6d7f06760831\n",
      "Fetching details for paper ID: 6296d90e5aee126c0f730aa9\n",
      "Fetching details for paper ID: 64741c33d68f896efaa7b684\n",
      "Fetching details for paper ID: 619c5bbf5244ab9dcbf22191\n",
      "Fetching details for paper ID: 6684b07501d2a3fbfce34d64\n",
      "Fetching details for paper ID: 626b49615aee126c0fffce85\n",
      "Fetching details for paper ID: 646edc9cd68f896efaddab04\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1baba\n",
      "Fetching details for paper ID: 6541a99d939a5f40824f9774\n",
      "Fetching details for paper ID: 65cd719f939a5f4082365060\n",
      "Fetching details for paper ID: 65b078e9939a5f4082b3307b\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b606c\n",
      "Fetching details for paper ID: 634781fe90e50fcafd2c1d83\n",
      "Fetching details for paper ID: 6695d3c001d2a3fbfccec120\n",
      "Fetching details for paper ID: 658e4adc939a5f4082dbe58d\n",
      "Fetching details for paper ID: 65fc055e13fb2c6cf6df2527\n",
      "Fetching details for paper ID: 64dd9b053fda6d7f0622e5fc\n",
      "Fetching details for paper ID: 630ed16590e50fcafd793932\n",
      "Fetching details for paper ID: 644744fb71ac66d2cbf9b64c\n",
      "Fetching details for paper ID: 668b481a01d2a3fbfc146e25\n",
      "Fetching details for paper ID: 607562a991e0110f6fe68218\n",
      "Fetching details for paper ID: 65fceadf13fb2c6cf6927a5d\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b637f\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b6187\n",
      "Fetching details for paper ID: 6279c9c55aee126c0fdadc5c\n",
      "Fetching details for paper ID: 64927546d68f896efa88a323\n",
      "Fetching details for paper ID: 6296d90f5aee126c0f730d22\n",
      "Fetching details for paper ID: 62bab8fa5aee126c0f6afdc6\n",
      "Fetching details for paper ID: 62b3da1f5aee126c0fb1ba42\n",
      "Fetching details for paper ID: 64af9a073fda6d7f065a6d83\n",
      "Fetching details for paper ID: 65fc055e13fb2c6cf6df2541\n",
      "Fetching details for paper ID: 652377f9939a5f4082e0ff9d\n",
      "Fetching details for paper ID: 634cc7a890e50fcafd163c6d\n",
      "Fetching details for paper ID: 653b1d19939a5f4082995002\n",
      "Fetching details for paper ID: 653b1d19939a5f4082995002\n",
      "Fetching details for paper ID: 60b5811b91e011f95a649603\n",
      "Fetching details for paper ID: 64e826d63fda6d7f06c31491\n",
      "Fetching details for paper ID: 6684b07501d2a3fbfce34d64\n",
      "Fetching details for paper ID: 62bab8fb5aee126c0f6b011a\n",
      "Fetching details for paper ID: 62c28ae55aee126c0f8a1a91\n",
      "Fetching details for paper ID: 621d8efc5aee126c0f757064\n",
      "Fetching details for paper ID: 66398b6801d2a3fbfcaee8a9\n",
      "Fetching details for paper ID: 6528c20b939a5f408299a8dd\n",
      "Fetching details for paper ID: 61722be25244ab9dcb6f0d33\n",
      "Fetching details for paper ID: 636b1a6590e50fcafdf41a24\n",
      "Fetching details for paper ID: 6583b18a939a5f408229ae5a\n",
      "Fetching details for paper ID: 621454535aee126c0f2016dd\n",
      "Fetching details for paper ID: 6401669c90e50fcafd688d3c\n",
      "Fetching details for paper ID: 6168f1a35244ab9dcbe2ffb5\n",
      "Fetching details for paper ID: 669dbc8001d2a3fbfca4223e\n",
      "Fetching details for paper ID: 6684b07501d2a3fbfce34d64\n",
      "Fetching details for paper ID: 6279c9c55aee126c0fdadc5c\n",
      "Fetching details for paper ID: 6630513001d2a3fbfcc1329a\n",
      "Fetching details for paper ID: 621d8efc5aee126c0f757064\n",
      "Fetching details for paper ID: 65ea87e213fb2c6cf62d262c\n",
      "Fetching details for paper ID: 652377f9939a5f4082e0ff9d\n",
      "Fetching details for paper ID: 64d074bf3fda6d7f06ce9265\n",
      "Fetching details for paper ID: 62feff8d90e50fcafd599837\n",
      "Fetching details for paper ID: 64f59fb33fda6d7f0648d313\n",
      "Fetching details for paper ID: 657bc030939a5f4082f3a51d\n",
      "Fetching details for paper ID: 659e222e939a5f408289b50a\n",
      "Fetching details for paper ID: 652def08939a5f4082b53a82\n",
      "Fetching details for paper ID: 6699cc8401d2a3fbfcc305f6\n",
      "Fetching details for paper ID: 6694829701d2a3fbfc866421\n",
      "Fetching details for paper ID: 621d8ece5aee126c0f73b43e\n",
      "Fetching details for paper ID: 63e1c14790e50fcafd2dd474\n",
      "Fetching details for paper ID: 64af9a033fda6d7f065a69b9\n",
      "Fetching details for paper ID: 64af99fe3fda6d7f065a6424\n",
      "Fetching details for paper ID: 6699cc8401d2a3fbfcc304bb\n",
      "Fetching details for paper ID: 65026d513fda6d7f06474bb3\n",
      "Fetching details for paper ID: 650904f23fda6d7f06cd533a\n",
      "Fetching details for paper ID: 6694829701d2a3fbfc866454\n",
      "Fetching details for paper ID: 65ea87e213fb2c6cf62d262c\n",
      "Fetching details for paper ID: 63c0cc6490e50fcafd2a8e39\n",
      "Fetching details for paper ID: 65ea8c8f13fb2c6cf6313ca1\n",
      "Fetching details for paper ID: 65f25a4213fb2c6cf6e10cb0\n",
      "Fetching details for paper ID: 660f5aea13fb2c6cf6543b4a\n",
      "Fetching details for paper ID: 6344dede90e50fcafd24d2a3\n",
      "Fetching details for paper ID: 6456389bd68f896efacf6ab0\n",
      "Fetching details for paper ID: 65cd71a5939a5f40823651e7\n",
      "Fetching details for paper ID: 634e194190e50fcafd24e6f5\n",
      "Fetching details for paper ID: 6419209390e50fcafda930c1\n",
      "Fetching details for paper ID: 65a75ad7939a5f408261ba1b\n",
      "Fetching details for paper ID: 64e432bf3fda6d7f0600af66\n",
      "Fetching details for paper ID: 6464afbed68f896efa355607\n",
      "Fetching details for paper ID: 633ba44990e50fcafdfe513e\n",
      "Fetching details for paper ID: 64e2e15a3fda6d7f06466aed\n",
      "Fetching details for paper ID: 628c4ce15aee126c0ff5986d\n",
      "Fetching details for paper ID: 6421094690e50fcafdb025a7\n",
      "Fetching details for paper ID: 64af9a033fda6d7f065a69b9\n",
      "Fetching details for paper ID: 62abf1365aee126c0f475dfb\n",
      "Fetching details for paper ID: 64ffca703fda6d7f06cd8b93\n",
      "Fetching details for paper ID: 629587475aee126c0fe14c31\n",
      "Fetching details for paper ID: 6424fe3390e50fcafd78b7ad\n",
      "Fetching details for paper ID: 6304455490e50fcafd12c525\n",
      "Fetching details for paper ID: 6285b5995aee126c0f14d938\n",
      "Fetching details for paper ID: 6350bc6c90e50fcafdecf087\n",
      "Fetching details for paper ID: 620b19c85aee126c0f7e6dcd\n",
      "Fetching details for paper ID: 64f7f8e53fda6d7f06f25284\n",
      "Fetching details for paper ID: 64f7f8e53fda6d7f06f25389\n",
      "Fetching details for paper ID: 65b70846939a5f4082e0bec1\n",
      "Fetching details for paper ID: 61f9f64a5aee126c0f41f4fd\n",
      "Fetching details for paper ID: 64ae66e33fda6d7f06848fb5\n",
      "Fetching details for paper ID: 628c4ce15aee126c0ff5986d\n",
      "Fetching details for paper ID: 64e432bf3fda6d7f0600af7b\n",
      "Fetching details for paper ID: 65f25a4213fb2c6cf6e10cb0\n",
      "Fetching details for paper ID: 652f3ff0939a5f4082e74d86\n",
      "Fetching details for paper ID: 647572d8d68f896efa7b7339\n",
      "Fetching details for paper ID: 64951856d68f896efa1ef4c9\n",
      "Fetching details for paper ID: 657bbe35939a5f4082f217f9\n",
      "Fetching details for paper ID: 65977591939a5f4082b152ec\n",
      "Fetching details for paper ID: 64af9a033fda6d7f065a69b9\n",
      "Fetching details for paper ID: 64f7f9443fda6d7f06f28c22\n",
      "Fetching details for paper ID: 65810e63939a5f4082fd0411\n",
      "Fetching details for paper ID: 65b313a0939a5f4082a4ad09\n",
      "Fetching details for paper ID: 63a2794890e50fcafd294038\n",
      "Fetching details for paper ID: 63dcdb422c26941cf00b60af\n",
      "Fetching details for paper ID: 65b313a0939a5f4082a4ad09\n",
      "Fetching details for paper ID: 649bb0eed68f896efa4ddd22\n",
      "Fetching details for paper ID: 64951856d68f896efa1ef49b\n",
      "Fetching details for paper ID: 62bbc3875aee126c0fa68993\n",
      "Fetching details for paper ID: 61f9f64a5aee126c0f41f4fd\n",
      "Fetching details for paper ID: 62c28ae65aee126c0f8a23c9\n",
      "Fetching details for paper ID: 62abf1365aee126c0f475dfd\n",
      "Fetching details for paper ID: 65fa440013fb2c6cf673e6e4\n",
      "Fetching details for paper ID: 65b313a0939a5f4082a4ad09\n",
      "Fetching details for paper ID: 657bc0f9939a5f4082f44b59\n",
      "Fetching details for paper ID: 6049fc2991e01118b758f1cb\n",
      "Fetching details for paper ID: 657bbe35939a5f4082f217f9\n",
      "Fetching details for paper ID: 61664e625244ab9dcb4558e9\n",
      "Fetching details for paper ID: 65011bdb3fda6d7f060e46ef\n",
      "Fetching details for paper ID: 66ecdacf01d2a3fbfcdfd661\n",
      "Fetching details for paper ID: 650a56593fda6d7f067e9fff\n",
      "Fetching details for paper ID: 610a46645244ab9dcbb9f007\n",
      "Fetching details for paper ID: 60d140d191e011c16f0cb388\n",
      "Fetching details for paper ID: 65e7dcad13fb2c6cf6fdc96c\n",
      "Fetching details for paper ID: 63ae56c790e50fcafda9544b\n",
      "Fetching details for paper ID: 637c3dd190e50fcafd77c852\n",
      "Fetching details for paper ID: 637df726f54df3000cd72c2f\n",
      "Fetching details for paper ID: 658254cf939a5f4082bc95a5\n",
      "Fetching details for paper ID: 6464afa7d68f896efa35488d\n",
      "Fetching details for paper ID: 6271e0eb5aee126c0f57498f\n",
      "Fetching details for paper ID: 64dafb293fda6d7f064e2ccd\n",
      "Fetching details for paper ID: 6482a378d68f896efa8d0328\n",
      "Fetching details for paper ID: 662b0b1701d2a3fbfc660f32\n",
      "Fetching details for paper ID: 65655791939a5f4082b9d852\n",
      "Fetching details for paper ID: 622eb24d5aee126c0f62b47c\n",
      "Fetching details for paper ID: 640fe64f90e50fcafd9e4b6c\n",
      "Fetching details for paper ID: 64dafb293fda6d7f064e2c4e\n",
      "Fetching details for paper ID: 65a0a93f939a5f40828adf01\n",
      "Fetching details for paper ID: 6695d3c001d2a3fbfccebfaf\n",
      "Fetching details for paper ID: 656fdda8939a5f4082933dc2\n",
      "Fetching details for paper ID: 63520de390e50fcafd60eb9b\n",
      "Fetching details for paper ID: 620c6b6a5aee126c0fe29620\n",
      "Fetching details for paper ID: 64671265d68f896efaf147e6\n",
      "Fetching details for paper ID: 61fb47e15aee126c0f873be1\n",
      "Fetching details for paper ID: 65810e5b939a5f4082fcfd71\n",
      "Fetching details for paper ID: 622eb24d5aee126c0f62b47c\n",
      "Fetching details for paper ID: 61d65e0b5244ab9dcbf16072\n",
      "Fetching details for paper ID: 658254cf939a5f4082bc95a5\n",
      "Data cached for query: 学术界在损失函数相关方面取得了哪些技术进步，又存在哪些局限性？  at /tmp/query_cache/7e65de92f6996843d16a351a2d7b2b4f.json\n",
      "owner:register_event thread 258022\n",
      "owner:getlock thread 259472, resource_id:resource_collection_94b00ac0-f040-4b86-a4cf-d0a341d92cd8\n",
      "owner:lock thread 259472, resource_id:resource_collection_94b00ac0-f040-4b86-a4cf-d0a341d92cd8\n",
      "thread 259472 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259472 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259472 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259472 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Fetching details for paper ID: 62d620f65aee126c0fad477f\n",
      "Exception in thread Thread-23 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_94b00ac0-f040-4b86-a4cf-d0a341d92cd8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching details for paper ID: 64671268d68f896efaf14a15\n",
      "Data cached for query: 论文中提出的损失函数相关未来研究方向里，结合元学习、强化学习设计动态自适应损失函数时，具体会面临哪些技术难点来实现根据模型学习过程和环境反馈实时调整损失函数的形式和参数 ？  at /tmp/query_cache/61daa058af012d45485b169caeae1fe6.json\n",
      "owner:register_event thread 258025\n",
      "owner:getlock thread 259561, resource_id:resource_collection_0fe8a867-be0a-4937-aa37-5a97fb432a3c\n",
      "owner:lock thread 259561, resource_id:resource_collection_0fe8a867-be0a-4937-aa37-5a97fb432a3c\n",
      "thread 259561 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259561 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259561 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259561 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-26 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n",
      "Data cached for query: 损失函数是通过衡量模型预测结果与真实标签之间差异来让模型最小化该差异从而使预测接近真实值，那么在实际应用中，如何具体确定模型是否已经将损失函数最小化到了理想程度呢？  at /tmp/query_cache/f88cfc0c200df47d4b60601eabe8583b.json\n",
      "owner:register_event thread 258019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_0fe8a867-be0a-4937-aa37-5a97fb432a3c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "owner:getlock thread 259606, resource_id:resource_collection_2e3a7c8d-7783-48f5-8344-79a0816bf207\n",
      "owner:lock thread 259606, resource_id:resource_collection_2e3a7c8d-7783-48f5-8344-79a0816bf207\n",
      "thread 259606 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259606 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259606 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259606 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-20 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_2e3a7c8d-7783-48f5-8344-79a0816bf207.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data cached for query: 在小样本、不均衡或存在噪声的数据集上，有哪些具体的针对性损失函数变体可以有效提升模型性能？  at /tmp/query_cache/e7acff03d32f9af684dec62be5476874.json\n",
      "owner:register_event thread 258023\n",
      "owner:getlock thread 259662, resource_id:resource_collection_0664ac70-89c3-481c-976f-ae120a264ff4\n",
      "owner:lock thread 259662, resource_id:resource_collection_0664ac70-89c3-481c-976f-ae120a264ff4\n",
      "thread 259662 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259662 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259662 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259662 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-24 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n",
      "Data cached for query: 在研究论文中，损失函数在分类、回归和生成任务中分别有哪些典型应用及变体，这些应用和变体是如何针对不同任务特点来提升模型性能的？  at /tmp/query_cache/8f71d1496939487e6090284ce1e3450e.json\n",
      "owner:register_event thread 258021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_0664ac70-89c3-481c-976f-ae120a264ff4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "owner:getlock thread 259708, resource_id:resource_collection_ebde806e-4129-49b2-ae14-a53024b4da31\n",
      "owner:lock thread 259708, resource_id:resource_collection_ebde806e-4129-49b2-ae14-a53024b4da31\n",
      "thread 259708 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259708 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259708 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259708 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-22 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n",
      "Fetching details for paper ID: 6434cfd690e50fcafd7a4432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_ebde806e-4129-49b2-ae14-a53024b4da31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching details for paper ID: 65cd71a5939a5f40823651e7\n",
      "Data cached for query: 在深度学习框架下，除了图像分类任务常用交叉熵损失函数、回归任务常用均方误差损失函数外，其他不同类型的任务（如目标检测、语义分割等）分别适合选择哪些损失函数，其选择依据是什么？  at /tmp/query_cache/76e6e4a05cda5a64f42893395024cd43.json\n",
      "owner:register_event thread 258020\n",
      "owner:getlock thread 259801, resource_id:resource_collection_c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d\n",
      "owner:lock thread 259801, resource_id:resource_collection_c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d\n",
      "thread 259801 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259801 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259801 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259801 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-21 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n",
      "Data cached for query: 在极端复杂、动态变化剧烈的环境中，除了实时对抗性环境会使损失函数剧烈波动影响训练和预测效果外，还有哪些具体情况会对损失函数算法的稳定性和容错性造成挑战？  at /tmp/query_cache/e2bd6796773888281c535a16201b9b3d.json\n",
      "owner:register_event thread 258024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "owner:getlock thread 259846, resource_id:resource_collection_86c7af97-ccb6-4a5a-bbe5-d86ce755bac4\n",
      "owner:lock thread 259846, resource_id:resource_collection_86c7af97-ccb6-4a5a-bbe5-d86ce755bac4\n",
      "thread 259846 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259846 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。\n",
      "thread 259846 开始操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "thread 259846 结束操作：('60f9b7459a7749597e7efa71d1747bc4', 'samples')。插入\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/common/callback.py\", line 71, in _run\n",
      "    self.mfunc(callback=self._callback, resource_id=self.resource_id, **self.kwargs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 189, in _into_database_query\n",
      "    kwargs.get(\"collection\").do_add_doc(docs)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/vector/faiss_kb_service.py\", line 106, in do_add_doc\n",
      "    embeddings = vs.embeddings.embed_documents(texts)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/langchain_community/embeddings/huggingface.py\", line 98, in embed_documents\n",
      "    embeddings = self.client.encode(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\", line 583, in encode\n",
      "    self.to(device)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "Exception in thread Thread-25 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/mnt/ceph/develop/jiawei/conda_env/dreams/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_244018/2502808359.py\", line 5, in worker\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/engine/task_engine_builder/core.py\", line 144, in init_task_engine\n",
      "    self.task_step_to_question_chain.invoke_task_step_question_context(self.task_step_id)\n",
      "  File \"/mnt/ceph/develop/jiawei/InterpretationoDreams/src/dreamsboard/dreamsboard/dreams/task_step_to_question_chain/base.py\", line 223, in invoke_task_step_question_context\n",
      "    response = results[0]\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration complete for resource_collection_86c7af97-ccb6-4a5a-bbe5-d86ce755bac4.\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "def worker(step: int, task_engine: TaskEngineBuilder, task_step_store: BaseTaskStepStore):\n",
    "    owner = f\"step:{step}, task_step_id:{task_engine.task_step_id}, thread {threading.get_native_id()}\"\n",
    "    logger.info(f\"{owner}，任务开始\")\n",
    "    if not task_engine.check_engine_init():\n",
    "        task_engine.init_task_engine()\n",
    "        task_engine.init_task_engine_dreams()\n",
    "        task_engine.init_task_engine_storyboard_executor()\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"{owner}，storyboard_code_gen_builder\")\n",
    "        code_gen_builder = task_engine.storyboard_code_gen_builder()\n",
    "        task_step = task_engine.task_step_store.get_task_step(task_engine.task_step_id)\n",
    "        if task_step.task_step_question_answer is None or len(task_step.task_step_question_answer) == 0:\n",
    "            task_engine.generate_step_answer(code_gen_builder)\n",
    "        \n",
    "        logger.info(f\"step:{step}, {owner}，get_mcts_node\")\n",
    "        mcts_node = task_engine.get_mcts_node()\n",
    "        if step % 2 == 0:\n",
    "            mcts_node.llm_runable = deepseek_llm\n",
    "        if step % 3 == 0:\n",
    "            mcts_node.llm_runable = zhipuai_llm\n",
    "        logger.info(f\"step:{step}, {owner}，get_mcts_node run\")\n",
    "        answer = mcts_node.run()\n",
    "        \n",
    "        mcts_node.print()\n",
    "        print(answer)\n",
    "        task_step.task_step_question_answer = answer \n",
    "        task_step_id = task_engine.task_step_id\n",
    "        \n",
    "        task_engine.task_step_store.add_task_step([task_step])\n",
    "        task_step_store_path = concat_dirs(dirname=f\"{builder.base_path}/storage/{task_step_id}\", basename=DEFAULT_PERSIST_FNAME)\n",
    "        task_engine.task_step_store.persist(persist_path=task_step_store_path) \n",
    "        \n",
    "        task_step_store.add_task_step([task_step])\n",
    "        task_step_store_path = concat_dirs(dirname=f\"{builder.base_path}/storage\", basename=DEFAULT_PERSIST_FNAME)\n",
    "        task_step_store.persist(persist_path=task_step_store_path) \n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"场景加载失败\", e)\n",
    "\n",
    "    logger.info(f\"{owner}，任务结束\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    threads = []\n",
    "    \n",
    "    step =0\n",
    "    task_step_store = builder.task_step_store\n",
    "    # 初始化任务引擎\n",
    "    task_engine_builder = builder.loader_task_step_iter_builder(allow_init=False)\n",
    "    while not task_engine_builder.empty():\n",
    "       \n",
    "        task_engine = task_engine_builder.get()\n",
    "        step += 1\n",
    "        t = threading.Thread(target=worker,\n",
    "                             kwargs={\"step\": step, \"task_engine\": task_engine, \"task_step_store\": task_step_store},\n",
    "                             daemon=True)\n",
    "        t.start()\n",
    "        threads.append(t) \n",
    "    \n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944db87a-cb55-4148-aaf0-4806ffeea663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# 什么是损失函数？ \n",
       "\n",
       "\n",
       "### 损失函数的定义 [task_id:0](2e3a7c8d-7783-48f5-8344-79a0816bf207)\n",
       "\n",
       "损失函数（Loss Function）是一个用于衡量模型预测结果与真实标签之间差异的函数。在机器学习和深度学习中，模型的目标通常是最小化这个损失函数，以便使模型的预测尽可能接近真实值。\n",
       "\n",
       "分析近几年研究领域中损失函数相关的技术框架与方法论 [task_id:0>1](c7cd45bd-b59c-49cc-b0b1-f5253f5f5a9d)在不同研究领域，损失函数的设计与选择紧密关联技术框架与方法论。例如在深度学习框架下，根据任务类型（分类、回归等）选择合适的损失函数。如在图像分类任务中常用交叉熵损失函数，它基于概率分布的差异度量，符合分类任务预测类别概率的特性；在回归任务里，均方误差损失函数较为常用，通过计算预测值与真实值差值的平方来衡量误差，反映预测的偏离程度。不同方法论也会影响损失函数的构建，如强化学习中基于策略梯度的方法，其损失函数设计围绕最大化累计奖励，与监督学习中的损失函数设计思路有明显区别。\n",
       "\n",
       "研究论文中损失函数在不同任务中的应用与变体 [task_id:0>2](ebde806e-4129-49b2-ae14-a53024b4da31)分类任务：交叉熵损失函数是主流选择，如在图像分类的卷积神经网络（CNN）中广泛应用。为应对类别不均衡问题，出现了变体如焦点损失（Focal Loss），它通过对不同类别样本赋予不同权重，加大对难分类样本的学习权重，提升模型在不均衡数据上的分类性能。在文本分类任务中，除了标准交叉熵损失，还会结合对抗训练引入对抗损失，以增强模型对文本语义的理解和泛化能力。回归任务：均方误差损失函数是基础，但在一些对异常值敏感的场景下，会采用平均绝对误差（MAE）损失函数，它对异常值的鲁棒性更强。还有 Huber 损失函数，结合了 MSE 和 MAE 的优点，在误差较小时类似 MSE 以加快收敛，误差较大时类似 MAE 增强鲁棒性。生成任务：生成对抗网络（GAN）中，生成器和判别器的训练基于对抗损失。生成器试图最小化生成样本与真实样本在判别器上的差异损失，判别器则最大化区分真实样本和生成样本的损失。此外，在变分自编码器（VAE）中，使用重构损失和 KL 散度损失共同约束模型学习数据的潜在表示和重构能力。\n",
       "\n",
       "评估学术界损失函数相关的技术进步与局限性 [task_id:0>3](94b00ac0-f040-4b86-a4cf-d0a341d92cd8)技术进步：近年来损失函数的设计不断创新，针对不同任务和数据特点开发出多种有效的变体，显著提升了模型性能。例如上述提到的焦点损失、对抗损失等，在实际应用中取得了良好效果。同时，随着理论研究的深入，对损失函数的性质和优化过程有了更清晰的理解，有助于更合理地选择和设计损失函数。局限性：尽管取得进步，但损失函数仍存在一些问题。一方面，很多损失函数的设计依赖于特定的任务假设和数据分布，泛化能力有限。例如某些针对特定数据集设计的损失函数变体，在其他数据集上效果不佳。另一方面，模型偏差和数据依赖问题依然存在。如在小样本数据上，损失函数可能无法充分学习到数据的特征，导致模型过拟合；在存在噪声的数据中，损失函数可能对噪声敏感，影响模型性能。\n",
       "\n",
       "探讨损失函数在不同数据集与应用场景下的适用性与泛化能力 [task_id:0>4](0664ac70-89c3-481c-976f-ae120a264ff4)在不同数据集上，损失函数的表现差异较大。对于大规模、高质量且分布均匀的数据集，标准的损失函数如交叉熵损失、均方误差损失通常能取得较好效果。但在小样本、不均衡或存在噪声的数据集上，需要针对性的损失函数变体来提升模型性能。在应用场景方面，医疗影像诊断中，由于数据稀缺且对诊断准确性要求高，需要设计能充分利用有限数据且对微小病变敏感的损失函数；在自动驾驶场景下，数据具有动态性和实时性，损失函数要能适应环境变化，保证模型在复杂路况下的稳定性和准确性。然而，目前很多损失函数在跨领域、跨模态数据上的泛化能力仍有待提高，难以直接应用于多领域融合的复杂场景。\n",
       "\n",
       "分析最新损失函数算法的稳定性与容错性 [task_id:0>5](86c7af97-ccb6-4a5a-bbe5-d86ce755bac4)一些最新的损失函数算法针对稳定性和容错性进行了优化。例如在复杂动态环境下，部分自适应损失函数能够根据训练过程中的数据变化自动调整参数，保持模型训练的稳定性。在大规模数据上，一些分布式训练的损失函数算法通过优化通信和计算策略，提高算法的适应性和效率。但总体而言，在极端复杂、动态变化剧烈的环境中，损失函数算法的稳定性和容错性仍面临挑战，例如在实时对抗性环境中，模型可能因环境突变导致损失函数剧烈波动，影响训练和预测效果。\n",
       "\n",
       "评估论文中提出的损失函数相关未来研究方向与挑战 [task_id:0>6](0fe8a867-be0a-4937-aa37-5a97fb432a3c)新研究问题：提出了如何设计通用的、不依赖特定任务和数据分布假设的损失函数，以提高模型在不同场景下的泛化能力。还关注如何利用无监督或弱监督数据设计损失函数，降低对大规模标注数据的依赖。现有问题改进：针对模型偏差和数据依赖问题，研究如何通过损失函数的设计使模型更好地学习数据的本质特征，减少过拟合和欠拟合现象。同时，致力于提升损失函数在复杂环境下的稳定性和容错性，确保模型在各种干扰和变化下仍能正常工作。新研究切入点：结合新的技术如元学习、强化学习来设计动态自适应的损失函数，根据模型的学习过程和环境反馈实时调整损失函数的形式和参数。这些挑战推动后续研究不断探索新的理论和方法，以改进损失函数的设计和应用，提升模型的整体性能和适应性。\n",
       "\n",
       "\n",
       " \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "store_load = SimpleTaskStepStore.from_persist_dir(persist_dir=\"./60f9b7459a7749597e7efa71d1747bc4/storage\")\n",
    "task_step_md = TaskStepMD(store_load)\n",
    "md_text =   task_step_md.format_md() \n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(md_text.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f79489-2835-4b70-97ec-3c3bdbeb5fdf",
   "metadata": {},
   "source": [
    "\n",
    "StructuredTaskStepStoryboard\n",
    "    \n",
    "对任务进行规划，生成段落之间组成一个动态上下文，  扩写任务步骤构建MCTS任务\n",
    "    输入：\n",
    "    \tstart_task_context： 起始任务\n",
    "    \tllm： 模型\n",
    "    \tkor_dreams_task_step_llm: 任务抽取模型\n",
    "    \ttask_step_store: 任务存储器（SimpleTaskStepStore）\n",
    "    \tcross_encoder_path: ranking模型路径（sentence_transformers），当前设计耦合了业务，之后会单独设计一个召回模块\n",
    "\n",
    "    任务：\n",
    "\n",
    "        1、对任务（AEMO_REPRESENTATION_PROMPT_TEMPLATE）按照提示词要求进行扩写，将扩写任务步骤收集 （src/dreamsboard/dreamsboard/engine/entity/task_step、src/dreamsboard/tests/test_kor/test_kor3.py）\n",
    "\n",
    "        2、收集每个任务后存储到磁盘（src/dreamsboard/dreamsboard/engine/storage/task_step_store）\n",
    "\n",
    "        3、对每个子任务载入会话场景，然后按照扩写任务步骤构建，MCTS任务 loader_task_step_iter_builder\n",
    "\n",
    "\n",
    "\t》 TaskEngineBuilder 场景加载模块\n",
    "\t\t执行会话场景资源初始化，构建MCTS任务\n",
    "\n",
    "    根据任务步骤，构建场景加载模块，生成资源文件csv\n",
    "    根据每个任务，载入StructuredDreamsStoryboard 会话场景\n",
    "    按照扩写任务步骤构建MCTS任务\n",
    "\n",
    "\t\t输入：\n",
    "\t\t\ttask_step_id\n",
    "\t\t\ttask_step_store: 任务存储器（SimpleTaskStepStore）\n",
    "\t\t\tstart_task_context： 起始任务\n",
    "\t\t\tllm： 模型\n",
    "\n",
    "\t\t任务：\n",
    "\t\t\tinit_task_engine：\n",
    "\t\t\t\t初始化任务引擎\n",
    "        》TaskStepToQuestionChain \n",
    "        \t输入：\n",
    "        \t\tclient： 矢量库客户端\n",
    "        \t\tllm： 模型\n",
    "\t\t\t\t\tinvoke_task_step_to_question：1、 对开始任务进行抽取，得到任务步骤，提示词所要求的输入拆分成子任务， \n",
    "\t\t\t\t\tinvoke_task_step_question_context： 2、对每个子任务指令转换为子问题，召回问题前3条，对任务步骤进行抽取，得到任务步骤的上下文\n",
    "\t\t\t\t\texport_csv_file_path: 3、对召回内容与问题 导出csv文件\n",
    "\n",
    "\t\t\tinit_task_engine_dreams\n",
    "\t\t\t\t初始化场景加载资源\n",
    "\t\t\t\t\tStoryBoardDreamsGenerationChain\n",
    "\t\t\t\t\t对每个子任务通过职业提示词，载入会话场景\n",
    "\t\t\t\t\t\t1、构建场景信息（story_scenario_context），提示词（STORY_BOARD_SCENE_TEMPLATE）\n",
    "\t\t\t\t\t\t2、对任务上下文(story_board_summary_context)，构建第一人称数据(scene_monologue_context),提示词（STORY_BOARD_SUMMARY_CONTEXT_TEMPLATE）\n",
    "\t\t\t\t\t\t3、对任务上下文(story_board_summary_context)，获取任务分析(evolutionary_step), 提示词（EDREAMS_EVOLUTIONARY_TEMPLATE）\n",
    "\t\t\t\t\t\t4、对任务分析(evolutionary_step)，分析对话预设信息（性格）， 提示词（EDREAMS_PERSONALITY_TEMPLATE）\n",
    "\t\t\t\t\t\t5、对任务上下文(story_board_summary_context)，场景信息story_scenario_context, 第一人称数据(scene_monologue_context)，\n",
    "\t\t\t\t\t\t生成关于人物职业的引导话术，提示词（DREAMS_GEN_TEMPLATE）\n",
    "\n",
    "\t\t\tinit_task_engine_storyboard_executor\n",
    "\n",
    "\t\t\t\t构建会话场景执行器 StructuredDreamsStoryboard\n",
    "\t\t\t\t\t对剧本和分析结果进行结构化，将开放问题与性格分析结果进行结合。生成情景扮演会话场景执行器\n",
    "\t\t\t    此过程如下\n",
    "\t\t\t        对开放问题结果进行抽取，得到问题内容\n",
    "\t\t\t        对性格分析结果进行抽取，得到性格分析结果\n",
    "\t\t\t        增加系统提示词\n",
    "\t\t\t        根据剧本与任务性格基础情景扮演代码，根据每步的抽取析得到的问题，生成问题的答案\n",
    "\t\t\t       \t在上下文中增加，关于人物职业的引导话术\n",
    "\t        \t\t导出会话场景执行器\n",
    "\t\t\t\t\t\n",
    "\t    storyboard_code_gen_builder\n",
    "\t    \t构建会话场景执行器\n",
    "\n",
    "\t    generate_step_answer\n",
    "\t    \t获取主进程子任务的答案\n",
    "\t    \n",
    "\t    get_mcts_node\n",
    "\t    \t构建MCTS树, 初始化当前任务相关的MCTS节点，并返回MCTS执行器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7d06a-858a-48c9-80d5-f7dedeb20220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
